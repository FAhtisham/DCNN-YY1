{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 19:56:14.704582: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Dense, LSTM, Conv1D, Bidirectional, Flatten, Concatenate,concatenate,BatchNormalization,MaxPooling1D, Conv2D, MaxPooling2D, AveragePooling2D, Dropout, Reshape, normalization\n",
    "from keras.models import Model\n",
    "# from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "# from keras.layers.recurrent import LSTM\n",
    "from sklearn import metrics\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 19:56:19.100097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-08 19:56:19.105266: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-06-08 19:56:19.105276: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-06-08 19:56:19.105635: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    # Calculates the precision\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    # Calculates the recall\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1(test_Y, pre_test_y):\n",
    "    \"\"\"F1-score\"\"\"\n",
    "    Precision = precision(test_Y, pre_test_y)\n",
    "    Recall = recall(test_Y, pre_test_y)\n",
    "    f1 = 2 * ((Precision * Recall) / (Precision + Recall + K.epsilon()))\n",
    "    return f1 \n",
    "\n",
    "def TP(test_Y,pre_test_y):\n",
    "    TP = K.sum(K.round(K.clip(test_Y * pre_test_y, 0, 1)))#TP\n",
    "    return TP\n",
    "\n",
    "def FN(test_Y,pre_test_y):\n",
    "    TP = K.sum(K.round(K.clip(test_Y * pre_test_y, 0, 1)))#TP\n",
    "    P=K.sum(K.round(K.clip(test_Y, 0, 1)))\n",
    "    FN = P-TP #FN=P-TP\n",
    "    return FN\n",
    "\n",
    "def TN(test_Y,pre_test_y):\n",
    "    TN=K.sum(K.round(K.clip((test_Y-K.ones_like(test_Y))*(pre_test_y-K.ones_like(pre_test_y)), 0, 1)))#TN\n",
    "    return TN\n",
    "\n",
    "def FP(test_Y,pre_test_y):\n",
    "    N = (-1)*K.sum(K.round(K.clip(test_Y-K.ones_like(test_Y), -1, 0)))#N\n",
    "    TN=K.sum(K.round(K.clip((test_Y-K.ones_like(test_Y))*(pre_test_y-K.ones_like(pre_test_y)), 0, 1)))#TN\n",
    "    FP=N-TN\n",
    "    return FP\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc\n",
    "\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "# def dnn_model(train_X, train_Y, test_X, test_Y, lr, epoch, batch_size):\n",
    "    \n",
    "#     train_X = np.expand_dims(train_X, 2)\n",
    "#     test_X = np.expand_dims(test_X, 2)\n",
    "#     inputs = Input(shape = (train_X.shape[1], train_X.shape[2]))\n",
    "    \n",
    "#     initializer = tf.keras.initializers.RandomUniform()\n",
    "#     c10 = Conv1D(64,11, strides=1, activation='relu', padding = 'same')(inputs)\n",
    "#     c1 = BatchNormalization()(c10)\n",
    "#     #c1 = MaxPooling1D(4,strides=2, padding = 'same')(c1)\n",
    "#     #c1 = Dropout(0.1)(c1)\n",
    "    \n",
    "#     u1 = concatenate([inputs, c1])\n",
    "#     c2 = Conv1D(32,7, strides=1, activation='relu', padding = 'same')(u1)\n",
    "#     c2 = BatchNormalization()(c2)\n",
    "#     u6 = concatenate([u1, c2])\n",
    "\n",
    "#     #c2 = MaxPooling1D(4,strides=2)(c2)\n",
    "#     #c2 = Dropout(0.25)(c2)\n",
    "# #     c2 = Conv1D(32,5, strides=1, activation='relu', padding = 'same')(u6)\n",
    "# #     c2 = BatchNormalization()(c2)\n",
    "# #     u7 = concatenate([u6, c2])\n",
    "\n",
    "\n",
    "# #     c2 = MaxPooling1D(4,strides=2)(u7)\n",
    "# #     c2 = Dropout(0.30)(c2)\n",
    "\n",
    "#     # c3 = LSTM(5, activation='relu', return_sequences=True)(c2)\n",
    "#     c3=Bidirectional(LSTM(30, return_sequences=True))(u6)\n",
    "\n",
    "#     fc = Flatten()(c3)\n",
    "#     #fc0 = Dense(16, activation='relu')(fc)\n",
    "#     #R1=RandomFourierFeatures(300, kernel_initializer=\"gaussian\")(fc)\n",
    "    \n",
    "    \n",
    "#     fc1 = Dense(16, activation='relu',kernel_initializer='glorot_uniform',\n",
    "#     bias_initializer='zeros')(fc)\n",
    "#     fc1=Dropout(0.2)(fc1)\n",
    "#     fc1 = Dense(8, activation='relu',kernel_initializer='glorot_uniform',\n",
    "#     bias_initializer='zeros')(fc1)\n",
    "\n",
    "#     predictions = Dense(1, activation='sigmoid')(fc1)\n",
    "    \n",
    "#     model = Model(inputs = inputs, outputs = predictions)\n",
    "#     print(\"model\")\n",
    "#     model.compile(optimizer = 'RMSprop',\n",
    "#                   loss = 'binary_crossentropy',\n",
    "#                   metrics = METRICS)\n",
    "#     print(\"compile\")\n",
    "#     model.fit(train_X, train_Y, epochs = epoch, batch_size = 32, validation_data = (test_X, test_Y), shuffle = True)\n",
    "#     model.save('CNN_model.h5')\n",
    "#     pre_test_y = model.predict(test_X, batch_size = 32)\n",
    "#     pre_train_y = model.predict(train_X, batch_size = 32)\n",
    "#     test_auc = metrics.roc_auc_score(test_Y, pre_test_y)\n",
    "#     train_auc = metrics.roc_auc_score(train_Y, pre_train_y)\n",
    "#     print(\"train_auc: \", train_auc)\n",
    "#     print(\"test_auc: \", test_auc) \n",
    "#     return test_auc\n",
    "\n",
    "\n",
    "\n",
    "# def dnn_model(train_X, train_Y, test_X, test_Y, lr, epoch, batch_size):\n",
    "#     train_X = np.expand_dims(train_X, 2)\n",
    "#     test_X = np.expand_dims(test_X, 2)\n",
    "#     inputs = Input(shape = (train_X.shape[1], train_X.shape[2]))\n",
    "#     x = Conv1D(32, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu')(inputs)\n",
    "\n",
    "#     x = MaxPooling1D(pool_size = 2, strides = 2, padding = 'same')(x)\n",
    "#     x = Flatten()(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "    \n",
    "#     x = Dense(32, activation = 'relu')(x)\n",
    "#     x = Dense(16, activation = 'relu')(x)\n",
    "#     x = Dense(8, activation = 'relu')(x)\n",
    "#     predictions = Dense(1, activation = 'sigmoid')(x)\n",
    "#     model = Model(inputs = inputs, outputs = predictions)\n",
    "#     print(\"model\")\n",
    "#     model.compile(optimizer = 'RMSprop',\n",
    "#                   loss = 'binary_crossentropy',\n",
    "#                   metrics = METRICS)\n",
    "#     print(\"compile\")\n",
    "#     model.fit(train_X, train_Y, epochs = epoch, batch_size = 32, validation_data = (test_X, test_Y), shuffle = True)\n",
    "#     model.save('CNN_model.h5')\n",
    "#     pre_test_y = model.predict(test_X, batch_size = 64)\n",
    "#     pre_train_y = model.predict(train_X, batch_size = 64)\n",
    "#     test_auc = metrics.roc_auc_score(test_Y, pre_test_y)\n",
    "#     train_auc = metrics.roc_auc_score(train_Y, pre_train_y)\n",
    "#     print(\"train_auc: \", train_auc)\n",
    "#     print(\"test_auc: \", test_auc) \n",
    "#     return test_auc\n",
    "\n",
    "# #working\n",
    "# def dnn_model(train_X, train_Y, test_X, test_Y, lr, epoch, batch_size):\n",
    "#     train_X = np.expand_dims(train_X, 2)\n",
    "#     test_X = np.expand_dims(test_X, 2)\n",
    "#     inputs = Input(shape = (train_X.shape[1], train_X.shape[2]))\n",
    "#     x = Conv1D(32, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu')(inputs)\n",
    "#     x1 = Conv1D(32, kernel_size=3, strides = 1, padding = 'same', activation = 'relu')(x)\n",
    "#     x = concatenate([inputs, x])\n",
    "#     # x = MaxPooling1D(pool_size = 2, strides = 2, padding = 'same')(x)\n",
    "#     x = Flatten()(x)\n",
    "#     x1= Flatten()(x1)\n",
    "#     x = Dropout(0.2)(x)\n",
    "    \n",
    "#     x = Dense(32, activation = 'relu')(x)\n",
    "#     x1 = Dense(32)(x1)\n",
    "#     x = Dense(16, activation = 'relu')(x+x1)\n",
    "#     x = Dense(8, activation = 'relu')(x)\n",
    "#     predictions = Dense(1, activation = 'sigmoid')(x)\n",
    "#     model = Model(inputs = inputs, outputs = predictions)\n",
    "#     print(\"model\")\n",
    "#     model.compile(optimizer = 'RMSprop',\n",
    "#                   loss = 'binary_crossentropy',\n",
    "#                   metrics = METRICS)\n",
    "#     print(\"compile\")\n",
    "#     model.fit(train_X, train_Y, epochs = epoch, batch_size = 32, validation_data = (test_X, test_Y), shuffle = True)\n",
    "#     model.save('CNN_model.h5')\n",
    "#     pre_test_y = model.predict(test_X, batch_size = 32)\n",
    "#     pre_train_y = model.predict(train_X, batch_size = 32)\n",
    "#     test_auc = metrics.roc_auc_score(test_Y, pre_test_y)\n",
    "#     train_auc = metrics.roc_auc_score(train_Y, pre_train_y)\n",
    "#     print(\"train_auc: \", train_auc)\n",
    "#     print(\"test_auc: \", test_auc) \n",
    "#     return test_auc\n",
    "\n",
    "\n",
    "# def dnn_model(train_X, train_Y, test_X, test_Y, lr, epoch, batch_size):\n",
    "#     train_X = np.expand_dims(train_X, 2)\n",
    "#     test_X = np.expand_dims(test_X, 2)\n",
    "#     inputs = Input(shape = (train_X.shape[1], train_X.shape[2]))\n",
    "#     x = Conv1D(32, kernel_size = 5, strides = 1, padding = 'same', activation = 'relu')(inputs)\n",
    "    \n",
    "#     x2 = Conv1D(32, kernel_size=10, strides = 1, padding = 'same', activation = 'relu')(x)\n",
    "#     x = concatenate([inputs, x])\n",
    "    \n",
    "#     x1 = Conv1D(32, kernel_size=8, strides = 1, padding = 'same', activation = 'relu')(x)\n",
    "#     x1 = concatenate([inputs, x1])\n",
    "#     # x = MaxPooling1D(pool_size = 2, strides = 2, padding = 'same')(x)\n",
    "#     x = Flatten()(x)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     x1= Flatten()(x1)\n",
    "#     x1= Dropout(0.2)(x1)\n",
    "#     x2 = Flatten()(x2)\n",
    "    \n",
    "#     print(x.get_shape(), x2.get_shape(), x1.get_shape())\n",
    "#     x = Dense(32, activation = 'relu')(x)\n",
    "#     x1 = Dense(32)(x1)\n",
    "#     x2=Dense(16)(x2)\n",
    "#     x = concatenate([x, x1])\n",
    "#     # x = Dense(16, activation = 'relu')(x)\n",
    "#     # x = Dropout(0.2)(x)\n",
    "#     x = concatenate([x, x2])\n",
    "#     # x = Dense(8, activation = 'relu')(x)\n",
    "#     predictions = Dense(1, activation = 'sigmoid')(x)\n",
    "#     model = Model(inputs = inputs, outputs = predictions)\n",
    "#     print(\"model\")\n",
    "#     model.compile(optimizer = 'RMSprop',\n",
    "#                   loss = 'binary_crossentropy',\n",
    "#                   metrics = METRICS)\n",
    "#     print(\"compile\")\n",
    "#     model.fit(train_X, train_Y, epochs = epoch, batch_size = 32, validation_data = (test_X, test_Y), shuffle = True)\n",
    "#     model.save('CNN_model.h5')\n",
    "#     pre_test_y = model.predict(test_X, batch_size = 32)\n",
    "#     pre_train_y = model.predict(train_X, batch_size = 32)\n",
    "#     test_auc = metrics.roc_auc_score(test_Y, pre_test_y)\n",
    "#     train_auc = metrics.roc_auc_score(train_Y, pre_train_y)\n",
    "#     print(\"train_auc: \", train_auc)\n",
    "#     print(\"test_auc: \", test_auc) \n",
    "#     return test_auc\n",
    "\n",
    "# # 97.5\n",
    "# def dnn_model(train_X, train_Y, test_X, test_Y, lr, epoch, batch_size):\n",
    "#     train_X = np.expand_dims(train_X, 2)\n",
    "#     test_X = np.expand_dims(test_X, 2)\n",
    "#     inputs = Input(shape = (train_X.shape[1], train_X.shape[2]))\n",
    "#     x = Conv1D(32, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu')(inputs)\n",
    "#     x1 = Conv1D(32, kernel_size=3, strides = 1, padding = 'same', activation = 'relu')(x)\n",
    "#     x2 = Conv1D(32, kernel_size=3, strides = 1, padding = 'same', activation = 'relu')(x)\n",
    "#     x = concatenate([inputs, x])\n",
    "#     # x = MaxPooling1D(pool_size = 2, strides = 2, padding = 'same')(x)\n",
    "#     x = Flatten()(x)\n",
    "#     x1= Flatten()(x1)\n",
    "#     x2 = Flatten()(x2)\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     print(x.get_shape(), x2.get_shape(), x1.get_shape())\n",
    "#     x = Dense(32, activation = 'relu')(x)\n",
    "#     x1 = Dense(32)(x1)\n",
    "#     x2=Dense(16)(x2)\n",
    "    \n",
    "#     x = Dense(16, activation = 'relu')(x+x1)\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     # x = Dense(8, activation = 'relu')(x)\n",
    "#     predictions = Dense(1, activation = 'sigmoid')(x+x2)\n",
    "#     model = Model(inputs = inputs, outputs = predictions)\n",
    "#     print(\"model\")\n",
    "#     model.compile(optimizer = 'SGD',\n",
    "#                   loss = 'binary_crossentropy',\n",
    "#                   metrics = ['acc',precision,recall,f1,TP,FN,TN,FP])\n",
    "#     print(\"compile\")\n",
    "#     model.fit(train_X, train_Y, epochs = epoch, batch_size = 32, validation_data = (test_X, test_Y), shuffle = True)\n",
    "#     model.save('CNN_model.h5')\n",
    "#     pre_test_y = model.predict(test_X, batch_size = 50)\n",
    "#     pre_train_y = model.predict(train_X, batch_size = 50)\n",
    "#     test_auc = metrics.roc_auc_score(test_Y, pre_test_y)\n",
    "#     train_auc = metrics.roc_auc_score(train_Y, pre_train_y)\n",
    "#     print(\"train_auc: \", train_auc)\n",
    "#     print(\"test_auc: \", test_auc) \n",
    "#     return test_auc\n",
    "\n",
    "def dnn_model(train_X, train_Y, test_X, test_Y, lr, epoch, batch_size):\n",
    "    train_X = np.expand_dims(train_X, 2)\n",
    "    test_X = np.expand_dims(test_X, 2)\n",
    "    inputs = Input(shape = (train_X.shape[1], train_X.shape[2]))\n",
    "    x = Conv1D(32, kernel_size = 5, strides = 1, padding = 'same', activation = 'relu')(inputs)\n",
    "    \n",
    "    x2 = Conv1D(32, kernel_size=10, strides = 1, padding = 'same', activation = 'relu')(x)\n",
    "    x = concatenate([inputs, x])\n",
    "    \n",
    "    x1 = Conv1D(32, kernel_size=8, strides = 1, padding = 'same', activation = 'relu')(x)\n",
    "    x1 = concatenate([inputs, x1])\n",
    "    # x = MaxPooling1D(pool_size = 2, strides = 2, padding = 'same')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x1= Flatten()(x1)\n",
    "    x1= Dropout(0.2)(x1)\n",
    "    x2 = Flatten()(x2)\n",
    "    \n",
    "    print(x.get_shape(), x2.get_shape(), x1.get_shape())\n",
    "    x = Dense(32, activation = 'relu')(x)\n",
    "    x1 = Dense(32)(x1)\n",
    "    x2=Dense(16)(x2)\n",
    "    x = concatenate([x, x1])\n",
    "    # x = Dense(16, activation = 'relu')(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "    x = concatenate([x, x2])\n",
    "    # x = Dense(8, activation = 'relu')(x)\n",
    "    predictions = Dense(1, activation = 'sigmoid')(x)\n",
    "    model = Model(inputs = inputs, outputs = predictions)\n",
    "    print(\"model\")\n",
    "    model.compile(optimizer = 'RMSprop',\n",
    "                  loss = 'binary_crossentropy',\n",
    "                  metrics = METRICS)\n",
    "    print(\"compile\")\n",
    "    model.fit(train_X, train_Y, epochs = epoch, batch_size = 32, validation_data = (test_X, test_Y), shuffle = True)\n",
    "    model.save('CNN_model.h5')\n",
    "    pre_test_y = model.predict(test_X, batch_size = 32)\n",
    "    pre_train_y = model.predict(train_X, batch_size = 32)\n",
    "    test_auc = metrics.roc_auc_score(test_Y, pre_test_y)\n",
    "    train_auc = metrics.roc_auc_score(train_Y, pre_train_y)\n",
    "    print(\"train_auc: \", train_auc)\n",
    "    print(\"test_auc: \", test_auc) \n",
    "    return test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5989, 200)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4192, 201)\n",
      "[[ 0.42737314 -0.00844267 -0.07556029 ... -0.5584215   0.05574878\n",
      "   0.23070288]\n",
      " [-2.3575263   1.4653926   0.5859087  ... -0.9385753   0.00256922\n",
      "   0.68821007]\n",
      " [-0.13512018  0.73815346 -0.18643889 ... -0.2936646   0.4673324\n",
      "  -0.6097265 ]\n",
      " ...\n",
      " [ 0.4745338  -0.25370017 -0.01347908 ... -0.71547806  0.1640001\n",
      "   0.15439436]\n",
      " [ 0.8306756  -0.75936556 -0.17794256 ...  0.914954   -0.191713\n",
      "  -1.2552228 ]\n",
      " [ 1.1189892  -0.5882476  -0.8425228  ...  1.0908928   0.26875666\n",
      "  -1.3071417 ]]\n",
      "X.shape:  (4192, 200)\n",
      "Y.shape:  (4192,)\n",
      "\n",
      "\n",
      "i:  0\n",
      "(None, 6600) (None, 6400) (None, 6600)\n",
      "model\n",
      "compile\n",
      "Epoch 1/10\n",
      "105/105 [==============================] - 2s 8ms/step - loss: 0.5029 - tp: 2531.0000 - fp: 655.0000 - tn: 916.0000 - fn: 449.0000 - accuracy: 0.7574 - precision: 0.7944 - recall: 0.8493 - auc: 0.8391 - val_loss: 0.4524 - val_tp: 532.0000 - val_fp: 119.0000 - val_tn: 93.0000 - val_fn: 95.0000 - val_accuracy: 0.7449 - val_precision: 0.8172 - val_recall: 0.8485 - val_auc: 0.7969\n",
      "Epoch 2/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.4657 - tp: 2002.0000 - fp: 512.0000 - tn: 474.0000 - fn: 365.0000 - accuracy: 0.7384 - precision: 0.7963 - recall: 0.8458 - auc: 0.8059 - val_loss: 0.4587 - val_tp: 575.0000 - val_fp: 158.0000 - val_tn: 54.0000 - val_fn: 52.0000 - val_accuracy: 0.7497 - val_precision: 0.7844 - val_recall: 0.9171 - val_auc: 0.7990\n",
      "Epoch 3/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.4546 - tp: 1998.0000 - fp: 482.0000 - tn: 504.0000 - fn: 369.0000 - accuracy: 0.7462 - precision: 0.8056 - recall: 0.8441 - auc: 0.8176 - val_loss: 0.4477 - val_tp: 590.0000 - val_fp: 177.0000 - val_tn: 35.0000 - val_fn: 37.0000 - val_accuracy: 0.7449 - val_precision: 0.7692 - val_recall: 0.9410 - val_auc: 0.8024\n",
      "Epoch 4/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.4396 - tp: 2015.0000 - fp: 459.0000 - tn: 527.0000 - fn: 352.0000 - accuracy: 0.7581 - precision: 0.8145 - recall: 0.8513 - auc: 0.8302 - val_loss: 0.4716 - val_tp: 489.0000 - val_fp: 71.0000 - val_tn: 141.0000 - val_fn: 138.0000 - val_accuracy: 0.7509 - val_precision: 0.8732 - val_recall: 0.7799 - val_auc: 0.8061\n",
      "Epoch 5/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.4290 - tp: 2021.0000 - fp: 425.0000 - tn: 561.0000 - fn: 346.0000 - accuracy: 0.7701 - precision: 0.8262 - recall: 0.8538 - auc: 0.8431 - val_loss: 0.4566 - val_tp: 508.0000 - val_fp: 82.0000 - val_tn: 130.0000 - val_fn: 119.0000 - val_accuracy: 0.7604 - val_precision: 0.8610 - val_recall: 0.8102 - val_auc: 0.8062\n",
      "Epoch 6/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.4167 - tp: 2039.0000 - fp: 390.0000 - tn: 596.0000 - fn: 328.0000 - accuracy: 0.7859 - precision: 0.8394 - recall: 0.8614 - auc: 0.8551 - val_loss: 0.4735 - val_tp: 479.0000 - val_fp: 70.0000 - val_tn: 142.0000 - val_fn: 148.0000 - val_accuracy: 0.7402 - val_precision: 0.8725 - val_recall: 0.7640 - val_auc: 0.8034\n",
      "Epoch 7/10\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.3994 - tp: 2049.0000 - fp: 367.0000 - tn: 619.0000 - fn: 318.0000 - accuracy: 0.7957 - precision: 0.8481 - recall: 0.8657 - auc: 0.8683 - val_loss: 0.4709 - val_tp: 565.0000 - val_fp: 154.0000 - val_tn: 58.0000 - val_fn: 62.0000 - val_accuracy: 0.7426 - val_precision: 0.7858 - val_recall: 0.9011 - val_auc: 0.7990\n",
      "Epoch 8/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.3884 - tp: 2069.0000 - fp: 359.0000 - tn: 627.0000 - fn: 298.0000 - accuracy: 0.8041 - precision: 0.8521 - recall: 0.8741 - auc: 0.8779 - val_loss: 0.4788 - val_tp: 565.0000 - val_fp: 157.0000 - val_tn: 55.0000 - val_fn: 62.0000 - val_accuracy: 0.7390 - val_precision: 0.7825 - val_recall: 0.9011 - val_auc: 0.7990\n",
      "Epoch 9/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.3645 - tp: 2087.0000 - fp: 327.0000 - tn: 659.0000 - fn: 280.0000 - accuracy: 0.8190 - precision: 0.8645 - recall: 0.8817 - auc: 0.8940 - val_loss: 0.5071 - val_tp: 488.0000 - val_fp: 73.0000 - val_tn: 139.0000 - val_fn: 139.0000 - val_accuracy: 0.7473 - val_precision: 0.8699 - val_recall: 0.7783 - val_auc: 0.7919\n",
      "Epoch 10/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.3486 - tp: 2102.0000 - fp: 296.0000 - tn: 690.0000 - fn: 265.0000 - accuracy: 0.8327 - precision: 0.8766 - recall: 0.8880 - auc: 0.9048 - val_loss: 0.5069 - val_tp: 509.0000 - val_fp: 102.0000 - val_tn: 110.0000 - val_fn: 118.0000 - val_accuracy: 0.7378 - val_precision: 0.8331 - val_recall: 0.8118 - val_auc: 0.7787\n",
      "27/27 [==============================] - 0s 1ms/step\n",
      "105/105 [==============================] - 0s 1ms/step\n",
      "train_auc:  0.9407745616493178\n",
      "test_auc:  0.7789375883963768\n",
      "\n",
      "\n",
      "i:  1\n",
      "(None, 6600) (None, 6400) (None, 6600)\n",
      "model\n",
      "compile\n",
      "Epoch 1/10\n",
      "105/105 [==============================] - 2s 8ms/step - loss: 0.5001 - tp: 2591.0000 - fp: 665.0000 - tn: 484.0000 - fn: 452.0000 - accuracy: 0.7335 - precision: 0.7958 - recall: 0.8515 - auc: 0.7760 - val_loss: 0.4969 - val_tp: 419.0000 - val_fp: 71.0000 - val_tn: 190.0000 - val_fn: 159.0000 - val_accuracy: 0.7259 - val_precision: 0.8551 - val_recall: 0.7249 - val_auc: 0.7953\n",
      "Epoch 2/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.4582 - tp: 2093.0000 - fp: 529.0000 - tn: 408.0000 - fn: 323.0000 - accuracy: 0.7459 - precision: 0.7982 - recall: 0.8663 - auc: 0.8075 - val_loss: 0.4958 - val_tp: 559.0000 - val_fp: 240.0000 - val_tn: 21.0000 - val_fn: 19.0000 - val_accuracy: 0.6913 - val_precision: 0.6996 - val_recall: 0.9671 - val_auc: 0.7953\n",
      "Epoch 3/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.4392 - tp: 2120.0000 - fp: 483.0000 - tn: 454.0000 - fn: 296.0000 - accuracy: 0.7677 - precision: 0.8144 - recall: 0.8775 - auc: 0.8279 - val_loss: 0.5135 - val_tp: 517.0000 - val_fp: 173.0000 - val_tn: 88.0000 - val_fn: 61.0000 - val_accuracy: 0.7211 - val_precision: 0.7493 - val_recall: 0.8945 - val_auc: 0.8009\n",
      "Epoch 4/10\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.4316 - tp: 2109.0000 - fp: 465.0000 - tn: 472.0000 - fn: 307.0000 - accuracy: 0.7698 - precision: 0.8193 - recall: 0.8729 - auc: 0.8359 - val_loss: 0.4830 - val_tp: 436.0000 - val_fp: 94.0000 - val_tn: 167.0000 - val_fn: 142.0000 - val_accuracy: 0.7187 - val_precision: 0.8226 - val_recall: 0.7543 - val_auc: 0.7953\n",
      "Epoch 5/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.4157 - tp: 2106.0000 - fp: 428.0000 - tn: 509.0000 - fn: 310.0000 - accuracy: 0.7799 - precision: 0.8311 - recall: 0.8717 - auc: 0.8485 - val_loss: 0.4952 - val_tp: 495.0000 - val_fp: 157.0000 - val_tn: 104.0000 - val_fn: 83.0000 - val_accuracy: 0.7139 - val_precision: 0.7592 - val_recall: 0.8564 - val_auc: 0.7840\n",
      "Epoch 6/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.4009 - tp: 2128.0000 - fp: 400.0000 - tn: 537.0000 - fn: 288.0000 - accuracy: 0.7948 - precision: 0.8418 - recall: 0.8808 - auc: 0.8635 - val_loss: 0.4904 - val_tp: 492.0000 - val_fp: 167.0000 - val_tn: 94.0000 - val_fn: 86.0000 - val_accuracy: 0.6985 - val_precision: 0.7466 - val_recall: 0.8512 - val_auc: 0.7826\n",
      "Epoch 7/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.3814 - tp: 2138.0000 - fp: 371.0000 - tn: 566.0000 - fn: 278.0000 - accuracy: 0.8064 - precision: 0.8521 - recall: 0.8849 - auc: 0.8789 - val_loss: 0.5106 - val_tp: 489.0000 - val_fp: 151.0000 - val_tn: 110.0000 - val_fn: 89.0000 - val_accuracy: 0.7139 - val_precision: 0.7641 - val_recall: 0.8460 - val_auc: 0.7809\n",
      "Epoch 8/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.3627 - tp: 2161.0000 - fp: 321.0000 - tn: 616.0000 - fn: 255.0000 - accuracy: 0.8282 - precision: 0.8707 - recall: 0.8945 - auc: 0.8944 - val_loss: 0.5207 - val_tp: 479.0000 - val_fp: 150.0000 - val_tn: 111.0000 - val_fn: 99.0000 - val_accuracy: 0.7032 - val_precision: 0.7615 - val_recall: 0.8287 - val_auc: 0.7783\n",
      "Epoch 9/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.3443 - tp: 2187.0000 - fp: 314.0000 - tn: 623.0000 - fn: 229.0000 - accuracy: 0.8381 - precision: 0.8745 - recall: 0.9052 - auc: 0.9069 - val_loss: 0.5539 - val_tp: 410.0000 - val_fp: 80.0000 - val_tn: 181.0000 - val_fn: 168.0000 - val_accuracy: 0.7044 - val_precision: 0.8367 - val_recall: 0.7093 - val_auc: 0.7757\n",
      "Epoch 10/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.3220 - tp: 2182.0000 - fp: 278.0000 - tn: 659.0000 - fn: 234.0000 - accuracy: 0.8473 - precision: 0.8870 - recall: 0.9031 - auc: 0.9187 - val_loss: 0.5639 - val_tp: 502.0000 - val_fp: 170.0000 - val_tn: 91.0000 - val_fn: 76.0000 - val_accuracy: 0.7068 - val_precision: 0.7470 - val_recall: 0.8685 - val_auc: 0.7770\n",
      "27/27 [==============================] - 0s 1ms/step\n",
      "105/105 [==============================] - 0s 1ms/step\n",
      "train_auc:  0.9555590796327579\n",
      "test_auc:  0.7772541065107584\n",
      "\n",
      "\n",
      "i:  2\n",
      "(None, 6600) (None, 6400) (None, 6600)\n",
      "model\n",
      "compile\n",
      "Epoch 1/10\n",
      "105/105 [==============================] - 2s 8ms/step - loss: 0.5134 - tp: 2509.0000 - fp: 716.0000 - tn: 508.0000 - fn: 460.0000 - accuracy: 0.7195 - precision: 0.7780 - recall: 0.8451 - auc: 0.7626 - val_loss: 0.4986 - val_tp: 598.0000 - val_fp: 226.0000 - val_tn: 9.0000 - val_fn: 5.0000 - val_accuracy: 0.7243 - val_precision: 0.7257 - val_recall: 0.9917 - val_auc: 0.7638\n",
      "Epoch 2/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.4744 - tp: 2049.0000 - fp: 563.0000 - tn: 400.0000 - fn: 342.0000 - accuracy: 0.7302 - precision: 0.7845 - recall: 0.8570 - auc: 0.7936 - val_loss: 0.4297 - val_tp: 555.0000 - val_fp: 157.0000 - val_tn: 78.0000 - val_fn: 48.0000 - val_accuracy: 0.7554 - val_precision: 0.7795 - val_recall: 0.9204 - val_auc: 0.8303\n",
      "Epoch 3/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.4563 - tp: 2081.0000 - fp: 528.0000 - tn: 435.0000 - fn: 310.0000 - accuracy: 0.7501 - precision: 0.7976 - recall: 0.8703 - auc: 0.8130 - val_loss: 0.4250 - val_tp: 486.0000 - val_fp: 94.0000 - val_tn: 141.0000 - val_fn: 117.0000 - val_accuracy: 0.7482 - val_precision: 0.8379 - val_recall: 0.8060 - val_auc: 0.8304\n",
      "Epoch 4/10\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.4474 - tp: 2056.0000 - fp: 470.0000 - tn: 493.0000 - fn: 335.0000 - accuracy: 0.7600 - precision: 0.8139 - recall: 0.8599 - auc: 0.8246 - val_loss: 0.4421 - val_tp: 575.0000 - val_fp: 190.0000 - val_tn: 45.0000 - val_fn: 28.0000 - val_accuracy: 0.7399 - val_precision: 0.7516 - val_recall: 0.9536 - val_auc: 0.8208\n",
      "Epoch 5/10\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.4339 - tp: 2073.0000 - fp: 468.0000 - tn: 495.0000 - fn: 318.0000 - accuracy: 0.7657 - precision: 0.8158 - recall: 0.8670 - auc: 0.8341 - val_loss: 0.4264 - val_tp: 495.0000 - val_fp: 100.0000 - val_tn: 135.0000 - val_fn: 108.0000 - val_accuracy: 0.7518 - val_precision: 0.8319 - val_recall: 0.8209 - val_auc: 0.8331\n",
      "Epoch 6/10\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.4227 - tp: 2084.0000 - fp: 441.0000 - tn: 522.0000 - fn: 307.0000 - accuracy: 0.7770 - precision: 0.8253 - recall: 0.8716 - auc: 0.8471 - val_loss: 0.4291 - val_tp: 472.0000 - val_fp: 77.0000 - val_tn: 158.0000 - val_fn: 131.0000 - val_accuracy: 0.7518 - val_precision: 0.8597 - val_recall: 0.7828 - val_auc: 0.8277\n",
      "Epoch 7/10\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.4105 - tp: 2075.0000 - fp: 390.0000 - tn: 573.0000 - fn: 316.0000 - accuracy: 0.7895 - precision: 0.8418 - recall: 0.8678 - auc: 0.8574 - val_loss: 0.4696 - val_tp: 568.0000 - val_fp: 185.0000 - val_tn: 50.0000 - val_fn: 35.0000 - val_accuracy: 0.7375 - val_precision: 0.7543 - val_recall: 0.9420 - val_auc: 0.8052\n",
      "Epoch 8/10\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.3884 - tp: 2118.0000 - fp: 376.0000 - tn: 587.0000 - fn: 273.0000 - accuracy: 0.8065 - precision: 0.8492 - recall: 0.8858 - auc: 0.8773 - val_loss: 0.4555 - val_tp: 515.0000 - val_fp: 132.0000 - val_tn: 103.0000 - val_fn: 88.0000 - val_accuracy: 0.7375 - val_precision: 0.7960 - val_recall: 0.8541 - val_auc: 0.8050\n",
      "Epoch 9/10\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.3674 - tp: 2118.0000 - fp: 347.0000 - tn: 616.0000 - fn: 273.0000 - accuracy: 0.8151 - precision: 0.8592 - recall: 0.8858 - auc: 0.8914 - val_loss: 0.4588 - val_tp: 508.0000 - val_fp: 126.0000 - val_tn: 109.0000 - val_fn: 95.0000 - val_accuracy: 0.7363 - val_precision: 0.8013 - val_recall: 0.8425 - val_auc: 0.8156\n",
      "Epoch 10/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.3532 - tp: 2137.0000 - fp: 318.0000 - tn: 645.0000 - fn: 254.0000 - accuracy: 0.8295 - precision: 0.8705 - recall: 0.8938 - auc: 0.9020 - val_loss: 0.4875 - val_tp: 546.0000 - val_fp: 173.0000 - val_tn: 62.0000 - val_fn: 57.0000 - val_accuracy: 0.7255 - val_precision: 0.7594 - val_recall: 0.9055 - val_auc: 0.7971\n",
      "27/27 [==============================] - 0s 1ms/step\n",
      "105/105 [==============================] - 0s 1ms/step\n",
      "train_auc:  0.9393980455437555\n",
      "test_auc:  0.7979040965385836\n",
      "\n",
      "\n",
      "i:  3\n",
      "(None, 6600) (None, 6400) (None, 6600)\n",
      "model\n",
      "compile\n",
      "Epoch 1/10\n",
      "105/105 [==============================] - 2s 8ms/step - loss: 0.5016 - tp: 2569.0000 - fp: 750.0000 - tn: 435.0000 - fn: 438.0000 - accuracy: 0.7166 - precision: 0.7740 - recall: 0.8543 - auc: 0.7695 - val_loss: 0.4819 - val_tp: 515.0000 - val_fp: 162.0000 - val_tn: 86.0000 - val_fn: 75.0000 - val_accuracy: 0.7172 - val_precision: 0.7607 - val_recall: 0.8729 - val_auc: 0.7865\n",
      "Epoch 2/10\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.4601 - tp: 2065.0000 - fp: 519.0000 - tn: 431.0000 - fn: 339.0000 - accuracy: 0.7442 - precision: 0.7991 - recall: 0.8590 - auc: 0.8065 - val_loss: 0.4764 - val_tp: 458.0000 - val_fp: 86.0000 - val_tn: 162.0000 - val_fn: 132.0000 - val_accuracy: 0.7399 - val_precision: 0.8419 - val_recall: 0.7763 - val_auc: 0.8051\n",
      "Epoch 3/10\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.4458 - tp: 2060.0000 - fp: 493.0000 - tn: 457.0000 - fn: 344.0000 - accuracy: 0.7504 - precision: 0.8069 - recall: 0.8569 - auc: 0.8192 - val_loss: 0.4704 - val_tp: 482.0000 - val_fp: 113.0000 - val_tn: 135.0000 - val_fn: 108.0000 - val_accuracy: 0.7363 - val_precision: 0.8101 - val_recall: 0.8169 - val_auc: 0.8031\n",
      "Epoch 4/10\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.4357 - tp: 2067.0000 - fp: 457.0000 - tn: 493.0000 - fn: 337.0000 - accuracy: 0.7633 - precision: 0.8189 - recall: 0.8598 - auc: 0.8294 - val_loss: 0.4819 - val_tp: 524.0000 - val_fp: 181.0000 - val_tn: 67.0000 - val_fn: 66.0000 - val_accuracy: 0.7053 - val_precision: 0.7433 - val_recall: 0.8881 - val_auc: 0.7868\n",
      "Epoch 5/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.4264 - tp: 2095.0000 - fp: 472.0000 - tn: 478.0000 - fn: 309.0000 - accuracy: 0.7671 - precision: 0.8161 - recall: 0.8715 - auc: 0.8392 - val_loss: 0.4863 - val_tp: 473.0000 - val_fp: 102.0000 - val_tn: 146.0000 - val_fn: 117.0000 - val_accuracy: 0.7387 - val_precision: 0.8226 - val_recall: 0.8017 - val_auc: 0.7939\n",
      "Epoch 6/10\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.4111 - tp: 2075.0000 - fp: 412.0000 - tn: 538.0000 - fn: 329.0000 - accuracy: 0.7791 - precision: 0.8343 - recall: 0.8631 - auc: 0.8523 - val_loss: 0.4820 - val_tp: 496.0000 - val_fp: 135.0000 - val_tn: 113.0000 - val_fn: 94.0000 - val_accuracy: 0.7267 - val_precision: 0.7861 - val_recall: 0.8407 - val_auc: 0.7943\n",
      "Epoch 7/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.3946 - tp: 2107.0000 - fp: 375.0000 - tn: 575.0000 - fn: 297.0000 - accuracy: 0.7996 - precision: 0.8489 - recall: 0.8765 - auc: 0.8698 - val_loss: 0.4999 - val_tp: 479.0000 - val_fp: 104.0000 - val_tn: 144.0000 - val_fn: 111.0000 - val_accuracy: 0.7434 - val_precision: 0.8216 - val_recall: 0.8119 - val_auc: 0.8053\n",
      "Epoch 8/10\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.3837 - tp: 2105.0000 - fp: 353.0000 - tn: 597.0000 - fn: 299.0000 - accuracy: 0.8056 - precision: 0.8564 - recall: 0.8756 - auc: 0.8786 - val_loss: 0.5123 - val_tp: 442.0000 - val_fp: 72.0000 - val_tn: 176.0000 - val_fn: 148.0000 - val_accuracy: 0.7375 - val_precision: 0.8599 - val_recall: 0.7492 - val_auc: 0.8033\n",
      "Epoch 9/10\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.3678 - tp: 2115.0000 - fp: 344.0000 - tn: 606.0000 - fn: 289.0000 - accuracy: 0.8113 - precision: 0.8601 - recall: 0.8798 - auc: 0.8899 - val_loss: 0.5422 - val_tp: 516.0000 - val_fp: 166.0000 - val_tn: 82.0000 - val_fn: 74.0000 - val_accuracy: 0.7136 - val_precision: 0.7566 - val_recall: 0.8746 - val_auc: 0.7926\n",
      "Epoch 10/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.3467 - tp: 2147.0000 - fp: 311.0000 - tn: 639.0000 - fn: 257.0000 - accuracy: 0.8306 - precision: 0.8735 - recall: 0.8931 - auc: 0.9035 - val_loss: 0.5268 - val_tp: 481.0000 - val_fp: 117.0000 - val_tn: 131.0000 - val_fn: 109.0000 - val_accuracy: 0.7303 - val_precision: 0.8043 - val_recall: 0.8153 - val_auc: 0.7918\n",
      "27/27 [==============================] - 0s 1ms/step\n",
      "105/105 [==============================] - 0s 1ms/step\n",
      "train_auc:  0.9319721516770295\n",
      "test_auc:  0.792167851284855\n",
      "\n",
      "\n",
      "i:  4\n",
      "(None, 6600) (None, 6400) (None, 6600)\n",
      "model\n",
      "compile\n",
      "Epoch 1/10\n",
      "105/105 [==============================] - 2s 8ms/step - loss: 0.5043 - tp: 2496.0000 - fp: 658.0000 - tn: 546.0000 - fn: 492.0000 - accuracy: 0.7257 - precision: 0.7914 - recall: 0.8353 - auc: 0.7716 - val_loss: 0.4868 - val_tp: 516.0000 - val_fp: 151.0000 - val_tn: 91.0000 - val_fn: 80.0000 - val_accuracy: 0.7243 - val_precision: 0.7736 - val_recall: 0.8658 - val_auc: 0.7894\n",
      "Epoch 2/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.4604 - tp: 2055.0000 - fp: 525.0000 - tn: 431.0000 - fn: 343.0000 - accuracy: 0.7412 - precision: 0.7965 - recall: 0.8570 - auc: 0.8020 - val_loss: 0.4737 - val_tp: 548.0000 - val_fp: 171.0000 - val_tn: 71.0000 - val_fn: 48.0000 - val_accuracy: 0.7387 - val_precision: 0.7622 - val_recall: 0.9195 - val_auc: 0.8049\n",
      "Epoch 3/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.4471 - tp: 2042.0000 - fp: 517.0000 - tn: 439.0000 - fn: 356.0000 - accuracy: 0.7397 - precision: 0.7980 - recall: 0.8515 - auc: 0.8157 - val_loss: 0.4775 - val_tp: 471.0000 - val_fp: 81.0000 - val_tn: 161.0000 - val_fn: 125.0000 - val_accuracy: 0.7542 - val_precision: 0.8533 - val_recall: 0.7903 - val_auc: 0.8060\n",
      "Epoch 4/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.4313 - tp: 2060.0000 - fp: 453.0000 - tn: 503.0000 - fn: 338.0000 - accuracy: 0.7642 - precision: 0.8197 - recall: 0.8590 - auc: 0.8336 - val_loss: 0.4978 - val_tp: 518.0000 - val_fp: 137.0000 - val_tn: 105.0000 - val_fn: 78.0000 - val_accuracy: 0.7434 - val_precision: 0.7908 - val_recall: 0.8691 - val_auc: 0.8023\n",
      "Epoch 5/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.4219 - tp: 2076.0000 - fp: 434.0000 - tn: 522.0000 - fn: 322.0000 - accuracy: 0.7746 - precision: 0.8271 - recall: 0.8657 - auc: 0.8432 - val_loss: 0.4807 - val_tp: 465.0000 - val_fp: 81.0000 - val_tn: 161.0000 - val_fn: 131.0000 - val_accuracy: 0.7470 - val_precision: 0.8516 - val_recall: 0.7802 - val_auc: 0.8091\n",
      "Epoch 6/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.4083 - tp: 2066.0000 - fp: 399.0000 - tn: 557.0000 - fn: 332.0000 - accuracy: 0.7821 - precision: 0.8381 - recall: 0.8616 - auc: 0.8546 - val_loss: 0.4755 - val_tp: 500.0000 - val_fp: 109.0000 - val_tn: 133.0000 - val_fn: 96.0000 - val_accuracy: 0.7554 - val_precision: 0.8210 - val_recall: 0.8389 - val_auc: 0.8106\n",
      "Epoch 7/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.3950 - tp: 2076.0000 - fp: 373.0000 - tn: 583.0000 - fn: 322.0000 - accuracy: 0.7928 - precision: 0.8477 - recall: 0.8657 - auc: 0.8665 - val_loss: 0.4914 - val_tp: 509.0000 - val_fp: 113.0000 - val_tn: 129.0000 - val_fn: 87.0000 - val_accuracy: 0.7613 - val_precision: 0.8183 - val_recall: 0.8540 - val_auc: 0.8078\n",
      "Epoch 8/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.3774 - tp: 2124.0000 - fp: 340.0000 - tn: 616.0000 - fn: 274.0000 - accuracy: 0.8169 - precision: 0.8620 - recall: 0.8857 - auc: 0.8841 - val_loss: 0.4946 - val_tp: 484.0000 - val_fp: 103.0000 - val_tn: 139.0000 - val_fn: 112.0000 - val_accuracy: 0.7434 - val_precision: 0.8245 - val_recall: 0.8121 - val_auc: 0.7994\n",
      "Epoch 9/10\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.3565 - tp: 2125.0000 - fp: 304.0000 - tn: 652.0000 - fn: 273.0000 - accuracy: 0.8280 - precision: 0.8748 - recall: 0.8862 - auc: 0.8987 - val_loss: 0.5177 - val_tp: 508.0000 - val_fp: 118.0000 - val_tn: 124.0000 - val_fn: 88.0000 - val_accuracy: 0.7542 - val_precision: 0.8115 - val_recall: 0.8523 - val_auc: 0.8016\n",
      "Epoch 10/10\n",
      "105/105 [==============================] - 1s 5ms/step - loss: 0.3343 - tp: 2128.0000 - fp: 280.0000 - tn: 676.0000 - fn: 270.0000 - accuracy: 0.8360 - precision: 0.8837 - recall: 0.8874 - auc: 0.9121 - val_loss: 0.5257 - val_tp: 493.0000 - val_fp: 101.0000 - val_tn: 141.0000 - val_fn: 103.0000 - val_accuracy: 0.7566 - val_precision: 0.8300 - val_recall: 0.8272 - val_auc: 0.8033\n",
      "27/27 [==============================] - 0s 1ms/step\n",
      "105/105 [==============================] - 0s 1ms/step\n",
      "train_auc:  0.9368943261644118\n",
      "test_auc:  0.8047936657607189\n",
      "Mean AUC: 0.7902114616982585\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = np.array(pd.read_csv(\"6_train.csv\"))\n",
    "pos_number = 2994 # NOTE: the number of postive sample in train file\n",
    "#CNN_model = 'CNN_model.h5'\n",
    "\n",
    "print(np.shape(data))\n",
    "X1 = data[0:pos_number, 1:]\n",
    "Y1 = data[0:pos_number, 0]\n",
    "X2 = data[pos_number:, 1:]\n",
    "Y2 = data[pos_number:, 0]\n",
    "X = np.concatenate([X1, X2], 0)\n",
    "Y = np.concatenate([Y1, Y2], 0)\n",
    "#Y = Y.reshape((Y.shape[0], -1))\n",
    "print (X)\n",
    "print (\"X.shape: \", X.shape)\n",
    "print (\"Y.shape: \", Y.shape)\n",
    "\n",
    "lr = 0.0001\n",
    "epoch = 10\n",
    "batch_size = 32\n",
    "kf = KFold(n_splits = 5, shuffle = True)\n",
    "#kf = KFold(n_splits = 5, shuffle = False)\n",
    "kf = kf.split(X)\n",
    "\n",
    "test_aucs = []\n",
    "for i, (train_fold, validate_fold) in enumerate(kf):\n",
    "    print(\"\\n\\ni: \", i)\n",
    "    test_auc = dnn_model(X[train_fold], Y[train_fold], X[validate_fold], Y[validate_fold], lr, epoch, batch_size)\n",
    "    test_aucs.append(test_auc)\n",
    "w = open(\"train_Result.txt\", \"w\")\n",
    "for j in test_aucs: \n",
    "    w.write(str(j) + ',')\n",
    "w.write('\\n')\n",
    "w.write(str(np.mean(test_aucs)) + '\\n')\n",
    "w.close()\n",
    "print(\"Mean AUC:\", str(np.mean(test_aucs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Independent Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 201)\n",
      "(899, 200) (898, 200)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(pd.read_csv(\"6_test.csv\"))\n",
    "print(data.shape)\n",
    "# pos_number = 1105 # NOTE: the number of postive sample in test file\n",
    "pos_number = 899 #3863    \n",
    "# pos_number = 1658\n",
    "X1 = data[0:pos_number, 1:]\n",
    "Y1 = data[0:pos_number, 0]\n",
    "X2 = data[pos_number:, 1:]\n",
    "Y2 = data[pos_number:, 0]\n",
    "X_test = np.concatenate([X1, X2], 0)\n",
    "Y_test = np.concatenate([Y1, Y2], 0)\n",
    "\n",
    "print(X1.shape, X2.shape)\n",
    "\n",
    "# data = np.array(pd.read_csv(\"6cross_test_data.csv\"))\n",
    "# pos_number = 1658 # NOTE: the number of postive sample in test file\n",
    "# X1 = data[0:pos_number, 1:]\n",
    "# Y1 = data[0:pos_number, 0]\n",
    "# X2 = data[pos_number:, 1:]\n",
    "# Y2 = data[pos_number:, 0]\n",
    "# X_test = np.concatenate([X1, X2], 0)\n",
    "# Y_test = np.concatenate([Y1, Y2], 0)\n",
    "\n",
    "# print(X1.shape, X2.shape)\n",
    "# print(Y1.shape, Y2.shape)\n",
    "\n",
    "lr = 0.001\n",
    "# epoch = 3\n",
    "batch_size = 32\n",
    "data = np.array(pd.read_csv(\"6_train_data.csv\"))\n",
    "pos_number = 2096 #3863 \n",
    "\n",
    "X1 = data[0:pos_number, 1:]\n",
    "Y1 = data[0:pos_number, 0]\n",
    "X2 = data[pos_number:, 1:]\n",
    "Y2 = data[pos_number:, 0]\n",
    "X = np.concatenate([X1, X2], 0)\n",
    "Y = np.concatenate([Y1, Y2], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 6600) (None, 6400) (None, 6600)\n",
      "model\n",
      "compile\n",
      "Epoch 1/6\n",
      "131/131 [==============================] - 2s 7ms/step - loss: 0.3568 - tp: 2559.0000 - fp: 678.0000 - tn: 2316.0000 - fn: 436.0000 - accuracy: 0.8140 - precision: 0.7905 - recall: 0.8544 - auc: 0.9002 - val_loss: 0.6435 - val_tp: 843.0000 - val_fp: 695.0000 - val_tn: 203.0000 - val_fn: 56.0000 - val_accuracy: 0.5821 - val_precision: 0.5481 - val_recall: 0.9377 - val_auc: 0.7622\n",
      "Epoch 2/6\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.3121 - tp: 1788.0000 - fp: 285.0000 - tn: 1811.0000 - fn: 308.0000 - accuracy: 0.8585 - precision: 0.8625 - recall: 0.8531 - auc: 0.9406 - val_loss: 0.4415 - val_tp: 775.0000 - val_fp: 178.0000 - val_tn: 720.0000 - val_fn: 124.0000 - val_accuracy: 0.8319 - val_precision: 0.8132 - val_recall: 0.8621 - val_auc: 0.9023\n",
      "Epoch 3/6\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2920 - tp: 1814.0000 - fp: 257.0000 - tn: 1839.0000 - fn: 282.0000 - accuracy: 0.8714 - precision: 0.8759 - recall: 0.8655 - auc: 0.9482 - val_loss: 0.5371 - val_tp: 872.0000 - val_fp: 502.0000 - val_tn: 396.0000 - val_fn: 27.0000 - val_accuracy: 0.7056 - val_precision: 0.6346 - val_recall: 0.9700 - val_auc: 0.8894\n",
      "Epoch 4/6\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2764 - tp: 1842.0000 - fp: 256.0000 - tn: 1840.0000 - fn: 254.0000 - accuracy: 0.8783 - precision: 0.8780 - recall: 0.8788 - auc: 0.9533 - val_loss: 0.4102 - val_tp: 723.0000 - val_fp: 152.0000 - val_tn: 746.0000 - val_fn: 176.0000 - val_accuracy: 0.8175 - val_precision: 0.8263 - val_recall: 0.8042 - val_auc: 0.8999\n",
      "Epoch 5/6\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2661 - tp: 1846.0000 - fp: 245.0000 - tn: 1851.0000 - fn: 250.0000 - accuracy: 0.8819 - precision: 0.8828 - recall: 0.8807 - auc: 0.9571 - val_loss: 0.5658 - val_tp: 873.0000 - val_fp: 499.0000 - val_tn: 399.0000 - val_fn: 26.0000 - val_accuracy: 0.7078 - val_precision: 0.6363 - val_recall: 0.9711 - val_auc: 0.8913\n",
      "Epoch 6/6\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2537 - tp: 1862.0000 - fp: 220.0000 - tn: 1876.0000 - fn: 234.0000 - accuracy: 0.8917 - precision: 0.8943 - recall: 0.8884 - auc: 0.9610 - val_loss: 1.1298 - val_tp: 895.0000 - val_fp: 831.0000 - val_tn: 67.0000 - val_fn: 4.0000 - val_accuracy: 0.5353 - val_precision: 0.5185 - val_recall: 0.9956 - val_auc: 0.8472\n",
      "57/57 [==============================] - 0s 1ms/step\n",
      "131/131 [==============================] - 0s 1ms/step\n",
      "train_auc:  0.9700200263315074\n",
      "test_auc:  0.8498665926753558\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# test_auc = dnn_model(X_train, y_train, X_test, y_test, lr, 5, 32)\n",
    "\n",
    "\n",
    "test_auc = dnn_model(X, Y, X_test, Y_test, lr, 6, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
