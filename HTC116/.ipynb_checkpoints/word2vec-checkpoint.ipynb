{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "import warnings\n",
    "from sklearn import preprocessing\n",
    "import sklearn.preprocessing\n",
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getWord_model(word,num_features,min_count, model, Unfile):\n",
    "    word_model = \"\"\n",
    "    if not os.path.isfile(model):\n",
    "        print(Unfile)\n",
    "        sentences = LineSentence(Unfile,max_sentence_length = 15000)\n",
    "\n",
    "        num_features = int(num_features)\n",
    "        min_word_count = int(min_count)\n",
    "        num_workers = 20\n",
    "        context = 20\n",
    "        downsampling = 1e-3\n",
    "        print (\"Training Word2Vec model...\")\n",
    "        word_model = Word2Vec(sentences, workers=num_workers,\\\n",
    "                        vector_size=num_features, min_count=min_word_count, \\\n",
    "                        window=context, sample=downsampling, seed=1,epochs = 50)\n",
    "        word_model.init_sims(replace=False)\n",
    "        word_model.save(model)\n",
    "\n",
    "    else:\n",
    "        print (\"Loading Word2Vec model...\")\n",
    "        word_model = Word2Vec.load(model)\n",
    "\n",
    "    return word_model\n",
    "\n",
    "def DNAToWord(dna, K):\n",
    "\n",
    "    sentence = \"\"\n",
    "    length = len(dna)\n",
    "\n",
    "    for i in range(length - K + 1):\n",
    "        sentence += dna[i: i + K] + \" \"\n",
    "\n",
    "    sentence = sentence[0 : len(sentence) - 1]\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def getDNA_split(DNAdata,word):\n",
    "\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    for DNA in DNAdata[\"seq1\"]:\n",
    "        DNA = str(DNA).upper()\n",
    "        list1.append(DNAToWord(DNA,word).split(\" \"))\n",
    "\n",
    "    for DNA in DNAdata[\"seq2\"]:\n",
    "        DNA = str(DNA).upper()\n",
    "        list2.append(DNAToWord(DNA,word).split(\" \"))\n",
    "\n",
    "    return list1,list2\n",
    "\n",
    "def getAvgFeatureVecs(DNAdata1,DNAdata2,model,num_features):\n",
    "    counter = 0\n",
    "    DNAFeatureVecs = np.zeros((len(DNAdata1),2*num_features), dtype=\"float32\")\n",
    "\n",
    "    for DNA in DNAdata1:\n",
    "        print(DNA)\n",
    "        if counter % 1000 == 0:\n",
    "            print (\"DNA %d of %d\\r\" % (counter, len(DNAdata1)))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        DNAFeatureVecs[counter][0:num_features] = np.mean(model.wv[DNA],axis = 0)\n",
    "        counter += 1\n",
    "\n",
    "    counter = 0\n",
    "    for DNA in DNAdata2:\n",
    "        if counter % 1000 == 0:\n",
    "            print (\"DNA %d of %d\\r\" % (counter, len(DNAdata2)))\n",
    "            sys.stdout.flush()\n",
    "        DNAFeatureVecs[counter][num_features:2*num_features] = np.mean(model[DNA],axis = 0)\n",
    "        counter += 1\n",
    "\n",
    "    return DNAFeatureVecs\n",
    "\n",
    "def npyTosvm(npyfile, svmfile, pos_num):\n",
    "    dataDataVecs = np.load(npyfile)\n",
    "    g = open(svmfile,'w')\n",
    "    print(len(dataDataVecs))\n",
    "    #print(dataDataVecs[0])\n",
    "    m = 0\n",
    "    for i in range(len(dataDataVecs)):\n",
    "        line = ''\n",
    "        for j in range(len(dataDataVecs[0])):\n",
    "            if j == len(dataDataVecs[0])-1:\n",
    "                line += str(j+1)+':'+str(dataDataVecs[i][j])+'\\n'\n",
    "            else:\n",
    "                line += str(j+1)+':'+str(dataDataVecs[i][j])+'\\t'\n",
    "        m += 1\n",
    "        if m < (pos_num+1):\n",
    "            g.write('1\\t'+line)\n",
    "        else:\n",
    "            g.write('0\\t'+line)\n",
    "\n",
    "def SVMtoCSV(svmfile, csvfile):\n",
    "    f = open(svmfile,'r')\n",
    "    g = open(csvfile,'w')\n",
    "    lines = f.readlines()\n",
    "    legth = len(lines[0].split(' '))-1\n",
    "    #print(legth)\n",
    "    classline = 'class'\n",
    "    for i in range(legth):\n",
    "        classline += ',%d'%(i+1)\n",
    "    g.write(classline+'\\n')\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip('\\n').split('\t')\n",
    "        g.write(line[0]+',')\n",
    "\n",
    "        legth2 = len(line[1:])\n",
    "        m = 0\n",
    "        for j in line[1:]:\n",
    "            if m == legth2-1:\n",
    "                j = j.split(':')[-1]\n",
    "                g.write(j)\n",
    "                m += 1\n",
    "            else:\n",
    "                j = j.split(':')[-1]\n",
    "                g.write(j+',')\n",
    "                m += 1\n",
    "        g.write('\\n')\n",
    "\n",
    "    f.close()\n",
    "    g.close()\n",
    "    word_model = \"\"\n",
    "    if not os.path.isfile(model):\n",
    "        sentence = LineSentence(Unfile,max_sentence_length = 15000)\n",
    "\n",
    "        num_features = int(num_features)\n",
    "        min_word_count = int(min_count)\n",
    "        num_workers = 20\n",
    "        context = 20\n",
    "        downsampling = 1e-3\n",
    "\n",
    "        print (\"Training Word2Vec model...\")\n",
    "        word_model = Word2Vec(sentence, workers=num_workers,\\\n",
    "                        vector_size=num_features, min_count=min_word_count, \\\n",
    "                        window=context, sample=downsampling, seed=1,epochs = 50)\n",
    "        word_model.init_sims(replace=False)\n",
    "        word_model.save(model)\n",
    "\n",
    "    else:\n",
    "        print (\"Loading Word2Vec model...\")\n",
    "        word_model = Word2Vec.load(model)\n",
    "\n",
    "    return word_model\n",
    "\n",
    "def DNAToWord(dna, K):\n",
    "\n",
    "    sentence = \"\"\n",
    "    length = len(dna)\n",
    "\n",
    "    for i in range(length - K + 1):\n",
    "        sentence += dna[i: i + K] + \" \"\n",
    "\n",
    "    sentence = sentence[0 : len(sentence) - 1]\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def getDNA_split(DNAdata,word):\n",
    "\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    for DNA in DNAdata[\"seq1\"]:\n",
    "        DNA = str(DNA).upper()\n",
    "        list1.append(DNAToWord(DNA,word).split(\" \"))\n",
    "\n",
    "    for DNA in DNAdata[\"seq2\"]:\n",
    "        DNA = str(DNA).upper()\n",
    "        list2.append(DNAToWord(DNA,word).split(\" \"))\n",
    "\n",
    "    return list1,list2\n",
    "\n",
    "def getAvgFeatureVecs(DNAdata1,DNAdata2,model,num_features):\n",
    "    counter = 0\n",
    "    DNAFeatureVecs = np.zeros((len(DNAdata1),2*num_features), dtype=\"float32\")\n",
    "\n",
    "    for DNA in DNAdata1:\n",
    "        if counter % 1000 == 0:\n",
    "            print (\"DNA %d of %d\\r\" % (counter, len(DNAdata1)))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        DNAFeatureVecs[counter][0:num_features] = np.mean(model.wv[DNA],axis = 0)\n",
    "        counter += 1\n",
    "    print()\n",
    "\n",
    "    counter = 0\n",
    "    for DNA in DNAdata2:\n",
    "        if counter % 1000 == 0:\n",
    "            print (\"DNA %d of %d\\r\" % (counter, len(DNAdata2)))\n",
    "            sys.stdout.flush()\n",
    "        DNAFeatureVecs[counter][num_features:2*num_features] = np.mean(model.wv[DNA],axis = 0)\n",
    "        counter += 1\n",
    "\n",
    "    return DNAFeatureVecs\n",
    "\n",
    "def npyTosvm(npyfile, svmfile, pos_num):\n",
    "    dataDataVecs = np.load(npyfile)\n",
    "    g = open(svmfile,'w')\n",
    "    print(len(dataDataVecs))\n",
    "    #print(dataDataVecs[0])\n",
    "    m = 0\n",
    "    for i in range(len(dataDataVecs)):\n",
    "        line = ''\n",
    "        for j in range(len(dataDataVecs[0])):\n",
    "            if j == len(dataDataVecs[0])-1:\n",
    "                line += str(j+1)+':'+str(dataDataVecs[i][j])+'\\n'\n",
    "            else:\n",
    "                line += str(j+1)+':'+str(dataDataVecs[i][j])+'\\t'\n",
    "        m += 1\n",
    "        if m < (pos_num+1):\n",
    "            g.write('1\\t'+line)\n",
    "        else:\n",
    "            g.write('0\\t'+line)\n",
    "\n",
    "def SVMtoCSV(svmfile, csvfile):\n",
    "    f = open(svmfile,'r')\n",
    "    g = open(csvfile,'w')\n",
    "    lines = f.readlines()\n",
    "    legth = len(lines[0].split('\t'))-1\n",
    "    #print(legth)\n",
    "    classline = 'class'\n",
    "    for i in range(legth):\n",
    "        classline += ',%d'%(i+1)\n",
    "    g.write(classline+'\\n')\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip('\\n').split('\t')\n",
    "        g.write(line[0]+',')\n",
    "\n",
    "        legth2 = len(line[1:])\n",
    "        m = 0\n",
    "        for j in line[1:]:\n",
    "            if m == legth2-1:\n",
    "                j = j.split(':')[-1]\n",
    "                g.write(j)\n",
    "                m += 1\n",
    "            else:\n",
    "                j = j.split(':')[-1]\n",
    "                g.write(j+',')\n",
    "                m += 1\n",
    "        g.write('\\n')\n",
    "\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abbasi/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Word2Vec model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmer = 6\n",
    "seqfile = 'cross_test_data.fa'\n",
    "# pos_number = 3863 # NOTE: the number of postive sample in test file\n",
    "pos_number = 1658 # cross test\n",
    "# pos_number=2994\n",
    "# pos_number=899\n",
    "\n",
    "#### generate Unsupervised ##### \n",
    "Unfile = '%dUn'%(kmer)\n",
    "g = open(Unfile,'w')\n",
    "DNAseq = pd.read_csv(seqfile,sep = \"\\t\",error_bad_lines=False)\n",
    "words1,words2 = getDNA_split(DNAseq,kmer)\n",
    "\n",
    "for i in range(len(words1)):\n",
    "    line = ' '.join(words1[i])\n",
    "    g.write(line+'\\n')\n",
    "\n",
    "for i in range(len(words2)):\n",
    "    line = ' '.join(words2[i])\n",
    "    g.write(line+'\\n')\n",
    "g.close()\n",
    "\n",
    "#####get word2vec model#####\n",
    "model = 'model_%d'%(kmer)\n",
    "fea_num = 100\n",
    "min_fea = 10\n",
    "word_model = getWord_model(kmer,fea_num,min_fea,model,Unfile)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNA 0 of 3314\n",
      "DNA 1000 of 3314\n",
      "DNA 2000 of 3314\n",
      "DNA 3000 of 3314\n",
      "\n",
      "DNA 0 of 3314\n",
      "DNA 1000 of 3314\n",
      "DNA 2000 of 3314\n",
      "DNA 3000 of 3314\n",
      "(3314, 200)\n",
      "3314\n"
     ]
    }
   ],
   "source": [
    "\n",
    "####obtain word2vec feature set####\n",
    "\n",
    "word_model = Word2Vec.load(model)\n",
    "dataDataVecs = getAvgFeatureVecs(words1,words2,word_model,fea_num)\n",
    "print (dataDataVecs.shape)\n",
    "fea_npy = '%d_vecs.npy'%(kmer)\n",
    "np.save(fea_npy,dataDataVecs)\n",
    "\n",
    "\n",
    "#### npy To csv #####\n",
    "fea_svm = '%d_cross_test_vecs.svm'%(kmer)\n",
    "fea_csv = '%d_cross_test.csv'%(kmer)\n",
    "\n",
    "npyTosvm(fea_npy, fea_svm,pos_number)\n",
    "SVMtoCSV(fea_svm, fea_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3314, 200)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDataVecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6_vecs.npy'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
