{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 23:31:47.659487: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Dense, LSTM, Conv1D, Bidirectional, Flatten, Concatenate,concatenate,BatchNormalization,MaxPooling1D, Conv2D, MaxPooling2D, AveragePooling2D, Dropout, Reshape, normalization\n",
    "from keras.models import Model\n",
    "# from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "# from keras.layers.recurrent import LSTM\n",
    "from sklearn import metrics\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 23:31:48.524794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-08 23:31:48.529358: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-06-08 23:31:48.529367: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-06-08 23:31:48.529727: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    # Calculates the precision\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    # Calculates the recall\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1(test_Y, pre_test_y):\n",
    "    \"\"\"F1-score\"\"\"\n",
    "    Precision = precision(test_Y, pre_test_y)\n",
    "    Recall = recall(test_Y, pre_test_y)\n",
    "    f1 = 2 * ((Precision * Recall) / (Precision + Recall + K.epsilon()))\n",
    "    return f1 \n",
    "\n",
    "def TP(test_Y,pre_test_y):\n",
    "    TP = K.sum(K.round(K.clip(test_Y * pre_test_y, 0, 1)))#TP\n",
    "    return TP\n",
    "\n",
    "def FN(test_Y,pre_test_y):\n",
    "    TP = K.sum(K.round(K.clip(test_Y * pre_test_y, 0, 1)))#TP\n",
    "    P=K.sum(K.round(K.clip(test_Y, 0, 1)))\n",
    "    FN = P-TP #FN=P-TP\n",
    "    return FN\n",
    "\n",
    "def TN(test_Y,pre_test_y):\n",
    "    TN=K.sum(K.round(K.clip((test_Y-K.ones_like(test_Y))*(pre_test_y-K.ones_like(pre_test_y)), 0, 1)))#TN\n",
    "    return TN\n",
    "\n",
    "def FP(test_Y,pre_test_y):\n",
    "    N = (-1)*K.sum(K.round(K.clip(test_Y-K.ones_like(test_Y), -1, 0)))#N\n",
    "    TN=K.sum(K.round(K.clip((test_Y-K.ones_like(test_Y))*(pre_test_y-K.ones_like(pre_test_y)), 0, 1)))#TN\n",
    "    FP=N-TN\n",
    "    return FP\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc\n",
    "\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "\n",
    "def dnn_model(train_X, train_Y, test_X, test_Y, lr, epoch, batch_size):\n",
    "    train_X = np.expand_dims(train_X, 2)\n",
    "    test_X = np.expand_dims(test_X, 2)\n",
    "    inputs = Input(shape = (train_X.shape[1], train_X.shape[2]))\n",
    "    x = Conv1D(32, kernel_size = 5, strides = 1, padding = 'same', activation = 'relu')(inputs)\n",
    "    \n",
    "    x2 = Conv1D(32, kernel_size=10, strides = 1, padding = 'same', activation = 'relu')(x)\n",
    "    x = concatenate([inputs, x])\n",
    "    \n",
    "    x1 = Conv1D(32, kernel_size=8, strides = 1, padding = 'same', activation = 'relu')(x)\n",
    "    x1 = concatenate([inputs, x1])\n",
    "    # x = MaxPooling1D(pool_size = 2, strides = 2, padding = 'same')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x1= Flatten()(x1)\n",
    "    x1= Dropout(0.2)(x1)\n",
    "    x2 = Flatten()(x2)\n",
    "    \n",
    "    print(x.get_shape(), x2.get_shape(), x1.get_shape())\n",
    "    x = Dense(32, activation = 'relu')(x)\n",
    "    x1 = Dense(32)(x1)\n",
    "    x2=Dense(16)(x2)\n",
    "    x = concatenate([x, x1])\n",
    "    # x = Dense(16, activation = 'relu')(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "    x = concatenate([x, x2])\n",
    "    # x = Dense(8, activation = 'relu')(x)\n",
    "    predictions = Dense(1, activation = 'sigmoid')(x)\n",
    "    model = Model(inputs = inputs, outputs = predictions)\n",
    "    print(\"model\")\n",
    "    model.compile(optimizer = 'Adam',\n",
    "                  loss = 'binary_crossentropy',\n",
    "                  metrics = METRICS)\n",
    "    print(\"compile\")\n",
    "    model.fit(train_X, train_Y, epochs = epoch, batch_size = 32, validation_data = (test_X, test_Y), shuffle = True)\n",
    "    model.save('CNN_model.h5')\n",
    "    pre_test_y = model.predict(test_X, batch_size = 32)\n",
    "    pre_train_y = model.predict(train_X, batch_size = 32)\n",
    "    test_auc = metrics.roc_auc_score(test_Y, pre_test_y)\n",
    "    train_auc = metrics.roc_auc_score(train_Y, pre_train_y)\n",
    "    print(\"train_auc: \", train_auc)\n",
    "    print(\"test_auc: \", test_auc) \n",
    "    return test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.3797547   0.07784197 -0.01948018 ... -0.24125525 -0.14943232\n",
      "  -0.04389763]\n",
      " [-1.6729022   1.5755434  -0.12083484 ... -0.49767768 -0.01879338\n",
      "   0.43628073]\n",
      " [ 0.06469692  0.6509919  -0.28475574 ... -0.12958059  0.6027435\n",
      "  -0.58045673]\n",
      " ...\n",
      " [ 0.39322275 -0.25646174 -0.09789193 ... -0.5019782   0.21615557\n",
      "  -0.05430014]\n",
      " [ 0.62657034 -0.66358966  0.10115879 ...  0.50686693 -0.24329251\n",
      "  -0.9478652 ]\n",
      " [ 0.96455413 -0.7510625  -0.6388193  ...  0.7835602   0.27140352\n",
      "  -1.1620626 ]]\n",
      "X.shape:  (4192, 200)\n",
      "Y.shape:  (4192,)\n",
      "\n",
      "\n",
      "i:  0\n",
      "(None, 6600) (None, 6400) (None, 6600)\n",
      "model\n",
      "compile\n",
      "Epoch 1/5\n",
      "105/105 [==============================] - 2s 8ms/step - loss: 0.3659 - tp: 1359.0000 - fp: 228.0000 - tn: 1459.0000 - fn: 307.0000 - accuracy: 0.8404 - precision: 0.8563 - recall: 0.8157 - auc: 0.9195 - val_loss: 0.3109 - val_tp: 371.0000 - val_fp: 47.0000 - val_tn: 362.0000 - val_fn: 59.0000 - val_accuracy: 0.8737 - val_precision: 0.8876 - val_recall: 0.8628 - val_auc: 0.9513\n",
      "Epoch 2/5\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.3100 - tp: 1417.0000 - fp: 207.0000 - tn: 1480.0000 - fn: 249.0000 - accuracy: 0.8640 - precision: 0.8725 - recall: 0.8505 - auc: 0.9416 - val_loss: 0.2890 - val_tp: 380.0000 - val_fp: 61.0000 - val_tn: 348.0000 - val_fn: 50.0000 - val_accuracy: 0.8677 - val_precision: 0.8617 - val_recall: 0.8837 - val_auc: 0.9540\n",
      "Epoch 3/5\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.2877 - tp: 1449.0000 - fp: 206.0000 - tn: 1481.0000 - fn: 217.0000 - accuracy: 0.8738 - precision: 0.8755 - recall: 0.8697 - auc: 0.9496 - val_loss: 0.2783 - val_tp: 378.0000 - val_fp: 38.0000 - val_tn: 371.0000 - val_fn: 52.0000 - val_accuracy: 0.8927 - val_precision: 0.9087 - val_recall: 0.8791 - val_auc: 0.9544\n",
      "Epoch 4/5\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.2697 - tp: 1465.0000 - fp: 198.0000 - tn: 1489.0000 - fn: 201.0000 - accuracy: 0.8810 - precision: 0.8809 - recall: 0.8794 - auc: 0.9557 - val_loss: 0.2884 - val_tp: 344.0000 - val_fp: 17.0000 - val_tn: 392.0000 - val_fn: 86.0000 - val_accuracy: 0.8772 - val_precision: 0.9529 - val_recall: 0.8000 - val_auc: 0.9604\n",
      "Epoch 5/5\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.2570 - tp: 1475.0000 - fp: 177.0000 - tn: 1510.0000 - fn: 191.0000 - accuracy: 0.8902 - precision: 0.8929 - recall: 0.8854 - auc: 0.9601 - val_loss: 0.2639 - val_tp: 370.0000 - val_fp: 38.0000 - val_tn: 371.0000 - val_fn: 60.0000 - val_accuracy: 0.8832 - val_precision: 0.9069 - val_recall: 0.8605 - val_auc: 0.9597\n",
      "27/27 [==============================] - 0s 1ms/step\n",
      "105/105 [==============================] - 0s 1ms/step\n",
      "train_auc:  0.9720658862240806\n",
      "test_auc:  0.9596804457838176\n",
      "\n",
      "\n",
      "i:  1\n",
      "(None, 6600) (None, 6400) (None, 6600)\n",
      "model\n",
      "compile\n",
      "Epoch 1/5\n",
      "105/105 [==============================] - 2s 9ms/step - loss: 0.3482 - tp: 1727.0000 - fp: 261.0000 - tn: 1830.0000 - fn: 374.0000 - accuracy: 0.8485 - precision: 0.8687 - recall: 0.8220 - auc: 0.9335 - val_loss: 0.3218 - val_tp: 352.0000 - val_fp: 44.0000 - val_tn: 370.0000 - val_fn: 73.0000 - val_accuracy: 0.8605 - val_precision: 0.8889 - val_recall: 0.8282 - val_auc: 0.9399\n",
      "Epoch 2/5\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.2987 - tp: 1408.0000 - fp: 200.0000 - tn: 1482.0000 - fn: 263.0000 - accuracy: 0.8619 - precision: 0.8756 - recall: 0.8426 - auc: 0.9456 - val_loss: 0.3313 - val_tp: 347.0000 - val_fp: 40.0000 - val_tn: 374.0000 - val_fn: 78.0000 - val_accuracy: 0.8594 - val_precision: 0.8966 - val_recall: 0.8165 - val_auc: 0.9403\n",
      "Epoch 3/5\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.2797 - tp: 1462.0000 - fp: 199.0000 - tn: 1483.0000 - fn: 209.0000 - accuracy: 0.8783 - precision: 0.8802 - recall: 0.8749 - auc: 0.9524 - val_loss: 0.3081 - val_tp: 365.0000 - val_fp: 46.0000 - val_tn: 368.0000 - val_fn: 60.0000 - val_accuracy: 0.8737 - val_precision: 0.8881 - val_recall: 0.8588 - val_auc: 0.9448\n",
      "Epoch 4/5\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.2683 - tp: 1472.0000 - fp: 180.0000 - tn: 1502.0000 - fn: 199.0000 - accuracy: 0.8870 - precision: 0.8910 - recall: 0.8809 - auc: 0.9558 - val_loss: 0.3096 - val_tp: 363.0000 - val_fp: 49.0000 - val_tn: 365.0000 - val_fn: 62.0000 - val_accuracy: 0.8677 - val_precision: 0.8811 - val_recall: 0.8541 - val_auc: 0.9436\n",
      "Epoch 5/5\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.2460 - tp: 1489.0000 - fp: 177.0000 - tn: 1505.0000 - fn: 182.0000 - accuracy: 0.8929 - precision: 0.8938 - recall: 0.8911 - auc: 0.9630 - val_loss: 0.3113 - val_tp: 366.0000 - val_fp: 50.0000 - val_tn: 364.0000 - val_fn: 59.0000 - val_accuracy: 0.8701 - val_precision: 0.8798 - val_recall: 0.8612 - val_auc: 0.9440\n",
      "27/27 [==============================] - 0s 1ms/step\n",
      "105/105 [==============================] - 0s 1ms/step\n",
      "train_auc:  0.9740523627866003\n",
      "test_auc:  0.9441204887752203\n",
      "\n",
      "\n",
      "i:  2\n",
      "(None, 6600) (None, 6400) (None, 6600)\n",
      "model\n",
      "compile\n",
      "Epoch 1/5\n",
      "105/105 [==============================] - 2s 8ms/step - loss: 0.3531 - tp: 1748.0000 - fp: 268.0000 - tn: 1811.0000 - fn: 366.0000 - accuracy: 0.8488 - precision: 0.8671 - recall: 0.8269 - auc: 0.9292 - val_loss: 0.3528 - val_tp: 350.0000 - val_fp: 76.0000 - val_tn: 355.0000 - val_fn: 57.0000 - val_accuracy: 0.8413 - val_precision: 0.8216 - val_recall: 0.8600 - val_auc: 0.9315\n",
      "Epoch 2/5\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.2991 - tp: 1456.0000 - fp: 195.0000 - tn: 1470.0000 - fn: 233.0000 - accuracy: 0.8724 - precision: 0.8819 - recall: 0.8620 - auc: 0.9463 - val_loss: 0.3082 - val_tp: 344.0000 - val_fp: 51.0000 - val_tn: 380.0000 - val_fn: 63.0000 - val_accuracy: 0.8640 - val_precision: 0.8709 - val_recall: 0.8452 - val_auc: 0.9420\n",
      "Epoch 3/5\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.2788 - tp: 1491.0000 - fp: 195.0000 - tn: 1470.0000 - fn: 198.0000 - accuracy: 0.8828 - precision: 0.8843 - recall: 0.8828 - auc: 0.9526 - val_loss: 0.3615 - val_tp: 388.0000 - val_fp: 118.0000 - val_tn: 313.0000 - val_fn: 19.0000 - val_accuracy: 0.8365 - val_precision: 0.7668 - val_recall: 0.9533 - val_auc: 0.9448\n",
      "Epoch 4/5\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.2612 - tp: 1496.0000 - fp: 185.0000 - tn: 1480.0000 - fn: 193.0000 - accuracy: 0.8873 - precision: 0.8899 - recall: 0.8857 - auc: 0.9584 - val_loss: 0.2980 - val_tp: 347.0000 - val_fp: 51.0000 - val_tn: 380.0000 - val_fn: 60.0000 - val_accuracy: 0.8675 - val_precision: 0.8719 - val_recall: 0.8526 - val_auc: 0.9461\n",
      "Epoch 5/5\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.2481 - tp: 1506.0000 - fp: 183.0000 - tn: 1482.0000 - fn: 183.0000 - accuracy: 0.8909 - precision: 0.8917 - recall: 0.8917 - auc: 0.9624 - val_loss: 0.3061 - val_tp: 357.0000 - val_fp: 69.0000 - val_tn: 362.0000 - val_fn: 50.0000 - val_accuracy: 0.8580 - val_precision: 0.8380 - val_recall: 0.8771 - val_auc: 0.9438\n",
      "27/27 [==============================] - 0s 1ms/step\n",
      "105/105 [==============================] - 0s 1ms/step\n",
      "train_auc:  0.9750884099019089\n",
      "test_auc:  0.9436656652433915\n",
      "\n",
      "\n",
      "i:  3\n",
      "(None, 6600) (None, 6400) (None, 6600)\n",
      "model\n",
      "compile\n",
      "Epoch 1/5\n",
      "105/105 [==============================] - 2s 9ms/step - loss: 0.3502 - tp: 1741.0000 - fp: 301.0000 - tn: 1805.0000 - fn: 345.0000 - accuracy: 0.8459 - precision: 0.8526 - recall: 0.8346 - auc: 0.9288 - val_loss: 0.3547 - val_tp: 328.0000 - val_fp: 45.0000 - val_tn: 376.0000 - val_fn: 89.0000 - val_accuracy: 0.8401 - val_precision: 0.8794 - val_recall: 0.7866 - val_auc: 0.9312\n",
      "Epoch 2/5\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.3020 - tp: 1451.0000 - fp: 194.0000 - tn: 1481.0000 - fn: 228.0000 - accuracy: 0.8742 - precision: 0.8821 - recall: 0.8642 - auc: 0.9445 - val_loss: 0.3223 - val_tp: 351.0000 - val_fp: 59.0000 - val_tn: 362.0000 - val_fn: 66.0000 - val_accuracy: 0.8508 - val_precision: 0.8561 - val_recall: 0.8417 - val_auc: 0.9352\n",
      "Epoch 3/5\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.2759 - tp: 1469.0000 - fp: 190.0000 - tn: 1485.0000 - fn: 210.0000 - accuracy: 0.8807 - precision: 0.8855 - recall: 0.8749 - auc: 0.9538 - val_loss: 0.3156 - val_tp: 359.0000 - val_fp: 66.0000 - val_tn: 355.0000 - val_fn: 58.0000 - val_accuracy: 0.8520 - val_precision: 0.8447 - val_recall: 0.8609 - val_auc: 0.9377\n",
      "Epoch 4/5\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.2570 - tp: 1495.0000 - fp: 189.0000 - tn: 1486.0000 - fn: 184.0000 - accuracy: 0.8888 - precision: 0.8878 - recall: 0.8904 - auc: 0.9600 - val_loss: 0.3038 - val_tp: 376.0000 - val_fp: 70.0000 - val_tn: 351.0000 - val_fn: 41.0000 - val_accuracy: 0.8675 - val_precision: 0.8430 - val_recall: 0.9017 - val_auc: 0.9455\n",
      "Epoch 5/5\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.2428 - tp: 1500.0000 - fp: 178.0000 - tn: 1497.0000 - fn: 179.0000 - accuracy: 0.8936 - precision: 0.8939 - recall: 0.8934 - auc: 0.9641 - val_loss: 0.2992 - val_tp: 368.0000 - val_fp: 64.0000 - val_tn: 357.0000 - val_fn: 49.0000 - val_accuracy: 0.8652 - val_precision: 0.8519 - val_recall: 0.8825 - val_auc: 0.9470\n",
      "27/27 [==============================] - 0s 1ms/step\n",
      "105/105 [==============================] - 0s 1ms/step\n",
      "train_auc:  0.9758015165388069\n",
      "test_auc:  0.9470827138764047\n",
      "\n",
      "\n",
      "i:  4\n",
      "(None, 6600) (None, 6400) (None, 6600)\n",
      "model\n",
      "compile\n",
      "Epoch 1/5\n",
      "105/105 [==============================] - 2s 8ms/step - loss: 0.3562 - tp: 1751.0000 - fp: 279.0000 - tn: 1817.0000 - fn: 345.0000 - accuracy: 0.8511 - precision: 0.8626 - recall: 0.8354 - auc: 0.9283 - val_loss: 0.2830 - val_tp: 372.0000 - val_fp: 57.0000 - val_tn: 364.0000 - val_fn: 45.0000 - val_accuracy: 0.8783 - val_precision: 0.8671 - val_recall: 0.8921 - val_auc: 0.9517\n",
      "Epoch 2/5\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.3077 - tp: 1443.0000 - fp: 209.0000 - tn: 1466.0000 - fn: 236.0000 - accuracy: 0.8673 - precision: 0.8735 - recall: 0.8594 - auc: 0.9419 - val_loss: 0.2799 - val_tp: 373.0000 - val_fp: 57.0000 - val_tn: 364.0000 - val_fn: 44.0000 - val_accuracy: 0.8795 - val_precision: 0.8674 - val_recall: 0.8945 - val_auc: 0.9515\n",
      "Epoch 3/5\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.2875 - tp: 1440.0000 - fp: 194.0000 - tn: 1481.0000 - fn: 239.0000 - accuracy: 0.8709 - precision: 0.8813 - recall: 0.8577 - auc: 0.9497 - val_loss: 0.2865 - val_tp: 386.0000 - val_fp: 70.0000 - val_tn: 351.0000 - val_fn: 31.0000 - val_accuracy: 0.8795 - val_precision: 0.8465 - val_recall: 0.9257 - val_auc: 0.9525\n",
      "Epoch 4/5\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.2620 - tp: 1492.0000 - fp: 187.0000 - tn: 1488.0000 - fn: 187.0000 - accuracy: 0.8885 - precision: 0.8886 - recall: 0.8886 - auc: 0.9585 - val_loss: 0.2809 - val_tp: 353.0000 - val_fp: 49.0000 - val_tn: 372.0000 - val_fn: 64.0000 - val_accuracy: 0.8652 - val_precision: 0.8781 - val_recall: 0.8465 - val_auc: 0.9525\n",
      "Epoch 5/5\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 0.2468 - tp: 1490.0000 - fp: 172.0000 - tn: 1503.0000 - fn: 189.0000 - accuracy: 0.8924 - precision: 0.8965 - recall: 0.8874 - auc: 0.9629 - val_loss: 0.2742 - val_tp: 359.0000 - val_fp: 50.0000 - val_tn: 371.0000 - val_fn: 58.0000 - val_accuracy: 0.8711 - val_precision: 0.8778 - val_recall: 0.8609 - val_auc: 0.9540\n",
      "27/27 [==============================] - 0s 1ms/step\n",
      "105/105 [==============================] - 0s 1ms/step\n",
      "train_auc:  0.9736264478678673\n",
      "test_auc:  0.954094681499456\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = np.array(pd.read_csv(\"6_train.csv\"))\n",
    "pos_number=2096 # train pos samples\n",
    "# NOTE: the number of postive sample in train file\n",
    "#CNN_model = 'CNN_model.h5'\n",
    "\n",
    "X1 = data[0:pos_number, 1:]\n",
    "Y1 = data[0:pos_number, 0]\n",
    "X2 = data[pos_number:, 1:]\n",
    "Y2 = data[pos_number:, 0]\n",
    "X = np.concatenate([X1, X2], 0)\n",
    "Y = np.concatenate([Y1, Y2], 0)\n",
    "#Y = Y.reshape((Y.shape[0], -1))\n",
    "print (X)\n",
    "print (\"X.shape: \", X.shape)\n",
    "print (\"Y.shape: \", Y.shape)\n",
    "\n",
    "lr = 0.01\n",
    "epoch = 5\n",
    "batch_size = 32\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "#kf = KFold(n_splits = 5, shuffle = False)\n",
    "kf = kf.split(X)\n",
    "\n",
    "test_aucs = []\n",
    "for i, (train_fold, validate_fold) in enumerate(kf):\n",
    "    print(\"\\n\\ni: \", i)\n",
    "    test_auc = dnn_model(X[train_fold], Y[train_fold], X[validate_fold], Y[validate_fold], lr, epoch, batch_size)\n",
    "    test_aucs.append(test_auc)\n",
    "w = open(\"train_Result.txt\", \"w\")\n",
    "for j in test_aucs: \n",
    "    w.write(str(j) + ',')\n",
    "w.write('\\n')\n",
    "w.write(str(np.mean(test_aucs)) + '\\n')\n",
    "w.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Independent Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(899, 200) (898, 200)\n",
      "(899,) (898,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = np.array(pd.read_csv(\"6_test.csv\"))\n",
    "pos_number = 899 # NOTE: the number of postive sample in test file\n",
    "\n",
    "X1 = data[0:pos_number, 1:]\n",
    "Y1 = data[0:pos_number, 0]\n",
    "X2 = data[pos_number:, 1:]\n",
    "Y2 = data[pos_number:, 0]\n",
    "X_test = np.concatenate([X1, X2], 0)\n",
    "Y_test = np.concatenate([Y1, Y2], 0)\n",
    "\n",
    "print(X1.shape, X2.shape)\n",
    "print(Y1.shape, Y2.shape)\n",
    "\n",
    "\n",
    "# data = np.array(pd.read_csv(\"6cross_test_data.csv\"))\n",
    "# pos_number = 1658 # NOTE: the number of postive sample in test file\n",
    "# X1 = data[0:pos_number, 1:]\n",
    "# Y1 = data[0:pos_number, 0]\n",
    "# X2 = data[pos_number:, 1:]\n",
    "# Y2 = data[pos_number:, 0]\n",
    "# X_test = np.concatenate([X1, X2], 0)\n",
    "# Y_test = np.concatenate([Y1, Y2], 0)\n",
    "\n",
    "# print(X1.shape, X2.shape)\n",
    "# print(Y1.shape, Y2.shape)\n",
    "\n",
    "lr = 0.01\n",
    "# epoch = 3\n",
    "batch_size = 32\n",
    "data = np.array(pd.read_csv(\"6_train.csv\"))\n",
    "pos_number=2097\n",
    "\n",
    "\n",
    "X1 = data[0:pos_number, 1:]\n",
    "Y1 = data[0:pos_number, 0]\n",
    "X2 = data[pos_number:, 1:]\n",
    "Y2 = data[pos_number:, 0]\n",
    "X = np.concatenate([X1, X2], 0)\n",
    "Y = np.concatenate([Y1, Y2], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 6600) (None, 6400) (None, 6600)\n",
      "model\n",
      "compile\n",
      "Epoch 1/6\n",
      "131/131 [==============================] - 2s 7ms/step - loss: 0.3469 - tp: 2077.0000 - fp: 299.0000 - tn: 2218.0000 - fn: 436.0000 - accuracy: 0.8539 - precision: 0.8742 - recall: 0.8265 - auc: 0.9322 - val_loss: 0.3076 - val_tp: 751.0000 - val_fp: 86.0000 - val_tn: 812.0000 - val_fn: 148.0000 - val_accuracy: 0.8698 - val_precision: 0.8973 - val_recall: 0.8354 - val_auc: 0.9470\n",
      "Epoch 2/6\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.3006 - tp: 1819.0000 - fp: 269.0000 - tn: 1827.0000 - fn: 277.0000 - accuracy: 0.8698 - precision: 0.8712 - recall: 0.8678 - auc: 0.9442 - val_loss: 0.3005 - val_tp: 745.0000 - val_fp: 80.0000 - val_tn: 818.0000 - val_fn: 154.0000 - val_accuracy: 0.8698 - val_precision: 0.9030 - val_recall: 0.8287 - val_auc: 0.9494\n",
      "Epoch 3/6\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2772 - tp: 1843.0000 - fp: 244.0000 - tn: 1852.0000 - fn: 253.0000 - accuracy: 0.8814 - precision: 0.8831 - recall: 0.8793 - auc: 0.9530 - val_loss: 0.2786 - val_tp: 781.0000 - val_fp: 92.0000 - val_tn: 806.0000 - val_fn: 118.0000 - val_accuracy: 0.8831 - val_precision: 0.8946 - val_recall: 0.8687 - val_auc: 0.9540\n",
      "Epoch 4/6\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2675 - tp: 1846.0000 - fp: 246.0000 - tn: 1850.0000 - fn: 250.0000 - accuracy: 0.8817 - precision: 0.8824 - recall: 0.8807 - auc: 0.9564 - val_loss: 0.2920 - val_tp: 844.0000 - val_fp: 162.0000 - val_tn: 736.0000 - val_fn: 55.0000 - val_accuracy: 0.8792 - val_precision: 0.8390 - val_recall: 0.9388 - val_auc: 0.9550\n",
      "Epoch 5/6\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2440 - tp: 1874.0000 - fp: 215.0000 - tn: 1881.0000 - fn: 222.0000 - accuracy: 0.8958 - precision: 0.8971 - recall: 0.8941 - auc: 0.9639 - val_loss: 0.2938 - val_tp: 831.0000 - val_fp: 149.0000 - val_tn: 749.0000 - val_fn: 68.0000 - val_accuracy: 0.8792 - val_precision: 0.8480 - val_recall: 0.9244 - val_auc: 0.9554\n",
      "Epoch 6/6\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2328 - tp: 1886.0000 - fp: 201.0000 - tn: 1895.0000 - fn: 210.0000 - accuracy: 0.9020 - precision: 0.9037 - recall: 0.8998 - auc: 0.9671 - val_loss: 0.2774 - val_tp: 751.0000 - val_fp: 62.0000 - val_tn: 836.0000 - val_fn: 148.0000 - val_accuracy: 0.8831 - val_precision: 0.9237 - val_recall: 0.8354 - val_auc: 0.9576\n",
      "57/57 [==============================] - 0s 1ms/step\n",
      "131/131 [==============================] - 0s 1ms/step\n",
      "train_auc:  0.9796454351436397\n",
      "test_auc:  0.9577394828701031\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_auc = dnn_model(X, Y, X_test, Y_test, lr, 6, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
