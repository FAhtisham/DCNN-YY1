{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 23:34:37.319284: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Dense, LSTM, Conv1D, Bidirectional, Flatten, Concatenate,concatenate,BatchNormalization,MaxPooling1D, Conv2D, MaxPooling2D, AveragePooling2D, Dropout, Reshape, normalization\n",
    "from keras.models import Model\n",
    "# from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "# from keras.layers.recurrent import LSTM\n",
    "from sklearn import metrics\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc\n",
    "\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "def dnn_model(train_X, train_Y, test_X, test_Y, lr, epoch, batch_size):\n",
    "    train_X = np.expand_dims(train_X, 2)\n",
    "    test_X = np.expand_dims(test_X, 2)\n",
    "    inputs = Input(shape = (train_X.shape[1], train_X.shape[2]))\n",
    "    x = Conv1D(32, kernel_size = 5, strides = 1, padding = 'same', activation = 'relu')(inputs)\n",
    "    \n",
    "    x2 = Conv1D(32, kernel_size=10, strides = 1, padding = 'same', activation = 'relu')(x)\n",
    "    x = concatenate([inputs, x])\n",
    "    \n",
    "    x1 = Conv1D(32, kernel_size=8, strides = 1, padding = 'same', activation = 'relu')(x)\n",
    "    x1 = concatenate([inputs, x1])\n",
    "    # x = MaxPooling1D(pool_size = 2, strides = 2, padding = 'same')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x1= Flatten()(x1)\n",
    "    x1= Dropout(0.2)(x1)\n",
    "    x2 = Flatten()(x2)\n",
    "    \n",
    "    x = Dense(32, activation = 'relu')(x)\n",
    "    x1 = Dense(32)(x1)\n",
    "    x2=Dense(16)(x2)\n",
    "    x = concatenate([x, x1])\n",
    "    # x = Dense(16, activation = 'relu')(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "    x = concatenate([x, x2])\n",
    "    # x = Dense(8, activation = 'relu')(x)\n",
    "    predictions = Dense(1, activation = 'sigmoid')(x)\n",
    "    model = Model(inputs = inputs, outputs = predictions)\n",
    "    # print(model.summary())\n",
    "    model.compile(optimizer = 'Adam',\n",
    "                  loss = 'binary_crossentropy',\n",
    "                  metrics = METRICS)\n",
    "    print(\"compile\")\n",
    "    model.fit(train_X, train_Y, epochs = epoch, batch_size = batch_size, validation_data = (test_X, test_Y), shuffle = True)\n",
    "\n",
    "    pre_test_y = model.predict(test_X, batch_size = batch_size)\n",
    "    pre_train_y = model.predict(train_X, batch_size = batch_size)\n",
    "    test_auc = metrics.roc_auc_score(test_Y, pre_test_y)\n",
    "    train_auc = metrics.roc_auc_score(train_Y, pre_train_y)\n",
    "    print(\"train_auc: \", train_auc)\n",
    "    print(\"test_auc: \", test_auc) \n",
    "    return test_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Cross Cell Independent Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1658, 200) (1656, 200)\n",
      "(1658,) (1656,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = np.array(pd.read_csv(\"6_test.csv\"))\n",
    "pos_number=1658\n",
    "X1 = data[0:pos_number, 1:]\n",
    "Y1 = data[0:pos_number, 0]\n",
    "X2 = data[pos_number:, 1:]\n",
    "Y2 = data[pos_number:, 0]\n",
    "X_test = np.concatenate([X1, X2], 0)\n",
    "Y_test = np.concatenate([Y1, Y2], 0)\n",
    "\n",
    "print(X1.shape, X2.shape)\n",
    "print(Y1.shape, Y2.shape)\n",
    "\n",
    "\n",
    "lr = 0.01\n",
    "# epoch = 3\n",
    "batch_size = 32\n",
    "data = np.array(pd.read_csv(\"6_train.csv\"))\n",
    "pos_number=2097\n",
    "\n",
    "\n",
    "X1 = data[0:pos_number, 1:]\n",
    "Y1 = data[0:pos_number, 0]\n",
    "X2 = data[pos_number:, 1:]\n",
    "Y2 = data[pos_number:, 0]\n",
    "X = np.concatenate([X1, X2], 0)\n",
    "Y = np.concatenate([Y1, Y2], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\n",
      "compile\n",
      "Epoch 1/6\n",
      "131/131 [==============================] - 2s 7ms/step - loss: 0.3520 - tp: 2746.0000 - fp: 378.0000 - tn: 3374.0000 - fn: 1008.0000 - accuracy: 0.8153 - precision: 0.8790 - recall: 0.7315 - auc: 0.9093 - val_loss: 0.3721 - val_tp: 1238.0000 - val_fp: 163.0000 - val_tn: 1493.0000 - val_fn: 420.0000 - val_accuracy: 0.8241 - val_precision: 0.8837 - val_recall: 0.7467 - val_auc: 0.9251\n",
      "Epoch 2/6\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2983 - tp: 1808.0000 - fp: 258.0000 - tn: 1838.0000 - fn: 288.0000 - accuracy: 0.8698 - precision: 0.8751 - recall: 0.8626 - auc: 0.9454 - val_loss: 0.3785 - val_tp: 1234.0000 - val_fp: 205.0000 - val_tn: 1451.0000 - val_fn: 424.0000 - val_accuracy: 0.8102 - val_precision: 0.8575 - val_recall: 0.7443 - val_auc: 0.9170\n",
      "Epoch 3/6\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2788 - tp: 1843.0000 - fp: 247.0000 - tn: 1849.0000 - fn: 253.0000 - accuracy: 0.8807 - precision: 0.8818 - recall: 0.8793 - auc: 0.9525 - val_loss: 0.3655 - val_tp: 1252.0000 - val_fp: 157.0000 - val_tn: 1499.0000 - val_fn: 406.0000 - val_accuracy: 0.8301 - val_precision: 0.8886 - val_recall: 0.7551 - val_auc: 0.9292\n",
      "Epoch 4/6\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2618 - tp: 1836.0000 - fp: 229.0000 - tn: 1867.0000 - fn: 260.0000 - accuracy: 0.8833 - precision: 0.8891 - recall: 0.8760 - auc: 0.9585 - val_loss: 0.3616 - val_tp: 1519.0000 - val_fp: 365.0000 - val_tn: 1291.0000 - val_fn: 139.0000 - val_accuracy: 0.8479 - val_precision: 0.8063 - val_recall: 0.9162 - val_auc: 0.9297\n",
      "Epoch 5/6\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2448 - tp: 1889.0000 - fp: 216.0000 - tn: 1880.0000 - fn: 207.0000 - accuracy: 0.8991 - precision: 0.8974 - recall: 0.9012 - auc: 0.9634 - val_loss: 0.3907 - val_tp: 1205.0000 - val_fp: 149.0000 - val_tn: 1507.0000 - val_fn: 453.0000 - val_accuracy: 0.8183 - val_precision: 0.8900 - val_recall: 0.7268 - val_auc: 0.9213\n",
      "Epoch 6/6\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2297 - tp: 1873.0000 - fp: 198.0000 - tn: 1898.0000 - fn: 223.0000 - accuracy: 0.8996 - precision: 0.9044 - recall: 0.8936 - auc: 0.9681 - val_loss: 0.3559 - val_tp: 1411.0000 - val_fp: 274.0000 - val_tn: 1382.0000 - val_fn: 247.0000 - val_accuracy: 0.8428 - val_precision: 0.8374 - val_recall: 0.8510 - val_auc: 0.9257\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "131/131 [==============================] - 0s 1ms/step\n",
      "train_auc:  0.9785487442456734\n",
      "test_auc:  0.9258623100994737\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# test_auc = dnn_model(X_train, y_train, X_test, y_test, lr, 5, 32)\n",
    "\n",
    "\n",
    "test_auc = dnn_model(X, Y, X_test, Y_test, lr, 6, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
