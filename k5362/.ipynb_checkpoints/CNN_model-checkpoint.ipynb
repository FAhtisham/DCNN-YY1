{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Dense, LSTM, Conv1D, Bidirectional, Flatten, Concatenate,concatenate,BatchNormalization,MaxPooling1D, Conv2D, MaxPooling2D, AveragePooling2D, Dropout, Reshape, normalization\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from sklearn import metrics\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def precision(y_true, y_pred):\n",
    "#     # Calculates the precision\n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#     predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "#     precision = true_positives / (predicted_positives + K.epsilon())\n",
    "#     return precision\n",
    "\n",
    "# def recall(y_true, y_pred):\n",
    "#     # Calculates the recall\n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#     possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "#     recall = true_positives / (possible_positives + K.epsilon())\n",
    "#     return recall\n",
    "\n",
    "# def f1(test_Y, pre_test_y):\n",
    "#     \"\"\"F1-score\"\"\"\n",
    "#     Precision = precision(test_Y, pre_test_y)\n",
    "#     Recall = recall(test_Y, pre_test_y)\n",
    "#     f1 = 2 * ((Precision * Recall) / (Precision + Recall + K.epsilon()))\n",
    "#     return f1 \n",
    "\n",
    "# def TP(test_Y,pre_test_y):\n",
    "#     TP = K.sum(K.round(K.clip(test_Y * pre_test_y, 0, 1)))#TP\n",
    "#     return TP\n",
    "\n",
    "# def FN(test_Y,pre_test_y):\n",
    "#     TP = K.sum(K.round(K.clip(test_Y * pre_test_y, 0, 1)))#TP\n",
    "#     P=K.sum(K.round(K.clip(test_Y, 0, 1)))\n",
    "#     FN = P-TP #FN=P-TP\n",
    "#     return FN\n",
    "\n",
    "# def TN(test_Y,pre_test_y):\n",
    "#     TN=K.sum(K.round(K.clip((test_Y-K.ones_like(test_Y))*(pre_test_y-K.ones_like(pre_test_y)), 0, 1)))#TN\n",
    "#     return TN\n",
    "\n",
    "# def FP(test_Y,pre_test_y):\n",
    "#     N = (-1)*K.sum(K.round(K.clip(test_Y-K.ones_like(test_Y), -1, 0)))#N\n",
    "#     TN=K.sum(K.round(K.clip((test_Y-K.ones_like(test_Y))*(pre_test_y-K.ones_like(pre_test_y)), 0, 1)))#TN\n",
    "#     FP=N-TN\n",
    "#     return FP\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc\n",
    "\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "# def dnn_model(train_X, train_Y, test_X, test_Y, lr, epoch, batch_size):\n",
    "    \n",
    "#     train_X = np.expand_dims(train_X, 2)\n",
    "#     test_X = np.expand_dims(test_X, 2)\n",
    "#     inputs = Input(shape = (train_X.shape[1], train_X.shape[2]))\n",
    "    \n",
    "#     initializer = tf.keras.initializers.RandomUniform()\n",
    "#     c10 = Conv1D(64,11, strides=1, activation='relu', padding = 'same')(inputs)\n",
    "#     c1 = BatchNormalization()(c10)\n",
    "#     #c1 = MaxPooling1D(4,strides=2, padding = 'same')(c1)\n",
    "#     #c1 = Dropout(0.1)(c1)\n",
    "    \n",
    "#     u1 = concatenate([inputs, c1])\n",
    "#     c2 = Conv1D(32,7, strides=1, activation='relu', padding = 'same')(u1)\n",
    "#     c2 = BatchNormalization()(c2)\n",
    "#     u6 = concatenate([u1, c2])\n",
    "\n",
    "#     #c2 = MaxPooling1D(4,strides=2)(c2)\n",
    "#     #c2 = Dropout(0.25)(c2)\n",
    "# #     c2 = Conv1D(32,5, strides=1, activation='relu', padding = 'same')(u6)\n",
    "# #     c2 = BatchNormalization()(c2)\n",
    "# #     u7 = concatenate([u6, c2])\n",
    "\n",
    "\n",
    "# #     c2 = MaxPooling1D(4,strides=2)(u7)\n",
    "# #     c2 = Dropout(0.30)(c2)\n",
    "\n",
    "#     # c3 = LSTM(5, activation='relu', return_sequences=True)(c2)\n",
    "#     c3=Bidirectional(LSTM(30, return_sequences=True))(u6)\n",
    "\n",
    "#     fc = Flatten()(c3)\n",
    "#     #fc0 = Dense(16, activation='relu')(fc)\n",
    "#     #R1=RandomFourierFeatures(300, kernel_initializer=\"gaussian\")(fc)\n",
    "    \n",
    "    \n",
    "#     fc1 = Dense(16, activation='relu',kernel_initializer='glorot_uniform',\n",
    "#     bias_initializer='zeros')(fc)\n",
    "#     fc1=Dropout(0.2)(fc1)\n",
    "#     fc1 = Dense(8, activation='relu',kernel_initializer='glorot_uniform',\n",
    "#     bias_initializer='zeros')(fc1)\n",
    "\n",
    "#     predictions = Dense(1, activation='sigmoid')(fc1)\n",
    "    \n",
    "#     model = Model(inputs = inputs, outputs = predictions)\n",
    "#     print(\"model\")\n",
    "#     model.compile(optimizer = 'RMSprop',\n",
    "#                   loss = 'binary_crossentropy',\n",
    "#                   metrics = METRICS)\n",
    "#     print(\"compile\")\n",
    "#     model.fit(train_X, train_Y, epochs = epoch, batch_size = 32, validation_data = (test_X, test_Y), shuffle = True)\n",
    "#     model.save('CNN_model.h5')\n",
    "#     pre_test_y = model.predict(test_X, batch_size = 32)\n",
    "#     pre_train_y = model.predict(train_X, batch_size = 32)\n",
    "#     test_auc = metrics.roc_auc_score(test_Y, pre_test_y)\n",
    "#     train_auc = metrics.roc_auc_score(train_Y, pre_train_y)\n",
    "#     print(\"train_auc: \", train_auc)\n",
    "#     print(\"test_auc: \", test_auc) \n",
    "#     return test_auc\n",
    "\n",
    "\n",
    "\n",
    "# def dnn_model(train_X, train_Y, test_X, test_Y, lr, epoch, batch_size):\n",
    "#     train_X = np.expand_dims(train_X, 2)\n",
    "#     test_X = np.expand_dims(test_X, 2)\n",
    "#     inputs = Input(shape = (train_X.shape[1], train_X.shape[2]))\n",
    "#     x = Conv1D(32, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu')(inputs)\n",
    "\n",
    "#     x = MaxPooling1D(pool_size = 2, strides = 2, padding = 'same')(x)\n",
    "#     x = Flatten()(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "    \n",
    "#     x = Dense(32, activation = 'relu')(x)\n",
    "#     x = Dense(16, activation = 'relu')(x)\n",
    "#     x = Dense(8, activation = 'relu')(x)\n",
    "#     predictions = Dense(1, activation = 'sigmoid')(x)\n",
    "#     model = Model(inputs = inputs, outputs = predictions)\n",
    "#     print(\"model\")\n",
    "#     model.compile(optimizer = 'RMSprop',\n",
    "#                   loss = 'binary_crossentropy',\n",
    "#                   metrics = METRICS)\n",
    "#     print(\"compile\")\n",
    "#     model.fit(train_X, train_Y, epochs = epoch, batch_size = 32, validation_data = (test_X, test_Y), shuffle = True)\n",
    "#     model.save('CNN_model.h5')\n",
    "#     pre_test_y = model.predict(test_X, batch_size = 64)\n",
    "#     pre_train_y = model.predict(train_X, batch_size = 64)\n",
    "#     test_auc = metrics.roc_auc_score(test_Y, pre_test_y)\n",
    "#     train_auc = metrics.roc_auc_score(train_Y, pre_train_y)\n",
    "#     print(\"train_auc: \", train_auc)\n",
    "#     print(\"test_auc: \", test_auc) \n",
    "#     return test_auc\n",
    "\n",
    "#working\n",
    "# def dnn_model(train_X, train_Y, test_X, test_Y, lr, epoch, batch_size):\n",
    "#     train_X = np.expand_dims(train_X, 2)\n",
    "#     test_X = np.expand_dims(test_X, 2)\n",
    "#     inputs = Input(shape = (train_X.shape[1], train_X.shape[2]))\n",
    "#     x = Conv1D(32, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu')(inputs)\n",
    "#     x1 = Conv1D(32, kernel_size=3, strides = 1, padding = 'same', activation = 'relu')(x)\n",
    "#     x = concatenate([inputs, x])\n",
    "#     # x = MaxPooling1D(pool_size = 2, strides = 2, padding = 'same')(x)\n",
    "#     x = Flatten()(x)\n",
    "#     x1= Flatten()(x1)\n",
    "#     x = Dropout(0.2)(x)\n",
    "    \n",
    "#     x = Dense(32, activation = 'relu')(x)\n",
    "#     x1 = Dense(32)(x1)\n",
    "#     x = Dense(16, activation = 'relu')(x+x1)\n",
    "#     # x = Dense(8, activation = 'relu')(x)\n",
    "#     predictions = Dense(1, activation = 'sigmoid')(x)\n",
    "#     model = Model(inputs = inputs, outputs = predictions)\n",
    "#     print(\"model\")\n",
    "#     model.compile(optimizer = 'RMSprop',\n",
    "#                   loss = 'binary_crossentropy',\n",
    "#                   metrics = METRICS)\n",
    "#     print(\"compile\")\n",
    "#     model.fit(train_X, train_Y, epochs = epoch, batch_size = 32, validation_data = (test_X, test_Y), shuffle = True)\n",
    "#     model.save('CNN_model.h5')\n",
    "#     pre_test_y = model.predict(test_X, batch_size = 32)\n",
    "#     pre_train_y = model.predict(train_X, batch_size = 32)\n",
    "#     test_auc = metrics.roc_auc_score(test_Y, pre_test_y)\n",
    "#     train_auc = metrics.roc_auc_score(train_Y, pre_train_y)\n",
    "#     print(\"train_auc: \", train_auc)\n",
    "#     print(\"test_auc: \", test_auc) \n",
    "#     return test_auc\n",
    "\n",
    "# # 97.5\n",
    "# def dnn_model(train_X, train_Y, test_X, test_Y, lr, epoch, batch_size):\n",
    "#     train_X = np.expand_dims(train_X, 2)\n",
    "#     test_X = np.expand_dims(test_X, 2)\n",
    "#     inputs = Input(shape = (train_X.shape[1], train_X.shape[2]))\n",
    "#     x = Conv1D(32, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu')(inputs)\n",
    "#     x1 = Conv1D(32, kernel_size=3, strides = 1, padding = 'same', activation = 'relu')(x)\n",
    "#     x2 = Conv1D(32, kernel_size=3, strides = 1, padding = 'same', activation = 'relu')(x)\n",
    "#     x = concatenate([inputs, x])\n",
    "#     # x = MaxPooling1D(pool_size = 2, strides = 2, padding = 'same')(x)\n",
    "#     x = Flatten()(x)\n",
    "#     x1= Flatten()(x1)\n",
    "#     x2 = Flatten()(x2)\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     print(x.get_shape(), x2.get_shape(), x1.get_shape())\n",
    "#     x = Dense(32, activation = 'relu')(x)\n",
    "#     x1 = Dense(32)(x1)\n",
    "#     x2=Dense(16)(x2)\n",
    "    \n",
    "#     x = Dense(16, activation = 'relu')(x+x1)\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     # x = Dense(8, activation = 'relu')(x)\n",
    "#     predictions = Dense(1, activation = 'sigmoid')(x+x2)\n",
    "#     model = Model(inputs = inputs, outputs = predictions)\n",
    "#     print(\"model\")\n",
    "#     model.compile(optimizer = 'SGD',\n",
    "#                   loss = 'binary_crossentropy',\n",
    "#                   metrics = METRICS)\n",
    "#     print(\"compile\")\n",
    "#     model.fit(train_X, train_Y, epochs = epoch, batch_size = 32, validation_data = (test_X, test_Y), shuffle = True)\n",
    "#     model.save('CNN_model.h5')\n",
    "#     pre_test_y = model.predict(test_X, batch_size = 50)\n",
    "#     pre_train_y = model.predict(train_X, batch_size = 50)\n",
    "#     test_auc = metrics.roc_auc_score(test_Y, pre_test_y)\n",
    "#     train_auc = metrics.roc_auc_score(train_Y, pre_train_y)\n",
    "#     print(\"train_auc: \", train_auc)\n",
    "#     print(\"test_auc: \", test_auc) \n",
    "#     return test_auc\n",
    "\n",
    "def dnn_model(train_X, train_Y, test_X, test_Y, lr, epoch, batch_size):\n",
    "    train_X = np.expand_dims(train_X, 2)\n",
    "    test_X = np.expand_dims(test_X, 2)\n",
    "    inputs = Input(shape = (train_X.shape[1], train_X.shape[2]))\n",
    "    x = Conv1D(32, kernel_size = 5, strides = 1, padding = 'same', activation = 'relu')(inputs)\n",
    "    \n",
    "    x2 = Conv1D(32, kernel_size=10, strides = 1, padding = 'same', activation = 'relu')(x)\n",
    "    x = concatenate([inputs, x])\n",
    "    \n",
    "    x1 = Conv1D(32, kernel_size=8, strides = 1, padding = 'same', activation = 'relu')(x)\n",
    "    x1 = concatenate([inputs, x1])\n",
    "    # x = MaxPooling1D(pool_size = 2, strides = 2, padding = 'same')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x1= Flatten()(x1)\n",
    "    x1= Dropout(0.2)(x1)\n",
    "    x2 = Flatten()(x2)\n",
    "    \n",
    "    print(x.get_shape(), x2.get_shape(), x1.get_shape())\n",
    "    x = Dense(32, activation = 'relu')(x)\n",
    "    x1 = Dense(32)(x1)\n",
    "    x2=Dense(16)(x2)\n",
    "    x = concatenate([x, x1])\n",
    "    # x = Dense(16, activation = 'relu')(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "    x = concatenate([x, x2])\n",
    "    # x = Dense(8, activation = 'relu')(x)\n",
    "    predictions = Dense(1, activation = 'sigmoid')(x)\n",
    "    model = Model(inputs = inputs, outputs = predictions)\n",
    "    # print(model.summary())\n",
    "    model.compile(optimizer = 'RMSprop',\n",
    "                  loss = 'binary_crossentropy',\n",
    "                  metrics = METRICS)\n",
    "    print(\"compile\")\n",
    "    model.fit(train_X, train_Y, epochs = epoch, batch_size = batch_size, validation_data = (test_X, test_Y), shuffle = True)\n",
    "\n",
    "    pre_test_y = model.predict(test_X, batch_size = batch_size)\n",
    "    pre_train_y = model.predict(train_X, batch_size = batch_size)\n",
    "    test_auc = metrics.roc_auc_score(test_Y, pre_test_y)\n",
    "    train_auc = metrics.roc_auc_score(train_Y, pre_train_y)\n",
    "    print(\"train_auc: \", train_auc)\n",
    "    print(\"test_auc: \", test_auc) \n",
    "    return test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7729, 201)\n",
      "[[-0.26561624  0.6098262  -0.7489904  ... -0.1892702  -0.05502736\n",
      "  -0.04134279]\n",
      " [-0.08210649  1.0355824  -0.14756107 ...  0.26529473  0.12473003\n",
      "  -0.3475637 ]\n",
      " [ 0.16567737  0.1714673  -0.4582674  ...  0.2556168   0.6704794\n",
      "  -0.39164355]\n",
      " ...\n",
      " [ 0.44168887 -0.89097124  0.2816825  ...  0.25535288 -1.2825674\n",
      "  -0.34212294]\n",
      " [ 0.17637229 -0.8362072   0.36467612 ...  0.1760975   0.07081997\n",
      "  -0.5411232 ]\n",
      " [ 0.00589546 -0.52265966  0.24159986 ... -0.13643426 -0.30098712\n",
      "  -0.34720504]]\n",
      "X.shape:  (200,)\n",
      "Y.shape:  (7729,)\n",
      "\n",
      "\n",
      "i:  0\n",
      "(None, 6600) (None, 6400) (None, 6600)\n",
      "compile\n",
      "Epoch 1/5\n",
      "218/218 [==============================] - 3s 8ms/step - loss: 0.3579 - tp: 4406.0000 - fp: 762.0000 - tn: 4354.0000 - fn: 748.0000 - accuracy: 0.8530 - precision: 0.8526 - recall: 0.8549 - auc: 0.9277 - val_loss: 0.3055 - val_tp: 319.0000 - val_fp: 39.0000 - val_tn: 366.0000 - val_fn: 49.0000 - val_accuracy: 0.8862 - val_precision: 0.8911 - val_recall: 0.8668 - val_auc: 0.9439\n",
      "Epoch 2/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3207 - tp: 3102.0000 - fp: 544.0000 - tn: 2916.0000 - fn: 394.0000 - accuracy: 0.8652 - precision: 0.8508 - recall: 0.8873 - auc: 0.9361 - val_loss: 0.2907 - val_tp: 318.0000 - val_fp: 41.0000 - val_tn: 364.0000 - val_fn: 50.0000 - val_accuracy: 0.8823 - val_precision: 0.8858 - val_recall: 0.8641 - val_auc: 0.9500\n",
      "Epoch 3/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3079 - tp: 3113.0000 - fp: 518.0000 - tn: 2942.0000 - fn: 383.0000 - accuracy: 0.8705 - precision: 0.8573 - recall: 0.8904 - auc: 0.9413 - val_loss: 0.2889 - val_tp: 335.0000 - val_fp: 54.0000 - val_tn: 351.0000 - val_fn: 33.0000 - val_accuracy: 0.8875 - val_precision: 0.8612 - val_recall: 0.9103 - val_auc: 0.9496\n",
      "Epoch 4/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.2944 - tp: 3133.0000 - fp: 507.0000 - tn: 2953.0000 - fn: 363.0000 - accuracy: 0.8749 - precision: 0.8607 - recall: 0.8962 - auc: 0.9456 - val_loss: 0.3536 - val_tp: 355.0000 - val_fp: 97.0000 - val_tn: 308.0000 - val_fn: 13.0000 - val_accuracy: 0.8577 - val_precision: 0.7854 - val_recall: 0.9647 - val_auc: 0.9467\n",
      "Epoch 5/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.2830 - tp: 3157.0000 - fp: 482.0000 - tn: 2978.0000 - fn: 339.0000 - accuracy: 0.8820 - precision: 0.8675 - recall: 0.9030 - auc: 0.9500 - val_loss: 0.2943 - val_tp: 316.0000 - val_fp: 35.0000 - val_tn: 370.0000 - val_fn: 52.0000 - val_accuracy: 0.8875 - val_precision: 0.9003 - val_recall: 0.8587 - val_auc: 0.9500\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "218/218 [==============================] - 0s 2ms/step\n",
      "train_auc:  0.9586335663549423\n",
      "test_auc:  0.950342190016103\n",
      "\n",
      "\n",
      "i:  1\n",
      "(None, 6600) (None, 6400) (None, 6600)\n",
      "compile\n",
      "Epoch 1/5\n",
      "218/218 [==============================] - 3s 8ms/step - loss: 0.3513 - tp: 3315.0000 - fp: 579.0000 - tn: 3291.0000 - fn: 544.0000 - accuracy: 0.8547 - precision: 0.8513 - recall: 0.8590 - auc: 0.9271 - val_loss: 0.3269 - val_tp: 326.0000 - val_fp: 54.0000 - val_tn: 346.0000 - val_fn: 47.0000 - val_accuracy: 0.8693 - val_precision: 0.8579 - val_recall: 0.8740 - val_auc: 0.9357\n",
      "Epoch 2/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3175 - tp: 3096.0000 - fp: 525.0000 - tn: 2940.0000 - fn: 395.0000 - accuracy: 0.8677 - precision: 0.8550 - recall: 0.8869 - auc: 0.9372 - val_loss: 0.3268 - val_tp: 326.0000 - val_fp: 53.0000 - val_tn: 347.0000 - val_fn: 47.0000 - val_accuracy: 0.8706 - val_precision: 0.8602 - val_recall: 0.8740 - val_auc: 0.9384\n",
      "Epoch 3/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3022 - tp: 3132.0000 - fp: 518.0000 - tn: 2947.0000 - fn: 359.0000 - accuracy: 0.8739 - precision: 0.8581 - recall: 0.8972 - auc: 0.9428 - val_loss: 0.3276 - val_tp: 322.0000 - val_fp: 47.0000 - val_tn: 353.0000 - val_fn: 51.0000 - val_accuracy: 0.8732 - val_precision: 0.8726 - val_recall: 0.8633 - val_auc: 0.9417\n",
      "Epoch 4/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.2918 - tp: 3121.0000 - fp: 474.0000 - tn: 2991.0000 - fn: 370.0000 - accuracy: 0.8787 - precision: 0.8682 - recall: 0.8940 - auc: 0.9473 - val_loss: 0.3002 - val_tp: 324.0000 - val_fp: 54.0000 - val_tn: 346.0000 - val_fn: 49.0000 - val_accuracy: 0.8668 - val_precision: 0.8571 - val_recall: 0.8686 - val_auc: 0.9446\n",
      "Epoch 5/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.2791 - tp: 3157.0000 - fp: 480.0000 - tn: 2985.0000 - fn: 334.0000 - accuracy: 0.8830 - precision: 0.8680 - recall: 0.9043 - auc: 0.9514 - val_loss: 0.3051 - val_tp: 314.0000 - val_fp: 47.0000 - val_tn: 353.0000 - val_fn: 59.0000 - val_accuracy: 0.8629 - val_precision: 0.8698 - val_recall: 0.8418 - val_auc: 0.9438\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "218/218 [==============================] - 0s 2ms/step\n",
      "train_auc:  0.9621703799876243\n",
      "test_auc:  0.9439142091152815\n",
      "\n",
      "\n",
      "i:  2\n",
      "(None, 6600) (None, 6400) (None, 6600)\n",
      "compile\n",
      "Epoch 1/5\n",
      "218/218 [==============================] - 3s 9ms/step - loss: 0.3528 - tp: 3290.0000 - fp: 576.0000 - tn: 3316.0000 - fn: 547.0000 - accuracy: 0.8547 - precision: 0.8510 - recall: 0.8574 - auc: 0.9267 - val_loss: 0.3672 - val_tp: 347.0000 - val_fp: 61.0000 - val_tn: 312.0000 - val_fn: 53.0000 - val_accuracy: 0.8525 - val_precision: 0.8505 - val_recall: 0.8675 - val_auc: 0.9227\n",
      "Epoch 2/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3175 - tp: 3041.0000 - fp: 520.0000 - tn: 2972.0000 - fn: 423.0000 - accuracy: 0.8644 - precision: 0.8540 - recall: 0.8779 - auc: 0.9380 - val_loss: 0.3351 - val_tp: 358.0000 - val_fp: 60.0000 - val_tn: 313.0000 - val_fn: 42.0000 - val_accuracy: 0.8680 - val_precision: 0.8565 - val_recall: 0.8950 - val_auc: 0.9279\n",
      "Epoch 3/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3020 - tp: 3094.0000 - fp: 490.0000 - tn: 3002.0000 - fn: 370.0000 - accuracy: 0.8764 - precision: 0.8633 - recall: 0.8932 - auc: 0.9433 - val_loss: 0.3260 - val_tp: 356.0000 - val_fp: 66.0000 - val_tn: 307.0000 - val_fn: 44.0000 - val_accuracy: 0.8577 - val_precision: 0.8436 - val_recall: 0.8900 - val_auc: 0.9307\n",
      "Epoch 4/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.2894 - tp: 3098.0000 - fp: 484.0000 - tn: 3008.0000 - fn: 366.0000 - accuracy: 0.8778 - precision: 0.8649 - recall: 0.8943 - auc: 0.9482 - val_loss: 0.3414 - val_tp: 355.0000 - val_fp: 64.0000 - val_tn: 309.0000 - val_fn: 45.0000 - val_accuracy: 0.8590 - val_precision: 0.8473 - val_recall: 0.8875 - val_auc: 0.9296\n",
      "Epoch 5/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.2789 - tp: 3108.0000 - fp: 449.0000 - tn: 3043.0000 - fn: 356.0000 - accuracy: 0.8843 - precision: 0.8738 - recall: 0.8972 - auc: 0.9523 - val_loss: 0.3459 - val_tp: 369.0000 - val_fp: 78.0000 - val_tn: 295.0000 - val_fn: 31.0000 - val_accuracy: 0.8590 - val_precision: 0.8255 - val_recall: 0.9225 - val_auc: 0.9270\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "218/218 [==============================] - 0s 2ms/step\n",
      "train_auc:  0.9615039754344474\n",
      "test_auc:  0.927171581769437\n",
      "\n",
      "\n",
      "i:  3\n",
      "(None, 6600) (None, 6400) (None, 6600)\n",
      "compile\n",
      "Epoch 1/5\n",
      "218/218 [==============================] - 3s 7ms/step - loss: 0.3583 - tp: 3338.0000 - fp: 641.0000 - tn: 3205.0000 - fn: 545.0000 - accuracy: 0.8466 - precision: 0.8389 - recall: 0.8596 - auc: 0.9226 - val_loss: 0.3599 - val_tp: 286.0000 - val_fp: 34.0000 - val_tn: 358.0000 - val_fn: 95.0000 - val_accuracy: 0.8331 - val_precision: 0.8938 - val_recall: 0.7507 - val_auc: 0.9334\n",
      "Epoch 2/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3215 - tp: 3057.0000 - fp: 531.0000 - tn: 2942.0000 - fn: 426.0000 - accuracy: 0.8624 - precision: 0.8520 - recall: 0.8777 - auc: 0.9362 - val_loss: 0.3638 - val_tp: 348.0000 - val_fp: 84.0000 - val_tn: 308.0000 - val_fn: 33.0000 - val_accuracy: 0.8486 - val_precision: 0.8056 - val_recall: 0.9134 - val_auc: 0.9204\n",
      "Epoch 3/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3077 - tp: 3089.0000 - fp: 504.0000 - tn: 2969.0000 - fn: 394.0000 - accuracy: 0.8709 - precision: 0.8597 - recall: 0.8869 - auc: 0.9415 - val_loss: 0.3209 - val_tp: 337.0000 - val_fp: 54.0000 - val_tn: 338.0000 - val_fn: 44.0000 - val_accuracy: 0.8732 - val_precision: 0.8619 - val_recall: 0.8845 - val_auc: 0.9387\n",
      "Epoch 4/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.2973 - tp: 3112.0000 - fp: 478.0000 - tn: 2995.0000 - fn: 371.0000 - accuracy: 0.8779 - precision: 0.8669 - recall: 0.8935 - auc: 0.9457 - val_loss: 0.3129 - val_tp: 360.0000 - val_fp: 76.0000 - val_tn: 316.0000 - val_fn: 21.0000 - val_accuracy: 0.8745 - val_precision: 0.8257 - val_recall: 0.9449 - val_auc: 0.9419\n",
      "Epoch 5/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.2899 - tp: 3120.0000 - fp: 512.0000 - tn: 2961.0000 - fn: 363.0000 - accuracy: 0.8742 - precision: 0.8590 - recall: 0.8958 - auc: 0.9480 - val_loss: 0.2996 - val_tp: 357.0000 - val_fp: 67.0000 - val_tn: 325.0000 - val_fn: 24.0000 - val_accuracy: 0.8823 - val_precision: 0.8420 - val_recall: 0.9370 - val_auc: 0.9450\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "218/218 [==============================] - 0s 2ms/step\n",
      "train_auc:  0.9570649559511588\n",
      "test_auc:  0.9450091060046065\n",
      "\n",
      "\n",
      "i:  4\n",
      "(None, 6600) (None, 6400) (None, 6600)\n",
      "compile\n",
      "Epoch 1/5\n",
      "218/218 [==============================] - 3s 10ms/step - loss: 0.3552 - tp: 3316.0000 - fp: 618.0000 - tn: 3262.0000 - fn: 533.0000 - accuracy: 0.8511 - precision: 0.8429 - recall: 0.8615 - auc: 0.9243 - val_loss: 0.2871 - val_tp: 363.0000 - val_fp: 61.0000 - val_tn: 316.0000 - val_fn: 33.0000 - val_accuracy: 0.8784 - val_precision: 0.8561 - val_recall: 0.9167 - val_auc: 0.9480\n",
      "Epoch 2/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3170 - tp: 3070.0000 - fp: 536.0000 - tn: 2952.0000 - fn: 398.0000 - accuracy: 0.8657 - precision: 0.8514 - recall: 0.8852 - auc: 0.9376 - val_loss: 0.2996 - val_tp: 377.0000 - val_fp: 80.0000 - val_tn: 297.0000 - val_fn: 19.0000 - val_accuracy: 0.8719 - val_precision: 0.8249 - val_recall: 0.9520 - val_auc: 0.9498\n",
      "Epoch 3/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3059 - tp: 3087.0000 - fp: 508.0000 - tn: 2980.0000 - fn: 381.0000 - accuracy: 0.8722 - precision: 0.8587 - recall: 0.8901 - auc: 0.9414 - val_loss: 0.3115 - val_tp: 332.0000 - val_fp: 37.0000 - val_tn: 340.0000 - val_fn: 64.0000 - val_accuracy: 0.8693 - val_precision: 0.8997 - val_recall: 0.8384 - val_auc: 0.9520\n",
      "Epoch 4/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.2949 - tp: 3091.0000 - fp: 502.0000 - tn: 2986.0000 - fn: 377.0000 - accuracy: 0.8736 - precision: 0.8603 - recall: 0.8913 - auc: 0.9462 - val_loss: 0.2731 - val_tp: 356.0000 - val_fp: 53.0000 - val_tn: 324.0000 - val_fn: 40.0000 - val_accuracy: 0.8797 - val_precision: 0.8704 - val_recall: 0.8990 - val_auc: 0.9537\n",
      "Epoch 5/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.2868 - tp: 3092.0000 - fp: 481.0000 - tn: 3007.0000 - fn: 376.0000 - accuracy: 0.8768 - precision: 0.8654 - recall: 0.8916 - auc: 0.9489 - val_loss: 0.2888 - val_tp: 353.0000 - val_fp: 53.0000 - val_tn: 324.0000 - val_fn: 43.0000 - val_accuracy: 0.8758 - val_precision: 0.8695 - val_recall: 0.8914 - val_auc: 0.9485\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "218/218 [==============================] - 0s 1ms/step\n",
      "train_auc:  0.9602419202300455\n",
      "test_auc:  0.9485103019585779\n",
      "\n",
      "\n",
      "i:  5\n",
      "(None, 6600) (None, 6400) (None, 6600)\n",
      "compile\n",
      "Epoch 1/5\n",
      "218/218 [==============================] - 3s 8ms/step - loss: 0.3528 - tp: 3332.0000 - fp: 577.0000 - tn: 3273.0000 - fn: 547.0000 - accuracy: 0.8546 - precision: 0.8524 - recall: 0.8590 - auc: 0.9266 - val_loss: 0.3474 - val_tp: 335.0000 - val_fp: 70.0000 - val_tn: 322.0000 - val_fn: 46.0000 - val_accuracy: 0.8499 - val_precision: 0.8272 - val_recall: 0.8793 - val_auc: 0.9268\n",
      "Epoch 2/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3179 - tp: 3070.0000 - fp: 508.0000 - tn: 2965.0000 - fn: 413.0000 - accuracy: 0.8676 - precision: 0.8580 - recall: 0.8814 - auc: 0.9374 - val_loss: 0.3275 - val_tp: 332.0000 - val_fp: 64.0000 - val_tn: 328.0000 - val_fn: 49.0000 - val_accuracy: 0.8538 - val_precision: 0.8384 - val_recall: 0.8714 - val_auc: 0.9344\n",
      "Epoch 3/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3012 - tp: 3099.0000 - fp: 510.0000 - tn: 2963.0000 - fn: 384.0000 - accuracy: 0.8715 - precision: 0.8587 - recall: 0.8898 - auc: 0.9440 - val_loss: 0.4290 - val_tp: 369.0000 - val_fp: 139.0000 - val_tn: 253.0000 - val_fn: 12.0000 - val_accuracy: 0.8047 - val_precision: 0.7264 - val_recall: 0.9685 - val_auc: 0.9351\n",
      "Epoch 4/5\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.2939 - tp: 3131.0000 - fp: 486.0000 - tn: 2987.0000 - fn: 352.0000 - accuracy: 0.8795 - precision: 0.8656 - recall: 0.8989 - auc: 0.9466 - val_loss: 0.3652 - val_tp: 357.0000 - val_fp: 96.0000 - val_tn: 296.0000 - val_fn: 24.0000 - val_accuracy: 0.8448 - val_precision: 0.7881 - val_recall: 0.9370 - val_auc: 0.9357\n",
      "Epoch 5/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.2850 - tp: 3119.0000 - fp: 477.0000 - tn: 2996.0000 - fn: 364.0000 - accuracy: 0.8791 - precision: 0.8674 - recall: 0.8955 - auc: 0.9497 - val_loss: 0.3231 - val_tp: 316.0000 - val_fp: 45.0000 - val_tn: 347.0000 - val_fn: 65.0000 - val_accuracy: 0.8577 - val_precision: 0.8753 - val_recall: 0.8294 - val_auc: 0.9393\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "218/218 [==============================] - 0s 2ms/step\n",
      "train_auc:  0.9590335485781418\n",
      "test_auc:  0.93923081043441\n",
      "\n",
      "\n",
      "i:  6\n",
      "(None, 6600) (None, 6400) (None, 6600)\n",
      "compile\n",
      "Epoch 1/5\n",
      "218/218 [==============================] - 3s 8ms/step - loss: 0.3568 - tp: 3278.0000 - fp: 584.0000 - tn: 3292.0000 - fn: 575.0000 - accuracy: 0.8500 - precision: 0.8488 - recall: 0.8508 - auc: 0.9240 - val_loss: 0.2972 - val_tp: 333.0000 - val_fp: 29.0000 - val_tn: 352.0000 - val_fn: 59.0000 - val_accuracy: 0.8862 - val_precision: 0.9199 - val_recall: 0.8495 - val_auc: 0.9500\n",
      "Epoch 2/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3188 - tp: 3056.0000 - fp: 523.0000 - tn: 2961.0000 - fn: 416.0000 - accuracy: 0.8650 - precision: 0.8539 - recall: 0.8802 - auc: 0.9372 - val_loss: 0.2885 - val_tp: 359.0000 - val_fp: 59.0000 - val_tn: 322.0000 - val_fn: 33.0000 - val_accuracy: 0.8810 - val_precision: 0.8589 - val_recall: 0.9158 - val_auc: 0.9505\n",
      "Epoch 3/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3061 - tp: 3099.0000 - fp: 501.0000 - tn: 2983.0000 - fn: 373.0000 - accuracy: 0.8744 - precision: 0.8608 - recall: 0.8926 - auc: 0.9419 - val_loss: 0.2974 - val_tp: 369.0000 - val_fp: 71.0000 - val_tn: 310.0000 - val_fn: 23.0000 - val_accuracy: 0.8784 - val_precision: 0.8386 - val_recall: 0.9413 - val_auc: 0.9473\n",
      "Epoch 4/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.2938 - tp: 3100.0000 - fp: 487.0000 - tn: 2997.0000 - fn: 372.0000 - accuracy: 0.8765 - precision: 0.8642 - recall: 0.8929 - auc: 0.9466 - val_loss: 0.2830 - val_tp: 337.0000 - val_fp: 40.0000 - val_tn: 341.0000 - val_fn: 55.0000 - val_accuracy: 0.8771 - val_precision: 0.8939 - val_recall: 0.8597 - val_auc: 0.9520\n",
      "Epoch 5/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.2853 - tp: 3111.0000 - fp: 487.0000 - tn: 2997.0000 - fn: 361.0000 - accuracy: 0.8781 - precision: 0.8646 - recall: 0.8960 - auc: 0.9495 - val_loss: 0.2856 - val_tp: 359.0000 - val_fp: 56.0000 - val_tn: 325.0000 - val_fn: 33.0000 - val_accuracy: 0.8849 - val_precision: 0.8651 - val_recall: 0.9158 - val_auc: 0.9498\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "218/218 [==============================] - 0s 2ms/step\n",
      "train_auc:  0.9592958197315444\n",
      "test_auc:  0.949970539396861\n",
      "\n",
      "\n",
      "i:  7\n",
      "(None, 6600) (None, 6400) (None, 6600)\n",
      "compile\n",
      "Epoch 1/5\n",
      "218/218 [==============================] - 3s 7ms/step - loss: 0.3511 - tp: 3336.0000 - fp: 603.0000 - tn: 3264.0000 - fn: 526.0000 - accuracy: 0.8539 - precision: 0.8469 - recall: 0.8638 - auc: 0.9268 - val_loss: 0.3436 - val_tp: 335.0000 - val_fp: 50.0000 - val_tn: 329.0000 - val_fn: 59.0000 - val_accuracy: 0.8590 - val_precision: 0.8701 - val_recall: 0.8503 - val_auc: 0.9345\n",
      "Epoch 2/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3181 - tp: 3051.0000 - fp: 519.0000 - tn: 2967.0000 - fn: 419.0000 - accuracy: 0.8652 - precision: 0.8546 - recall: 0.8793 - auc: 0.9370 - val_loss: 0.3329 - val_tp: 341.0000 - val_fp: 57.0000 - val_tn: 322.0000 - val_fn: 53.0000 - val_accuracy: 0.8577 - val_precision: 0.8568 - val_recall: 0.8655 - val_auc: 0.9366\n",
      "Epoch 3/5\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.3047 - tp: 3085.0000 - fp: 530.0000 - tn: 2956.0000 - fn: 385.0000 - accuracy: 0.8685 - precision: 0.8534 - recall: 0.8890 - auc: 0.9425 - val_loss: 0.3177 - val_tp: 354.0000 - val_fp: 58.0000 - val_tn: 321.0000 - val_fn: 40.0000 - val_accuracy: 0.8732 - val_precision: 0.8592 - val_recall: 0.8985 - val_auc: 0.9396\n",
      "Epoch 4/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.2939 - tp: 3116.0000 - fp: 498.0000 - tn: 2988.0000 - fn: 354.0000 - accuracy: 0.8775 - precision: 0.8622 - recall: 0.8980 - auc: 0.9465 - val_loss: 0.3283 - val_tp: 353.0000 - val_fp: 66.0000 - val_tn: 313.0000 - val_fn: 41.0000 - val_accuracy: 0.8616 - val_precision: 0.8425 - val_recall: 0.8959 - val_auc: 0.9347\n",
      "Epoch 5/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.2865 - tp: 3138.0000 - fp: 479.0000 - tn: 3007.0000 - fn: 332.0000 - accuracy: 0.8834 - precision: 0.8676 - recall: 0.9043 - auc: 0.9492 - val_loss: 0.3648 - val_tp: 375.0000 - val_fp: 93.0000 - val_tn: 286.0000 - val_fn: 19.0000 - val_accuracy: 0.8551 - val_precision: 0.8013 - val_recall: 0.9518 - val_auc: 0.9378\n",
      "25/25 [==============================] - 0s 1ms/step\n",
      "218/218 [==============================] - 0s 2ms/step\n",
      "train_auc:  0.9602248020488705\n",
      "test_auc:  0.9377670332025233\n",
      "\n",
      "\n",
      "i:  8\n",
      "(None, 6600) (None, 6400) (None, 6600)\n",
      "compile\n",
      "Epoch 1/5\n",
      "218/218 [==============================] - 3s 8ms/step - loss: 0.3505 - tp: 3358.0000 - fp: 611.0000 - tn: 3246.0000 - fn: 514.0000 - accuracy: 0.8544 - precision: 0.8461 - recall: 0.8673 - auc: 0.9245 - val_loss: 0.3374 - val_tp: 323.0000 - val_fp: 51.0000 - val_tn: 336.0000 - val_fn: 63.0000 - val_accuracy: 0.8525 - val_precision: 0.8636 - val_recall: 0.8368 - val_auc: 0.9307\n",
      "Epoch 2/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3160 - tp: 3081.0000 - fp: 501.0000 - tn: 2977.0000 - fn: 397.0000 - accuracy: 0.8709 - precision: 0.8601 - recall: 0.8859 - auc: 0.9383 - val_loss: 0.3347 - val_tp: 326.0000 - val_fp: 53.0000 - val_tn: 334.0000 - val_fn: 60.0000 - val_accuracy: 0.8538 - val_precision: 0.8602 - val_recall: 0.8446 - val_auc: 0.9321\n",
      "Epoch 3/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3044 - tp: 3095.0000 - fp: 501.0000 - tn: 2977.0000 - fn: 383.0000 - accuracy: 0.8729 - precision: 0.8607 - recall: 0.8899 - auc: 0.9427 - val_loss: 0.3436 - val_tp: 350.0000 - val_fp: 73.0000 - val_tn: 314.0000 - val_fn: 36.0000 - val_accuracy: 0.8590 - val_precision: 0.8274 - val_recall: 0.9067 - val_auc: 0.9342\n",
      "Epoch 4/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.2936 - tp: 3126.0000 - fp: 490.0000 - tn: 2988.0000 - fn: 352.0000 - accuracy: 0.8790 - precision: 0.8645 - recall: 0.8988 - auc: 0.9463 - val_loss: 0.3282 - val_tp: 350.0000 - val_fp: 69.0000 - val_tn: 318.0000 - val_fn: 36.0000 - val_accuracy: 0.8642 - val_precision: 0.8353 - val_recall: 0.9067 - val_auc: 0.9373\n",
      "Epoch 5/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.2816 - tp: 3120.0000 - fp: 484.0000 - tn: 2994.0000 - fn: 358.0000 - accuracy: 0.8790 - precision: 0.8657 - recall: 0.8971 - auc: 0.9506 - val_loss: 0.3500 - val_tp: 359.0000 - val_fp: 87.0000 - val_tn: 300.0000 - val_fn: 27.0000 - val_accuracy: 0.8525 - val_precision: 0.8049 - val_recall: 0.9301 - val_auc: 0.9365\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "218/218 [==============================] - 0s 2ms/step\n",
      "train_auc:  0.9606541041181884\n",
      "test_auc:  0.9369803590794071\n",
      "\n",
      "\n",
      "i:  9\n",
      "(None, 6600) (None, 6400) (None, 6600)\n",
      "compile\n",
      "Epoch 1/5\n",
      "218/218 [==============================] - 3s 9ms/step - loss: 0.3550 - tp: 3317.0000 - fp: 615.0000 - tn: 3258.0000 - fn: 540.0000 - accuracy: 0.8506 - precision: 0.8436 - recall: 0.8600 - auc: 0.9232 - val_loss: 0.3343 - val_tp: 347.0000 - val_fp: 57.0000 - val_tn: 322.0000 - val_fn: 46.0000 - val_accuracy: 0.8666 - val_precision: 0.8589 - val_recall: 0.8830 - val_auc: 0.9328\n",
      "Epoch 2/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3190 - tp: 3080.0000 - fp: 546.0000 - tn: 2940.0000 - fn: 391.0000 - accuracy: 0.8653 - precision: 0.8494 - recall: 0.8874 - auc: 0.9363 - val_loss: 0.3250 - val_tp: 345.0000 - val_fp: 51.0000 - val_tn: 328.0000 - val_fn: 48.0000 - val_accuracy: 0.8718 - val_precision: 0.8712 - val_recall: 0.8779 - val_auc: 0.9374\n",
      "Epoch 3/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3051 - tp: 3100.0000 - fp: 523.0000 - tn: 2963.0000 - fn: 371.0000 - accuracy: 0.8715 - precision: 0.8556 - recall: 0.8931 - auc: 0.9418 - val_loss: 0.3385 - val_tp: 320.0000 - val_fp: 36.0000 - val_tn: 343.0000 - val_fn: 73.0000 - val_accuracy: 0.8588 - val_precision: 0.8989 - val_recall: 0.8142 - val_auc: 0.9390\n",
      "Epoch 4/5\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.2934 - tp: 3108.0000 - fp: 480.0000 - tn: 3006.0000 - fn: 363.0000 - accuracy: 0.8788 - precision: 0.8662 - recall: 0.8954 - auc: 0.9467 - val_loss: 0.3181 - val_tp: 355.0000 - val_fp: 59.0000 - val_tn: 320.0000 - val_fn: 38.0000 - val_accuracy: 0.8744 - val_precision: 0.8575 - val_recall: 0.9033 - val_auc: 0.9398\n",
      "Epoch 5/5\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.2856 - tp: 3118.0000 - fp: 480.0000 - tn: 3006.0000 - fn: 353.0000 - accuracy: 0.8803 - precision: 0.8666 - recall: 0.8983 - auc: 0.9494 - val_loss: 0.3489 - val_tp: 366.0000 - val_fp: 87.0000 - val_tn: 292.0000 - val_fn: 27.0000 - val_accuracy: 0.8523 - val_precision: 0.8079 - val_recall: 0.9313 - val_auc: 0.9403\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "218/218 [==============================] - 0s 2ms/step\n",
      "train_auc:  0.957490702820336\n",
      "test_auc:  0.9406701712689749\n",
      "Mean AUC: 0.9419566302246182\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = np.array(pd.read_csv(\"6_train.csv\"))\n",
    "pos_number = 3864 # NOTE: the number of postive sample in train file\n",
    "#CNN_model = 'CNN_model.h5'\n",
    "\n",
    "print(np.shape(data))\n",
    "X1 = data[0:pos_number, 1:]\n",
    "Y1 = data[0:pos_number, 0]\n",
    "X2 = data[pos_number:, 1:]\n",
    "Y2 = data[pos_number:, 0]\n",
    "X = np.concatenate([X1, X2], 0)\n",
    "Y = np.concatenate([Y1, Y2], 0)\n",
    "#Y = Y.reshape((Y.shape[0], -1))\n",
    "print (X)\n",
    "print (\"X.shape: \", X[0].shape)\n",
    "print (\"Y.shape: \", Y.shape)\n",
    "\n",
    "lr = 0.4\n",
    "epoch = 5\n",
    "batch_size = 32\n",
    "\n",
    "kf = KFold(n_splits = 10, shuffle = True)\n",
    "kf = kf.split(X)\n",
    "test_aucs = []\n",
    "\n",
    "for i, (train_fold, validate_fold) in enumerate(kf):\n",
    "    print(\"\\n\\ni: \", i)\n",
    "    test_auc = dnn_model(X[train_fold], Y[train_fold], X[validate_fold], Y[validate_fold], lr, epoch, batch_size)\n",
    "    test_aucs.append(test_auc)\n",
    "    \n",
    "w = open(\"train_Result.txt\", \"w\")\n",
    "for j in test_aucs: \n",
    "    w.write(str(j) + ',')\n",
    "w.write('\\n')\n",
    "w.write(str(np.mean(test_aucs)) + '\\n')\n",
    "w.close()\n",
    "print(\"Mean AUC:\", str(np.mean(test_aucs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Independent Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# data = np.array(pd.read_csv(\"6_vecs_test.csv\"))\n",
    "# # pos_number = 1105 # NOTE: the number of postive sample in test file\n",
    "# # pos_number = 899 #3863    \n",
    "# pos_number = 1658\n",
    "# X1 = data[0:pos_number, 1:]\n",
    "# Y1 = data[0:pos_number, 0]\n",
    "# X2 = data[pos_number:, 1:]\n",
    "# Y2 = data[pos_number:, 0]\n",
    "# X_test = np.concatenate([X1, X2], 0)\n",
    "# Y_test = np.concatenate([Y1, Y2], 0)\n",
    "\n",
    "\n",
    "data = np.array(pd.read_csv(\"cross_test.csv\"))\n",
    "pos_number = 899 #3863    \n",
    "# pos_number = 1658\n",
    "X1 = data[0:pos_number, 1:]\n",
    "Y1 = data[0:pos_number, 0]\n",
    "X2 = data[pos_number:, 1:]\n",
    "Y2 = data[pos_number:, 0]\n",
    "X_test = np.concatenate([X1, X2], 0)\n",
    "Y_test = np.concatenate([Y1, Y2], 0)\n",
    "\n",
    "\n",
    "lr = 0.01\n",
    "batch_size = 32\n",
    "\n",
    "data = np.array(pd.read_csv(\"6_train.csv\"))\n",
    "pos_number = 3864 # NOTE: the number of postive sample in train file\n",
    "#CNN_model = 'CNN_model.h5'\n",
    "\n",
    "\n",
    "X1 = data[0:pos_number, 1:]\n",
    "Y1 = data[0:pos_number, 0]\n",
    "X2 = data[pos_number:, 1:]\n",
    "Y2 = data[pos_number:, 0]\n",
    "X = np.concatenate([X1, X2], 0)\n",
    "Y = np.concatenate([Y1, Y2], 0)\n",
    "\n",
    "\n",
    "test_auc = dnn_model(X, Y, X_test, Y_test, lr, 6, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 6600) (None, 6400) (None, 6600)\n",
      "compile\n",
      "Epoch 1/6\n",
      "242/242 [==============================] - 3s 9ms/step - loss: 0.3488 - tp: 4128.0000 - fp: 731.0000 - tn: 4032.0000 - fn: 635.0000 - accuracy: 0.8566 - precision: 0.8496 - recall: 0.8667 - auc: 0.9299 - val_loss: 0.3218 - val_tp: 798.0000 - val_fp: 151.0000 - val_tn: 747.0000 - val_fn: 101.0000 - val_accuracy: 0.8598 - val_precision: 0.8409 - val_recall: 0.8877 - val_auc: 0.9390\n",
      "Epoch 2/6\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3151 - tp: 3422.0000 - fp: 566.0000 - tn: 3299.0000 - fn: 442.0000 - accuracy: 0.8696 - precision: 0.8581 - recall: 0.8856 - auc: 0.9385 - val_loss: 0.3224 - val_tp: 840.0000 - val_fp: 201.0000 - val_tn: 697.0000 - val_fn: 59.0000 - val_accuracy: 0.8553 - val_precision: 0.8069 - val_recall: 0.9344 - val_auc: 0.9433\n",
      "Epoch 3/6\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3020 - tp: 3444.0000 - fp: 565.0000 - tn: 3300.0000 - fn: 420.0000 - accuracy: 0.8726 - precision: 0.8591 - recall: 0.8913 - auc: 0.9433 - val_loss: 0.3379 - val_tp: 828.0000 - val_fp: 177.0000 - val_tn: 721.0000 - val_fn: 71.0000 - val_accuracy: 0.8620 - val_precision: 0.8239 - val_recall: 0.9210 - val_auc: 0.9442\n",
      "Epoch 4/6\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2940 - tp: 3467.0000 - fp: 572.0000 - tn: 3293.0000 - fn: 397.0000 - accuracy: 0.8746 - precision: 0.8584 - recall: 0.8973 - auc: 0.9462 - val_loss: 0.3068 - val_tp: 827.0000 - val_fp: 163.0000 - val_tn: 735.0000 - val_fn: 72.0000 - val_accuracy: 0.8692 - val_precision: 0.8354 - val_recall: 0.9199 - val_auc: 0.9478\n",
      "Epoch 5/6\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2816 - tp: 3471.0000 - fp: 524.0000 - tn: 3341.0000 - fn: 393.0000 - accuracy: 0.8814 - precision: 0.8688 - recall: 0.8983 - auc: 0.9506 - val_loss: 0.3246 - val_tp: 811.0000 - val_fp: 147.0000 - val_tn: 751.0000 - val_fn: 88.0000 - val_accuracy: 0.8692 - val_precision: 0.8466 - val_recall: 0.9021 - val_auc: 0.9443\n",
      "Epoch 6/6\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2730 - tp: 3489.0000 - fp: 499.0000 - tn: 3366.0000 - fn: 375.0000 - accuracy: 0.8869 - precision: 0.8749 - recall: 0.9030 - auc: 0.9539 - val_loss: 0.3178 - val_tp: 822.0000 - val_fp: 164.0000 - val_tn: 734.0000 - val_fn: 77.0000 - val_accuracy: 0.8659 - val_precision: 0.8337 - val_recall: 0.9143 - val_auc: 0.9476\n",
      "57/57 [==============================] - 0s 2ms/step\n",
      "242/242 [==============================] - 0s 2ms/step\n",
      "train_auc:  0.9620423640517571\n",
      "test_auc:  0.949237088474945\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# test_auc = dnn_model(X_train, y_train, X_test, y_test, lr, 5, 32)\n",
    "\n",
    "\n",
    "test_auc = dnn_model(X, Y, X_test, Y_test, lr, 6, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
