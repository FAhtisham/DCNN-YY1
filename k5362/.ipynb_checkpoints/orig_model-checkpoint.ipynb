{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.layers import Input, Dense, Conv1D, Flatten, MaxPooling1D, Conv2D, MaxPooling2D, AveragePooling2D, Dropout, Reshape, normalization\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.layers.recurrent import LSTM\n",
    "from sklearn import metrics\n",
    "import random\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    # Calculates the precision\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    # Calculates the recall\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1(test_Y, pre_test_y):\n",
    "    \"\"\"F1-score\"\"\"\n",
    "    Precision = precision(test_Y, pre_test_y)\n",
    "    Recall = recall(test_Y, pre_test_y)\n",
    "    f1 = 2 * ((Precision * Recall) / (Precision + Recall + K.epsilon()))\n",
    "    return f1 \n",
    "\n",
    "def TP(test_Y,pre_test_y):\n",
    "    TP = K.sum(K.round(K.clip(test_Y * pre_test_y, 0, 1)))#TP\n",
    "    return TP\n",
    "\n",
    "def FN(test_Y,pre_test_y):\n",
    "    TP = K.sum(K.round(K.clip(test_Y * pre_test_y, 0, 1)))#TP\n",
    "    P=K.sum(K.round(K.clip(test_Y, 0, 1)))\n",
    "    FN = P-TP #FN=P-TP\n",
    "    return FN\n",
    "\n",
    "def TN(test_Y,pre_test_y):\n",
    "    TN=K.sum(K.round(K.clip((test_Y-K.ones_like(test_Y))*(pre_test_y-K.ones_like(pre_test_y)), 0, 1)))#TN\n",
    "    return TN\n",
    "\n",
    "def FP(test_Y,pre_test_y):\n",
    "    N = (-1)*K.sum(K.round(K.clip(test_Y-K.ones_like(test_Y), -1, 0)))#N\n",
    "    TN=K.sum(K.round(K.clip((test_Y-K.ones_like(test_Y))*(pre_test_y-K.ones_like(pre_test_y)), 0, 1)))#TN\n",
    "    FP=N-TN\n",
    "    return FP\n",
    "\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "def dnn_model(train_X, train_Y, test_X, test_Y, lr, epoch, batch_size):\n",
    "    train_X = np.expand_dims(train_X, 2)\n",
    "    test_X = np.expand_dims(test_X, 2)\n",
    "    inputs = Input(shape = (train_X.shape[1], train_X.shape[2]))\n",
    "    x = Conv1D(32, kernel_size = 3, strides = 1, padding = 'valid', activation = 'relu')(inputs)\n",
    "    x = MaxPooling1D(pool_size = 2, strides = 2, padding = 'same')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(32, activation = 'relu')(x)\n",
    "    x = Dense(16, activation = 'relu')(x)\n",
    "    x = Dense(8, activation = 'relu')(x)\n",
    "    predictions = Dense(1, activation = 'sigmoid')(x)\n",
    "    model = Model(inputs = inputs, outputs = predictions)\n",
    "    print(\"model\")\n",
    "    model.compile(optimizer = 'RMSprop',\n",
    "                  loss = 'mean_squared_error',\n",
    "                  metrics = METRICS)\n",
    "    print(\"compile\")\n",
    "    model.fit(train_X, train_Y, epochs = epoch, batch_size = 32, validation_data = (test_X, test_Y), shuffle = True)\n",
    "    model.save('CNN_model.h5')\n",
    "    pre_test_y = model.predict(test_X, batch_size = 50)\n",
    "    pre_train_y = model.predict(train_X, batch_size = 50)\n",
    "    test_auc = metrics.roc_auc_score(test_Y, pre_test_y)\n",
    "    train_auc = metrics.roc_auc_score(train_Y, pre_train_y)\n",
    "    print(\"train_auc: \", train_auc)\n",
    "    print(\"test_auc: \", test_auc) \n",
    "    return test_auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.20644704 -0.45706296 -0.2562405  ... -1.4206289   0.9298074\n",
      "  -1.0609802 ]\n",
      " [-1.2384602   1.7543772   0.9248372  ... -1.8391443   1.139564\n",
      "  -0.7542995 ]\n",
      " [-0.05409286  0.21270198 -0.27500126 ...  0.64489275  0.15629809\n",
      "  -0.22529553]\n",
      " ...\n",
      " [ 0.9653186  -0.08109022 -0.68847555 ...  1.4501451  -0.49036932\n",
      "  -0.16801585]\n",
      " [ 0.41178006 -0.64946824 -0.43891364 ...  0.25375736  0.06554881\n",
      "  -0.01694088]\n",
      " [ 0.910602   -0.45758218 -0.7318825  ...  0.3283448  -0.02965107\n",
      "  -0.2959396 ]]\n",
      "X.shape:  (5989, 200)\n",
      "Y.shape:  (5989,)\n",
      "\n",
      "\n",
      "i:  0\n",
      "model\n",
      "compile\n",
      "Epoch 1/20\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.1185 - tp: 2468.0000 - fp: 443.0000 - tn: 2589.0000 - fn: 488.0000 - accuracy: 0.8445 - precision: 0.8478 - recall: 0.8349 - auc: 0.9209 - val_loss: 0.1024 - val_tp: 505.0000 - val_fp: 60.0000 - val_tn: 523.0000 - val_fn: 110.0000 - val_accuracy: 0.8581 - val_precision: 0.8938 - val_recall: 0.8211 - val_auc: 0.9367\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1049 - tp: 2015.0000 - fp: 347.0000 - tn: 2065.0000 - fn: 364.0000 - accuracy: 0.8516 - precision: 0.8531 - recall: 0.8470 - auc: 0.9310 - val_loss: 0.1189 - val_tp: 450.0000 - val_fp: 30.0000 - val_tn: 553.0000 - val_fn: 165.0000 - val_accuracy: 0.8372 - val_precision: 0.9375 - val_recall: 0.7317 - val_auc: 0.9424\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1004 - tp: 2034.0000 - fp: 335.0000 - tn: 2077.0000 - fn: 345.0000 - accuracy: 0.8581 - precision: 0.8586 - recall: 0.8550 - auc: 0.9370 - val_loss: 0.0957 - val_tp: 544.0000 - val_fp: 88.0000 - val_tn: 495.0000 - val_fn: 71.0000 - val_accuracy: 0.8673 - val_precision: 0.8608 - val_recall: 0.8846 - val_auc: 0.9423\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0962 - tp: 2068.0000 - fp: 325.0000 - tn: 2087.0000 - fn: 311.0000 - accuracy: 0.8673 - precision: 0.8642 - recall: 0.8693 - auc: 0.9406 - val_loss: 0.0965 - val_tp: 556.0000 - val_fp: 100.0000 - val_tn: 483.0000 - val_fn: 59.0000 - val_accuracy: 0.8673 - val_precision: 0.8476 - val_recall: 0.9041 - val_auc: 0.9422\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0950 - tp: 2075.0000 - fp: 321.0000 - tn: 2091.0000 - fn: 304.0000 - accuracy: 0.8695 - precision: 0.8660 - recall: 0.8722 - auc: 0.9428 - val_loss: 0.0995 - val_tp: 497.0000 - val_fp: 56.0000 - val_tn: 527.0000 - val_fn: 118.0000 - val_accuracy: 0.8548 - val_precision: 0.8987 - val_recall: 0.8081 - val_auc: 0.9447\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0947 - tp: 2072.0000 - fp: 334.0000 - tn: 2078.0000 - fn: 307.0000 - accuracy: 0.8662 - precision: 0.8612 - recall: 0.8710 - auc: 0.9433 - val_loss: 0.0944 - val_tp: 547.0000 - val_fp: 95.0000 - val_tn: 488.0000 - val_fn: 68.0000 - val_accuracy: 0.8639 - val_precision: 0.8520 - val_recall: 0.8894 - val_auc: 0.9444\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0932 - tp: 2087.0000 - fp: 332.0000 - tn: 2080.0000 - fn: 292.0000 - accuracy: 0.8698 - precision: 0.8628 - recall: 0.8773 - auc: 0.9449 - val_loss: 0.1048 - val_tp: 483.0000 - val_fp: 44.0000 - val_tn: 539.0000 - val_fn: 132.0000 - val_accuracy: 0.8531 - val_precision: 0.9165 - val_recall: 0.7854 - val_auc: 0.9454\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0900 - tp: 2086.0000 - fp: 314.0000 - tn: 2098.0000 - fn: 293.0000 - accuracy: 0.8733 - precision: 0.8692 - recall: 0.8768 - auc: 0.9483 - val_loss: 0.0941 - val_tp: 546.0000 - val_fp: 92.0000 - val_tn: 491.0000 - val_fn: 69.0000 - val_accuracy: 0.8656 - val_precision: 0.8558 - val_recall: 0.8878 - val_auc: 0.9450\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0898 - tp: 2108.0000 - fp: 317.0000 - tn: 2095.0000 - fn: 271.0000 - accuracy: 0.8773 - precision: 0.8693 - recall: 0.8861 - auc: 0.9481 - val_loss: 0.0947 - val_tp: 520.0000 - val_fp: 68.0000 - val_tn: 515.0000 - val_fn: 95.0000 - val_accuracy: 0.8639 - val_precision: 0.8844 - val_recall: 0.8455 - val_auc: 0.9461\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0891 - tp: 2103.0000 - fp: 314.0000 - tn: 2098.0000 - fn: 276.0000 - accuracy: 0.8769 - precision: 0.8701 - recall: 0.8840 - auc: 0.9487 - val_loss: 0.0948 - val_tp: 563.0000 - val_fp: 112.0000 - val_tn: 471.0000 - val_fn: 52.0000 - val_accuracy: 0.8631 - val_precision: 0.8341 - val_recall: 0.9154 - val_auc: 0.9453\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0891 - tp: 2108.0000 - fp: 308.0000 - tn: 2104.0000 - fn: 271.0000 - accuracy: 0.8791 - precision: 0.8725 - recall: 0.8861 - auc: 0.9488 - val_loss: 0.0951 - val_tp: 560.0000 - val_fp: 104.0000 - val_tn: 479.0000 - val_fn: 55.0000 - val_accuracy: 0.8673 - val_precision: 0.8434 - val_recall: 0.9106 - val_auc: 0.9443\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0867 - tp: 2109.0000 - fp: 320.0000 - tn: 2092.0000 - fn: 270.0000 - accuracy: 0.8769 - precision: 0.8683 - recall: 0.8865 - auc: 0.9515 - val_loss: 0.0975 - val_tp: 505.0000 - val_fp: 58.0000 - val_tn: 525.0000 - val_fn: 110.0000 - val_accuracy: 0.8598 - val_precision: 0.8970 - val_recall: 0.8211 - val_auc: 0.9469\n",
      "Epoch 13/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0863 - tp: 2117.0000 - fp: 299.0000 - tn: 2113.0000 - fn: 262.0000 - accuracy: 0.8829 - precision: 0.8762 - recall: 0.8899 - auc: 0.9510 - val_loss: 0.0926 - val_tp: 528.0000 - val_fp: 74.0000 - val_tn: 509.0000 - val_fn: 87.0000 - val_accuracy: 0.8656 - val_precision: 0.8771 - val_recall: 0.8585 - val_auc: 0.9470\n",
      "Epoch 14/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0843 - tp: 2130.0000 - fp: 303.0000 - tn: 2109.0000 - fn: 249.0000 - accuracy: 0.8848 - precision: 0.8755 - recall: 0.8953 - auc: 0.9533 - val_loss: 0.0934 - val_tp: 543.0000 - val_fp: 85.0000 - val_tn: 498.0000 - val_fn: 72.0000 - val_accuracy: 0.8689 - val_precision: 0.8646 - val_recall: 0.8829 - val_auc: 0.9457\n",
      "Epoch 15/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0850 - tp: 2117.0000 - fp: 312.0000 - tn: 2100.0000 - fn: 262.0000 - accuracy: 0.8802 - precision: 0.8716 - recall: 0.8899 - auc: 0.9531 - val_loss: 0.0941 - val_tp: 523.0000 - val_fp: 67.0000 - val_tn: 516.0000 - val_fn: 92.0000 - val_accuracy: 0.8673 - val_precision: 0.8864 - val_recall: 0.8504 - val_auc: 0.9475\n",
      "Epoch 16/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0838 - tp: 2119.0000 - fp: 295.0000 - tn: 2117.0000 - fn: 260.0000 - accuracy: 0.8842 - precision: 0.8778 - recall: 0.8907 - auc: 0.9540 - val_loss: 0.0936 - val_tp: 548.0000 - val_fp: 95.0000 - val_tn: 488.0000 - val_fn: 67.0000 - val_accuracy: 0.8648 - val_precision: 0.8523 - val_recall: 0.8911 - val_auc: 0.9447\n",
      "Epoch 17/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0826 - tp: 2132.0000 - fp: 301.0000 - tn: 2111.0000 - fn: 247.0000 - accuracy: 0.8856 - precision: 0.8763 - recall: 0.8962 - auc: 0.9541 - val_loss: 0.1011 - val_tp: 577.0000 - val_fp: 137.0000 - val_tn: 446.0000 - val_fn: 38.0000 - val_accuracy: 0.8539 - val_precision: 0.8081 - val_recall: 0.9382 - val_auc: 0.9429\n",
      "Epoch 18/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0835 - tp: 2135.0000 - fp: 301.0000 - tn: 2111.0000 - fn: 244.0000 - accuracy: 0.8862 - precision: 0.8764 - recall: 0.8974 - auc: 0.9537 - val_loss: 0.0925 - val_tp: 553.0000 - val_fp: 86.0000 - val_tn: 497.0000 - val_fn: 62.0000 - val_accuracy: 0.8765 - val_precision: 0.8654 - val_recall: 0.8992 - val_auc: 0.9457\n",
      "Epoch 19/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0813 - tp: 2137.0000 - fp: 285.0000 - tn: 2127.0000 - fn: 242.0000 - accuracy: 0.8900 - precision: 0.8823 - recall: 0.8983 - auc: 0.9565 - val_loss: 0.0925 - val_tp: 523.0000 - val_fp: 69.0000 - val_tn: 514.0000 - val_fn: 92.0000 - val_accuracy: 0.8656 - val_precision: 0.8834 - val_recall: 0.8504 - val_auc: 0.9469\n",
      "Epoch 20/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0812 - tp: 2128.0000 - fp: 286.0000 - tn: 2126.0000 - fn: 251.0000 - accuracy: 0.8879 - precision: 0.8815 - recall: 0.8945 - auc: 0.9568 - val_loss: 0.0943 - val_tp: 549.0000 - val_fp: 97.0000 - val_tn: 486.0000 - val_fn: 66.0000 - val_accuracy: 0.8639 - val_precision: 0.8498 - val_recall: 0.8927 - val_auc: 0.9446\n",
      "train_auc:  0.9653615591650825\n",
      "test_auc:  0.9449106806676986\n",
      "\n",
      "\n",
      "i:  1\n",
      "model\n",
      "compile\n",
      "Epoch 1/20\n",
      "150/150 [==============================] - 2s 4ms/step - loss: 0.1812 - tp: 2539.0000 - fp: 674.0000 - tn: 2318.0000 - fn: 458.0000 - accuracy: 0.8110 - precision: 0.7902 - recall: 0.8472 - auc: 0.8845 - val_loss: 0.1682 - val_tp: 492.0000 - val_fp: 70.0000 - val_tn: 516.0000 - val_fn: 120.0000 - val_accuracy: 0.8414 - val_precision: 0.8754 - val_recall: 0.8039 - val_auc: 0.8937\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1564 - tp: 1950.0000 - fp: 337.0000 - tn: 2072.0000 - fn: 432.0000 - accuracy: 0.8395 - precision: 0.8526 - recall: 0.8186 - auc: 0.8817 - val_loss: 0.1019 - val_tp: 517.0000 - val_fp: 70.0000 - val_tn: 516.0000 - val_fn: 95.0000 - val_accuracy: 0.8623 - val_precision: 0.8807 - val_recall: 0.8448 - val_auc: 0.9388\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1052 - tp: 1992.0000 - fp: 312.0000 - tn: 2097.0000 - fn: 390.0000 - accuracy: 0.8535 - precision: 0.8646 - recall: 0.8363 - auc: 0.9310 - val_loss: 0.0947 - val_tp: 536.0000 - val_fp: 77.0000 - val_tn: 509.0000 - val_fn: 76.0000 - val_accuracy: 0.8723 - val_precision: 0.8744 - val_recall: 0.8758 - val_auc: 0.9437\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1026 - tp: 2026.0000 - fp: 322.0000 - tn: 2087.0000 - fn: 356.0000 - accuracy: 0.8585 - precision: 0.8629 - recall: 0.8505 - auc: 0.9335 - val_loss: 0.1003 - val_tp: 469.0000 - val_fp: 39.0000 - val_tn: 547.0000 - val_fn: 143.0000 - val_accuracy: 0.8481 - val_precision: 0.9232 - val_recall: 0.7663 - val_auc: 0.9474\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0975 - tp: 2044.0000 - fp: 313.0000 - tn: 2096.0000 - fn: 338.0000 - accuracy: 0.8641 - precision: 0.8672 - recall: 0.8581 - auc: 0.9400 - val_loss: 0.0963 - val_tp: 483.0000 - val_fp: 48.0000 - val_tn: 538.0000 - val_fn: 129.0000 - val_accuracy: 0.8523 - val_precision: 0.9096 - val_recall: 0.7892 - val_auc: 0.9481\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0945 - tp: 2054.0000 - fp: 299.0000 - tn: 2110.0000 - fn: 328.0000 - accuracy: 0.8691 - precision: 0.8729 - recall: 0.8623 - auc: 0.9432 - val_loss: 0.0942 - val_tp: 568.0000 - val_fp: 104.0000 - val_tn: 482.0000 - val_fn: 44.0000 - val_accuracy: 0.8765 - val_precision: 0.8452 - val_recall: 0.9281 - val_auc: 0.9476\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0946 - tp: 2070.0000 - fp: 320.0000 - tn: 2089.0000 - fn: 312.0000 - accuracy: 0.8681 - precision: 0.8661 - recall: 0.8690 - auc: 0.9433 - val_loss: 0.0992 - val_tp: 485.0000 - val_fp: 46.0000 - val_tn: 540.0000 - val_fn: 127.0000 - val_accuracy: 0.8556 - val_precision: 0.9134 - val_recall: 0.7925 - val_auc: 0.9474\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0941 - tp: 2057.0000 - fp: 321.0000 - tn: 2088.0000 - fn: 325.0000 - accuracy: 0.8652 - precision: 0.8650 - recall: 0.8636 - auc: 0.9441 - val_loss: 0.0892 - val_tp: 556.0000 - val_fp: 89.0000 - val_tn: 497.0000 - val_fn: 56.0000 - val_accuracy: 0.8790 - val_precision: 0.8620 - val_recall: 0.9085 - val_auc: 0.9490\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0909 - tp: 2100.0000 - fp: 317.0000 - tn: 2092.0000 - fn: 282.0000 - accuracy: 0.8750 - precision: 0.8688 - recall: 0.8816 - auc: 0.9471 - val_loss: 0.0895 - val_tp: 534.0000 - val_fp: 71.0000 - val_tn: 515.0000 - val_fn: 78.0000 - val_accuracy: 0.8756 - val_precision: 0.8826 - val_recall: 0.8725 - val_auc: 0.9480\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0885 - tp: 2114.0000 - fp: 307.0000 - tn: 2102.0000 - fn: 268.0000 - accuracy: 0.8800 - precision: 0.8732 - recall: 0.8875 - auc: 0.9499 - val_loss: 0.0993 - val_tp: 491.0000 - val_fp: 45.0000 - val_tn: 541.0000 - val_fn: 121.0000 - val_accuracy: 0.8614 - val_precision: 0.9160 - val_recall: 0.8023 - val_auc: 0.9473\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0911 - tp: 2093.0000 - fp: 315.0000 - tn: 2094.0000 - fn: 289.0000 - accuracy: 0.8739 - precision: 0.8692 - recall: 0.8787 - auc: 0.9467 - val_loss: 0.0902 - val_tp: 524.0000 - val_fp: 61.0000 - val_tn: 525.0000 - val_fn: 88.0000 - val_accuracy: 0.8756 - val_precision: 0.8957 - val_recall: 0.8562 - val_auc: 0.9486\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0884 - tp: 2123.0000 - fp: 306.0000 - tn: 2103.0000 - fn: 259.0000 - accuracy: 0.8821 - precision: 0.8740 - recall: 0.8913 - auc: 0.9494 - val_loss: 0.0896 - val_tp: 527.0000 - val_fp: 60.0000 - val_tn: 526.0000 - val_fn: 85.0000 - val_accuracy: 0.8790 - val_precision: 0.8978 - val_recall: 0.8611 - val_auc: 0.9489\n",
      "Epoch 13/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0876 - tp: 2092.0000 - fp: 302.0000 - tn: 2107.0000 - fn: 290.0000 - accuracy: 0.8764 - precision: 0.8739 - recall: 0.8783 - auc: 0.9516 - val_loss: 0.0991 - val_tp: 484.0000 - val_fp: 46.0000 - val_tn: 540.0000 - val_fn: 128.0000 - val_accuracy: 0.8548 - val_precision: 0.9132 - val_recall: 0.7908 - val_auc: 0.9469\n",
      "Epoch 14/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0870 - tp: 2110.0000 - fp: 299.0000 - tn: 2110.0000 - fn: 272.0000 - accuracy: 0.8808 - precision: 0.8759 - recall: 0.8858 - auc: 0.9512 - val_loss: 0.0911 - val_tp: 513.0000 - val_fp: 49.0000 - val_tn: 537.0000 - val_fn: 99.0000 - val_accuracy: 0.8765 - val_precision: 0.9128 - val_recall: 0.8382 - val_auc: 0.9494\n",
      "Epoch 15/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0851 - tp: 2119.0000 - fp: 309.0000 - tn: 2100.0000 - fn: 263.0000 - accuracy: 0.8806 - precision: 0.8727 - recall: 0.8896 - auc: 0.9534 - val_loss: 0.0871 - val_tp: 554.0000 - val_fp: 80.0000 - val_tn: 506.0000 - val_fn: 58.0000 - val_accuracy: 0.8848 - val_precision: 0.8738 - val_recall: 0.9052 - val_auc: 0.9500\n",
      "Epoch 16/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0830 - tp: 2127.0000 - fp: 291.0000 - tn: 2118.0000 - fn: 255.0000 - accuracy: 0.8860 - precision: 0.8797 - recall: 0.8929 - auc: 0.9551 - val_loss: 0.0925 - val_tp: 507.0000 - val_fp: 53.0000 - val_tn: 533.0000 - val_fn: 105.0000 - val_accuracy: 0.8681 - val_precision: 0.9054 - val_recall: 0.8284 - val_auc: 0.9480\n",
      "Epoch 17/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0828 - tp: 2129.0000 - fp: 293.0000 - tn: 2116.0000 - fn: 253.0000 - accuracy: 0.8860 - precision: 0.8790 - recall: 0.8938 - auc: 0.9552 - val_loss: 0.0965 - val_tp: 509.0000 - val_fp: 52.0000 - val_tn: 534.0000 - val_fn: 103.0000 - val_accuracy: 0.8706 - val_precision: 0.9073 - val_recall: 0.8317 - val_auc: 0.9471\n",
      "Epoch 18/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0825 - tp: 2132.0000 - fp: 285.0000 - tn: 2124.0000 - fn: 250.0000 - accuracy: 0.8883 - precision: 0.8821 - recall: 0.8950 - auc: 0.9547 - val_loss: 0.0918 - val_tp: 516.0000 - val_fp: 60.0000 - val_tn: 526.0000 - val_fn: 96.0000 - val_accuracy: 0.8698 - val_precision: 0.8958 - val_recall: 0.8431 - val_auc: 0.9480\n",
      "Epoch 19/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0823 - tp: 2135.0000 - fp: 298.0000 - tn: 2111.0000 - fn: 247.0000 - accuracy: 0.8862 - precision: 0.8775 - recall: 0.8963 - auc: 0.9560 - val_loss: 0.0956 - val_tp: 506.0000 - val_fp: 54.0000 - val_tn: 532.0000 - val_fn: 106.0000 - val_accuracy: 0.8664 - val_precision: 0.9036 - val_recall: 0.8268 - val_auc: 0.9469\n",
      "Epoch 20/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0800 - tp: 2153.0000 - fp: 288.0000 - tn: 2121.0000 - fn: 229.0000 - accuracy: 0.8921 - precision: 0.8820 - recall: 0.9039 - auc: 0.9583 - val_loss: 0.0886 - val_tp: 549.0000 - val_fp: 82.0000 - val_tn: 504.0000 - val_fn: 63.0000 - val_accuracy: 0.8790 - val_precision: 0.8700 - val_recall: 0.8971 - val_auc: 0.9484\n",
      "train_auc:  0.9653003238973358\n",
      "test_auc:  0.9486967141805528\n",
      "\n",
      "\n",
      "i:  2\n",
      "model\n",
      "compile\n",
      "Epoch 1/20\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.1253 - tp: 2369.0000 - fp: 356.0000 - tn: 2627.0000 - fn: 637.0000 - accuracy: 0.8342 - precision: 0.8694 - recall: 0.7881 - auc: 0.9148 - val_loss: 0.1012 - val_tp: 492.0000 - val_fp: 63.0000 - val_tn: 535.0000 - val_fn: 108.0000 - val_accuracy: 0.8573 - val_precision: 0.8865 - val_recall: 0.8200 - val_auc: 0.9357\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1080 - tp: 1944.0000 - fp: 301.0000 - tn: 2096.0000 - fn: 450.0000 - accuracy: 0.8432 - precision: 0.8659 - recall: 0.8120 - auc: 0.9285 - val_loss: 0.0981 - val_tp: 517.0000 - val_fp: 79.0000 - val_tn: 519.0000 - val_fn: 83.0000 - val_accuracy: 0.8648 - val_precision: 0.8674 - val_recall: 0.8617 - val_auc: 0.9392\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1043 - tp: 1980.0000 - fp: 307.0000 - tn: 2090.0000 - fn: 414.0000 - accuracy: 0.8495 - precision: 0.8658 - recall: 0.8271 - auc: 0.9321 - val_loss: 0.0940 - val_tp: 510.0000 - val_fp: 68.0000 - val_tn: 530.0000 - val_fn: 90.0000 - val_accuracy: 0.8681 - val_precision: 0.8824 - val_recall: 0.8500 - val_auc: 0.9444\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0983 - tp: 2023.0000 - fp: 302.0000 - tn: 2095.0000 - fn: 371.0000 - accuracy: 0.8595 - precision: 0.8701 - recall: 0.8450 - auc: 0.9400 - val_loss: 0.0914 - val_tp: 528.0000 - val_fp: 80.0000 - val_tn: 518.0000 - val_fn: 72.0000 - val_accuracy: 0.8731 - val_precision: 0.8684 - val_recall: 0.8800 - val_auc: 0.9477\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0950 - tp: 2088.0000 - fp: 330.0000 - tn: 2067.0000 - fn: 306.0000 - accuracy: 0.8673 - precision: 0.8635 - recall: 0.8722 - auc: 0.9425 - val_loss: 0.0920 - val_tp: 508.0000 - val_fp: 62.0000 - val_tn: 536.0000 - val_fn: 92.0000 - val_accuracy: 0.8715 - val_precision: 0.8912 - val_recall: 0.8467 - val_auc: 0.9470\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0948 - tp: 2087.0000 - fp: 325.0000 - tn: 2072.0000 - fn: 307.0000 - accuracy: 0.8681 - precision: 0.8653 - recall: 0.8718 - auc: 0.9426 - val_loss: 0.0903 - val_tp: 529.0000 - val_fp: 78.0000 - val_tn: 520.0000 - val_fn: 71.0000 - val_accuracy: 0.8756 - val_precision: 0.8715 - val_recall: 0.8817 - val_auc: 0.9482\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0936 - tp: 2078.0000 - fp: 317.0000 - tn: 2080.0000 - fn: 316.0000 - accuracy: 0.8679 - precision: 0.8676 - recall: 0.8680 - auc: 0.9449 - val_loss: 0.0897 - val_tp: 531.0000 - val_fp: 82.0000 - val_tn: 516.0000 - val_fn: 69.0000 - val_accuracy: 0.8740 - val_precision: 0.8662 - val_recall: 0.8850 - val_auc: 0.9492\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0924 - tp: 2109.0000 - fp: 327.0000 - tn: 2070.0000 - fn: 285.0000 - accuracy: 0.8723 - precision: 0.8658 - recall: 0.8810 - auc: 0.9450 - val_loss: 0.0890 - val_tp: 536.0000 - val_fp: 83.0000 - val_tn: 515.0000 - val_fn: 64.0000 - val_accuracy: 0.8773 - val_precision: 0.8659 - val_recall: 0.8933 - val_auc: 0.9496\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0901 - tp: 2110.0000 - fp: 328.0000 - tn: 2069.0000 - fn: 284.0000 - accuracy: 0.8723 - precision: 0.8655 - recall: 0.8814 - auc: 0.9484 - val_loss: 0.0893 - val_tp: 542.0000 - val_fp: 87.0000 - val_tn: 511.0000 - val_fn: 58.0000 - val_accuracy: 0.8790 - val_precision: 0.8617 - val_recall: 0.9033 - val_auc: 0.9505\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0899 - tp: 2117.0000 - fp: 310.0000 - tn: 2087.0000 - fn: 277.0000 - accuracy: 0.8775 - precision: 0.8723 - recall: 0.8843 - auc: 0.9483 - val_loss: 0.0879 - val_tp: 528.0000 - val_fp: 74.0000 - val_tn: 524.0000 - val_fn: 72.0000 - val_accuracy: 0.8781 - val_precision: 0.8771 - val_recall: 0.8800 - val_auc: 0.9513\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0884 - tp: 2111.0000 - fp: 301.0000 - tn: 2096.0000 - fn: 283.0000 - accuracy: 0.8781 - precision: 0.8752 - recall: 0.8818 - auc: 0.9500 - val_loss: 0.1015 - val_tp: 565.0000 - val_fp: 127.0000 - val_tn: 471.0000 - val_fn: 35.0000 - val_accuracy: 0.8648 - val_precision: 0.8165 - val_recall: 0.9417 - val_auc: 0.9487\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0876 - tp: 2138.0000 - fp: 320.0000 - tn: 2077.0000 - fn: 256.0000 - accuracy: 0.8798 - precision: 0.8698 - recall: 0.8931 - auc: 0.9502 - val_loss: 0.1056 - val_tp: 574.0000 - val_fp: 160.0000 - val_tn: 438.0000 - val_fn: 26.0000 - val_accuracy: 0.8447 - val_precision: 0.7820 - val_recall: 0.9567 - val_auc: 0.9490\n",
      "Epoch 13/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0870 - tp: 2146.0000 - fp: 327.0000 - tn: 2070.0000 - fn: 248.0000 - accuracy: 0.8800 - precision: 0.8678 - recall: 0.8964 - auc: 0.9507 - val_loss: 0.0879 - val_tp: 539.0000 - val_fp: 87.0000 - val_tn: 511.0000 - val_fn: 61.0000 - val_accuracy: 0.8765 - val_precision: 0.8610 - val_recall: 0.8983 - val_auc: 0.9518\n",
      "Epoch 14/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0857 - tp: 2130.0000 - fp: 305.0000 - tn: 2092.0000 - fn: 264.0000 - accuracy: 0.8812 - precision: 0.8747 - recall: 0.8897 - auc: 0.9517 - val_loss: 0.0903 - val_tp: 510.0000 - val_fp: 63.0000 - val_tn: 535.0000 - val_fn: 90.0000 - val_accuracy: 0.8723 - val_precision: 0.8901 - val_recall: 0.8500 - val_auc: 0.9504\n",
      "Epoch 15/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0857 - tp: 2127.0000 - fp: 297.0000 - tn: 2100.0000 - fn: 267.0000 - accuracy: 0.8823 - precision: 0.8775 - recall: 0.8885 - auc: 0.9518 - val_loss: 0.0867 - val_tp: 534.0000 - val_fp: 82.0000 - val_tn: 516.0000 - val_fn: 66.0000 - val_accuracy: 0.8765 - val_precision: 0.8669 - val_recall: 0.8900 - val_auc: 0.9518\n",
      "Epoch 16/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0835 - tp: 2140.0000 - fp: 286.0000 - tn: 2111.0000 - fn: 254.0000 - accuracy: 0.8873 - precision: 0.8821 - recall: 0.8939 - auc: 0.9542 - val_loss: 0.0907 - val_tp: 548.0000 - val_fp: 101.0000 - val_tn: 497.0000 - val_fn: 52.0000 - val_accuracy: 0.8723 - val_precision: 0.8444 - val_recall: 0.9133 - val_auc: 0.9516\n",
      "Epoch 17/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0835 - tp: 2143.0000 - fp: 298.0000 - tn: 2099.0000 - fn: 251.0000 - accuracy: 0.8854 - precision: 0.8779 - recall: 0.8952 - auc: 0.9543 - val_loss: 0.0892 - val_tp: 522.0000 - val_fp: 69.0000 - val_tn: 529.0000 - val_fn: 78.0000 - val_accuracy: 0.8773 - val_precision: 0.8832 - val_recall: 0.8700 - val_auc: 0.9515\n",
      "Epoch 18/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0824 - tp: 2144.0000 - fp: 292.0000 - tn: 2105.0000 - fn: 250.0000 - accuracy: 0.8869 - precision: 0.8801 - recall: 0.8956 - auc: 0.9555 - val_loss: 0.0988 - val_tp: 559.0000 - val_fp: 137.0000 - val_tn: 461.0000 - val_fn: 41.0000 - val_accuracy: 0.8514 - val_precision: 0.8032 - val_recall: 0.9317 - val_auc: 0.9486\n",
      "Epoch 19/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0817 - tp: 2155.0000 - fp: 284.0000 - tn: 2113.0000 - fn: 239.0000 - accuracy: 0.8908 - precision: 0.8836 - recall: 0.9002 - auc: 0.9559 - val_loss: 0.0880 - val_tp: 524.0000 - val_fp: 72.0000 - val_tn: 526.0000 - val_fn: 76.0000 - val_accuracy: 0.8765 - val_precision: 0.8792 - val_recall: 0.8733 - val_auc: 0.9517\n",
      "Epoch 20/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0796 - tp: 2157.0000 - fp: 263.0000 - tn: 2134.0000 - fn: 237.0000 - accuracy: 0.8956 - precision: 0.8913 - recall: 0.9010 - auc: 0.9570 - val_loss: 0.0882 - val_tp: 536.0000 - val_fp: 87.0000 - val_tn: 511.0000 - val_fn: 64.0000 - val_accuracy: 0.8740 - val_precision: 0.8604 - val_recall: 0.8933 - val_auc: 0.9522\n",
      "train_auc:  0.9640665772343527\n",
      "test_auc:  0.9525641025641026\n",
      "\n",
      "\n",
      "i:  3\n",
      "model\n",
      "compile\n",
      "Epoch 1/20\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.1160 - tp: 2496.0000 - fp: 421.0000 - tn: 2564.0000 - fn: 508.0000 - accuracy: 0.8449 - precision: 0.8557 - recall: 0.8309 - auc: 0.9244 - val_loss: 0.1298 - val_tp: 393.0000 - val_fp: 41.0000 - val_tn: 567.0000 - val_fn: 197.0000 - val_accuracy: 0.8013 - val_precision: 0.9055 - val_recall: 0.6661 - val_auc: 0.9255\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1033 - tp: 2024.0000 - fp: 323.0000 - tn: 2064.0000 - fn: 380.0000 - accuracy: 0.8533 - precision: 0.8624 - recall: 0.8419 - auc: 0.9339 - val_loss: 0.1082 - val_tp: 524.0000 - val_fp: 120.0000 - val_tn: 488.0000 - val_fn: 66.0000 - val_accuracy: 0.8447 - val_precision: 0.8137 - val_recall: 0.8881 - val_auc: 0.9303\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0996 - tp: 2078.0000 - fp: 337.0000 - tn: 2050.0000 - fn: 326.0000 - accuracy: 0.8616 - precision: 0.8605 - recall: 0.8644 - auc: 0.9377 - val_loss: 0.1055 - val_tp: 500.0000 - val_fp: 92.0000 - val_tn: 516.0000 - val_fn: 90.0000 - val_accuracy: 0.8481 - val_precision: 0.8446 - val_recall: 0.8475 - val_auc: 0.9329\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0949 - tp: 2076.0000 - fp: 313.0000 - tn: 2074.0000 - fn: 328.0000 - accuracy: 0.8662 - precision: 0.8690 - recall: 0.8636 - auc: 0.9431 - val_loss: 0.1014 - val_tp: 508.0000 - val_fp: 98.0000 - val_tn: 510.0000 - val_fn: 82.0000 - val_accuracy: 0.8497 - val_precision: 0.8383 - val_recall: 0.8610 - val_auc: 0.9375\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0925 - tp: 2106.0000 - fp: 330.0000 - tn: 2057.0000 - fn: 298.0000 - accuracy: 0.8689 - precision: 0.8645 - recall: 0.8760 - auc: 0.9462 - val_loss: 0.1023 - val_tp: 491.0000 - val_fp: 76.0000 - val_tn: 532.0000 - val_fn: 99.0000 - val_accuracy: 0.8539 - val_precision: 0.8660 - val_recall: 0.8322 - val_auc: 0.9398\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0936 - tp: 2101.0000 - fp: 334.0000 - tn: 2053.0000 - fn: 303.0000 - accuracy: 0.8670 - precision: 0.8628 - recall: 0.8740 - auc: 0.9441 - val_loss: 0.1021 - val_tp: 498.0000 - val_fp: 84.0000 - val_tn: 524.0000 - val_fn: 92.0000 - val_accuracy: 0.8531 - val_precision: 0.8557 - val_recall: 0.8441 - val_auc: 0.9382\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0910 - tp: 2129.0000 - fp: 322.0000 - tn: 2065.0000 - fn: 275.0000 - accuracy: 0.8754 - precision: 0.8686 - recall: 0.8856 - auc: 0.9470 - val_loss: 0.1000 - val_tp: 524.0000 - val_fp: 95.0000 - val_tn: 513.0000 - val_fn: 66.0000 - val_accuracy: 0.8656 - val_precision: 0.8465 - val_recall: 0.8881 - val_auc: 0.9389\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0897 - tp: 2123.0000 - fp: 322.0000 - tn: 2065.0000 - fn: 281.0000 - accuracy: 0.8741 - precision: 0.8683 - recall: 0.8831 - auc: 0.9478 - val_loss: 0.1107 - val_tp: 556.0000 - val_fp: 155.0000 - val_tn: 453.0000 - val_fn: 34.0000 - val_accuracy: 0.8422 - val_precision: 0.7820 - val_recall: 0.9424 - val_auc: 0.9383\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0896 - tp: 2139.0000 - fp: 322.0000 - tn: 2065.0000 - fn: 265.0000 - accuracy: 0.8775 - precision: 0.8692 - recall: 0.8898 - auc: 0.9486 - val_loss: 0.0982 - val_tp: 529.0000 - val_fp: 99.0000 - val_tn: 509.0000 - val_fn: 61.0000 - val_accuracy: 0.8664 - val_precision: 0.8424 - val_recall: 0.8966 - val_auc: 0.9407\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0878 - tp: 2142.0000 - fp: 322.0000 - tn: 2065.0000 - fn: 262.0000 - accuracy: 0.8781 - precision: 0.8693 - recall: 0.8910 - auc: 0.9501 - val_loss: 0.1003 - val_tp: 507.0000 - val_fp: 86.0000 - val_tn: 522.0000 - val_fn: 83.0000 - val_accuracy: 0.8589 - val_precision: 0.8550 - val_recall: 0.8593 - val_auc: 0.9402\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0855 - tp: 2148.0000 - fp: 301.0000 - tn: 2086.0000 - fn: 256.0000 - accuracy: 0.8837 - precision: 0.8771 - recall: 0.8935 - auc: 0.9524 - val_loss: 0.1010 - val_tp: 496.0000 - val_fp: 78.0000 - val_tn: 530.0000 - val_fn: 94.0000 - val_accuracy: 0.8564 - val_precision: 0.8641 - val_recall: 0.8407 - val_auc: 0.9413\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0857 - tp: 2151.0000 - fp: 299.0000 - tn: 2088.0000 - fn: 253.0000 - accuracy: 0.8848 - precision: 0.8780 - recall: 0.8948 - auc: 0.9514 - val_loss: 0.1002 - val_tp: 513.0000 - val_fp: 90.0000 - val_tn: 518.0000 - val_fn: 77.0000 - val_accuracy: 0.8606 - val_precision: 0.8507 - val_recall: 0.8695 - val_auc: 0.9399\n",
      "Epoch 13/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0854 - tp: 2134.0000 - fp: 302.0000 - tn: 2085.0000 - fn: 270.0000 - accuracy: 0.8806 - precision: 0.8760 - recall: 0.8877 - auc: 0.9522 - val_loss: 0.0997 - val_tp: 498.0000 - val_fp: 77.0000 - val_tn: 531.0000 - val_fn: 92.0000 - val_accuracy: 0.8589 - val_precision: 0.8661 - val_recall: 0.8441 - val_auc: 0.9411\n",
      "Epoch 14/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0836 - tp: 2153.0000 - fp: 294.0000 - tn: 2093.0000 - fn: 251.0000 - accuracy: 0.8862 - precision: 0.8799 - recall: 0.8956 - auc: 0.9540 - val_loss: 0.0997 - val_tp: 504.0000 - val_fp: 79.0000 - val_tn: 529.0000 - val_fn: 86.0000 - val_accuracy: 0.8623 - val_precision: 0.8645 - val_recall: 0.8542 - val_auc: 0.9400\n",
      "Epoch 15/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0841 - tp: 2155.0000 - fp: 317.0000 - tn: 2070.0000 - fn: 249.0000 - accuracy: 0.8819 - precision: 0.8718 - recall: 0.8964 - auc: 0.9541 - val_loss: 0.1015 - val_tp: 541.0000 - val_fp: 112.0000 - val_tn: 496.0000 - val_fn: 49.0000 - val_accuracy: 0.8656 - val_precision: 0.8285 - val_recall: 0.9169 - val_auc: 0.9400\n",
      "Epoch 16/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0819 - tp: 2149.0000 - fp: 291.0000 - tn: 2096.0000 - fn: 255.0000 - accuracy: 0.8860 - precision: 0.8807 - recall: 0.8939 - auc: 0.9563 - val_loss: 0.1021 - val_tp: 544.0000 - val_fp: 121.0000 - val_tn: 487.0000 - val_fn: 46.0000 - val_accuracy: 0.8606 - val_precision: 0.8180 - val_recall: 0.9220 - val_auc: 0.9396\n",
      "Epoch 17/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0819 - tp: 2155.0000 - fp: 288.0000 - tn: 2099.0000 - fn: 249.0000 - accuracy: 0.8879 - precision: 0.8821 - recall: 0.8964 - auc: 0.9554 - val_loss: 0.0994 - val_tp: 524.0000 - val_fp: 102.0000 - val_tn: 506.0000 - val_fn: 66.0000 - val_accuracy: 0.8598 - val_precision: 0.8371 - val_recall: 0.8881 - val_auc: 0.9399\n",
      "Epoch 18/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0804 - tp: 2159.0000 - fp: 279.0000 - tn: 2108.0000 - fn: 245.0000 - accuracy: 0.8906 - precision: 0.8856 - recall: 0.8981 - auc: 0.9573 - val_loss: 0.1015 - val_tp: 536.0000 - val_fp: 109.0000 - val_tn: 499.0000 - val_fn: 54.0000 - val_accuracy: 0.8639 - val_precision: 0.8310 - val_recall: 0.9085 - val_auc: 0.9404\n",
      "Epoch 19/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0793 - tp: 2167.0000 - fp: 284.0000 - tn: 2103.0000 - fn: 237.0000 - accuracy: 0.8913 - precision: 0.8841 - recall: 0.9014 - auc: 0.9576 - val_loss: 0.0994 - val_tp: 528.0000 - val_fp: 102.0000 - val_tn: 506.0000 - val_fn: 62.0000 - val_accuracy: 0.8631 - val_precision: 0.8381 - val_recall: 0.8949 - val_auc: 0.9405\n",
      "Epoch 20/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0789 - tp: 2166.0000 - fp: 271.0000 - tn: 2116.0000 - fn: 238.0000 - accuracy: 0.8938 - precision: 0.8888 - recall: 0.9010 - auc: 0.9584 - val_loss: 0.1017 - val_tp: 535.0000 - val_fp: 113.0000 - val_tn: 495.0000 - val_fn: 55.0000 - val_accuracy: 0.8598 - val_precision: 0.8256 - val_recall: 0.9068 - val_auc: 0.9395\n",
      "train_auc:  0.9647043887892474\n",
      "test_auc:  0.9396562778768957\n",
      "\n",
      "\n",
      "i:  4\n",
      "model\n",
      "compile\n",
      "Epoch 1/20\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.1183 - tp: 2490.0000 - fp: 446.0000 - tn: 2537.0000 - fn: 517.0000 - accuracy: 0.8392 - precision: 0.8481 - recall: 0.8281 - auc: 0.9184 - val_loss: 0.1122 - val_tp: 441.0000 - val_fp: 53.0000 - val_tn: 567.0000 - val_fn: 136.0000 - val_accuracy: 0.8421 - val_precision: 0.8927 - val_recall: 0.7643 - val_auc: 0.9340\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1057 - tp: 2043.0000 - fp: 323.0000 - tn: 2052.0000 - fn: 374.0000 - accuracy: 0.8545 - precision: 0.8635 - recall: 0.8453 - auc: 0.9302 - val_loss: 0.1073 - val_tp: 416.0000 - val_fp: 37.0000 - val_tn: 583.0000 - val_fn: 161.0000 - val_accuracy: 0.8346 - val_precision: 0.9183 - val_recall: 0.7210 - val_auc: 0.9465\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0997 - tp: 2075.0000 - fp: 332.0000 - tn: 2043.0000 - fn: 342.0000 - accuracy: 0.8593 - precision: 0.8621 - recall: 0.8585 - auc: 0.9375 - val_loss: 0.0957 - val_tp: 482.0000 - val_fp: 73.0000 - val_tn: 547.0000 - val_fn: 95.0000 - val_accuracy: 0.8596 - val_precision: 0.8685 - val_recall: 0.8354 - val_auc: 0.9442\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0968 - tp: 2091.0000 - fp: 330.0000 - tn: 2045.0000 - fn: 326.0000 - accuracy: 0.8631 - precision: 0.8637 - recall: 0.8651 - auc: 0.9408 - val_loss: 0.0967 - val_tp: 543.0000 - val_fp: 122.0000 - val_tn: 498.0000 - val_fn: 34.0000 - val_accuracy: 0.8697 - val_precision: 0.8165 - val_recall: 0.9411 - val_auc: 0.9483\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0956 - tp: 2101.0000 - fp: 335.0000 - tn: 2040.0000 - fn: 316.0000 - accuracy: 0.8641 - precision: 0.8625 - recall: 0.8693 - auc: 0.9425 - val_loss: 0.0993 - val_tp: 463.0000 - val_fp: 53.0000 - val_tn: 567.0000 - val_fn: 114.0000 - val_accuracy: 0.8605 - val_precision: 0.8973 - val_recall: 0.8024 - val_auc: 0.9472\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0928 - tp: 2104.0000 - fp: 310.0000 - tn: 2065.0000 - fn: 313.0000 - accuracy: 0.8700 - precision: 0.8716 - recall: 0.8705 - auc: 0.9446 - val_loss: 0.0951 - val_tp: 535.0000 - val_fp: 110.0000 - val_tn: 510.0000 - val_fn: 42.0000 - val_accuracy: 0.8730 - val_precision: 0.8295 - val_recall: 0.9272 - val_auc: 0.9469\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0935 - tp: 2116.0000 - fp: 329.0000 - tn: 2046.0000 - fn: 301.0000 - accuracy: 0.8685 - precision: 0.8654 - recall: 0.8755 - auc: 0.9446 - val_loss: 0.0915 - val_tp: 511.0000 - val_fp: 85.0000 - val_tn: 535.0000 - val_fn: 66.0000 - val_accuracy: 0.8739 - val_precision: 0.8574 - val_recall: 0.8856 - val_auc: 0.9460\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0905 - tp: 2125.0000 - fp: 320.0000 - tn: 2055.0000 - fn: 292.0000 - accuracy: 0.8723 - precision: 0.8691 - recall: 0.8792 - auc: 0.9480 - val_loss: 0.0905 - val_tp: 503.0000 - val_fp: 74.0000 - val_tn: 546.0000 - val_fn: 74.0000 - val_accuracy: 0.8764 - val_precision: 0.8718 - val_recall: 0.8718 - val_auc: 0.9477\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0887 - tp: 2143.0000 - fp: 318.0000 - tn: 2057.0000 - fn: 274.0000 - accuracy: 0.8765 - precision: 0.8708 - recall: 0.8866 - auc: 0.9493 - val_loss: 0.0865 - val_tp: 526.0000 - val_fp: 86.0000 - val_tn: 534.0000 - val_fn: 51.0000 - val_accuracy: 0.8855 - val_precision: 0.8595 - val_recall: 0.9116 - val_auc: 0.9502\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0884 - tp: 2138.0000 - fp: 310.0000 - tn: 2065.0000 - fn: 279.0000 - accuracy: 0.8771 - precision: 0.8734 - recall: 0.8846 - auc: 0.9497 - val_loss: 0.0906 - val_tp: 510.0000 - val_fp: 79.0000 - val_tn: 541.0000 - val_fn: 67.0000 - val_accuracy: 0.8780 - val_precision: 0.8659 - val_recall: 0.8839 - val_auc: 0.9466\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0859 - tp: 2148.0000 - fp: 310.0000 - tn: 2065.0000 - fn: 269.0000 - accuracy: 0.8792 - precision: 0.8739 - recall: 0.8887 - auc: 0.9527 - val_loss: 0.0966 - val_tp: 459.0000 - val_fp: 59.0000 - val_tn: 561.0000 - val_fn: 118.0000 - val_accuracy: 0.8521 - val_precision: 0.8861 - val_recall: 0.7955 - val_auc: 0.9480\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0858 - tp: 2144.0000 - fp: 286.0000 - tn: 2089.0000 - fn: 273.0000 - accuracy: 0.8833 - precision: 0.8823 - recall: 0.8871 - auc: 0.9523 - val_loss: 0.0907 - val_tp: 508.0000 - val_fp: 79.0000 - val_tn: 541.0000 - val_fn: 69.0000 - val_accuracy: 0.8764 - val_precision: 0.8654 - val_recall: 0.8804 - val_auc: 0.9470\n",
      "Epoch 13/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0856 - tp: 2159.0000 - fp: 319.0000 - tn: 2056.0000 - fn: 258.0000 - accuracy: 0.8796 - precision: 0.8713 - recall: 0.8933 - auc: 0.9527 - val_loss: 0.0933 - val_tp: 537.0000 - val_fp: 112.0000 - val_tn: 508.0000 - val_fn: 40.0000 - val_accuracy: 0.8730 - val_precision: 0.8274 - val_recall: 0.9307 - val_auc: 0.9488\n",
      "Epoch 14/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0843 - tp: 2142.0000 - fp: 293.0000 - tn: 2082.0000 - fn: 275.0000 - accuracy: 0.8815 - precision: 0.8797 - recall: 0.8862 - auc: 0.9539 - val_loss: 0.0895 - val_tp: 526.0000 - val_fp: 98.0000 - val_tn: 522.0000 - val_fn: 51.0000 - val_accuracy: 0.8755 - val_precision: 0.8429 - val_recall: 0.9116 - val_auc: 0.9497\n",
      "Epoch 15/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0830 - tp: 2143.0000 - fp: 276.0000 - tn: 2099.0000 - fn: 274.0000 - accuracy: 0.8852 - precision: 0.8859 - recall: 0.8866 - auc: 0.9547 - val_loss: 0.0917 - val_tp: 519.0000 - val_fp: 88.0000 - val_tn: 532.0000 - val_fn: 58.0000 - val_accuracy: 0.8780 - val_precision: 0.8550 - val_recall: 0.8995 - val_auc: 0.9472\n",
      "Epoch 16/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0825 - tp: 2157.0000 - fp: 285.0000 - tn: 2090.0000 - fn: 260.0000 - accuracy: 0.8863 - precision: 0.8833 - recall: 0.8924 - auc: 0.9554 - val_loss: 0.0899 - val_tp: 514.0000 - val_fp: 76.0000 - val_tn: 544.0000 - val_fn: 63.0000 - val_accuracy: 0.8839 - val_precision: 0.8712 - val_recall: 0.8908 - val_auc: 0.9487\n",
      "Epoch 17/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0797 - tp: 2179.0000 - fp: 282.0000 - tn: 2093.0000 - fn: 238.0000 - accuracy: 0.8915 - precision: 0.8854 - recall: 0.9015 - auc: 0.9577 - val_loss: 0.0941 - val_tp: 489.0000 - val_fp: 66.0000 - val_tn: 554.0000 - val_fn: 88.0000 - val_accuracy: 0.8713 - val_precision: 0.8811 - val_recall: 0.8475 - val_auc: 0.9481\n",
      "Epoch 18/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0817 - tp: 2161.0000 - fp: 297.0000 - tn: 2078.0000 - fn: 256.0000 - accuracy: 0.8846 - precision: 0.8792 - recall: 0.8941 - auc: 0.9562 - val_loss: 0.0896 - val_tp: 491.0000 - val_fp: 69.0000 - val_tn: 551.0000 - val_fn: 86.0000 - val_accuracy: 0.8705 - val_precision: 0.8768 - val_recall: 0.8510 - val_auc: 0.9494\n",
      "Epoch 19/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0800 - tp: 2176.0000 - fp: 291.0000 - tn: 2084.0000 - fn: 241.0000 - accuracy: 0.8890 - precision: 0.8820 - recall: 0.9003 - auc: 0.9578 - val_loss: 0.0905 - val_tp: 507.0000 - val_fp: 76.0000 - val_tn: 544.0000 - val_fn: 70.0000 - val_accuracy: 0.8780 - val_precision: 0.8696 - val_recall: 0.8787 - val_auc: 0.9480\n",
      "Epoch 20/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0794 - tp: 2159.0000 - fp: 266.0000 - tn: 2109.0000 - fn: 258.0000 - accuracy: 0.8907 - precision: 0.8903 - recall: 0.8933 - auc: 0.9582 - val_loss: 0.0897 - val_tp: 498.0000 - val_fp: 71.0000 - val_tn: 549.0000 - val_fn: 79.0000 - val_accuracy: 0.8747 - val_precision: 0.8752 - val_recall: 0.8631 - val_auc: 0.9479\n",
      "train_auc:  0.9668818674738148\n",
      "test_auc:  0.9487546821714095\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = np.array(pd.read_csv(\"6_vecs_train.csv\"))\n",
    "pos_number=2994\n",
    "# NOTE: the number of postive sample in train file\n",
    "#CNN_model = 'CNN_model.h5'\n",
    "\n",
    "X1 = data[0:pos_number, 1:]\n",
    "Y1 = data[0:pos_number, 0]\n",
    "X2 = data[pos_number:, 1:]\n",
    "Y2 = data[pos_number:, 0]\n",
    "X = np.concatenate([X1, X2], 0)\n",
    "Y = np.concatenate([Y1, Y2], 0)\n",
    "#Y = Y.reshape((Y.shape[0], -1))\n",
    "print (X)\n",
    "print (\"X.shape: \", X.shape)\n",
    "print (\"Y.shape: \", Y.shape)\n",
    "\n",
    "lr = 0.4\n",
    "epoch = 20\n",
    "batch_size = 32\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "#kf = KFold(n_splits = 5, shuffle = False)\n",
    "kf = kf.split(X)\n",
    "\n",
    "test_aucs = []\n",
    "for i, (train_fold, validate_fold) in enumerate(kf):\n",
    "    print(\"\\n\\ni: \", i)\n",
    "    test_auc = dnn_model(X[train_fold], Y[train_fold], X[validate_fold], Y[validate_fold], lr, epoch, batch_size)\n",
    "    test_aucs.append(test_auc)\n",
    "w = open(\"train_Result.txt\", \"w\")\n",
    "for j in test_aucs: \n",
    "    w.write(str(j) + ',')\n",
    "w.write('\\n')\n",
    "w.write(str(np.mean(test_aucs)) + '\\n')\n",
    "w.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(899, 200) (898, 200)\n",
      "(899,) (898,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = np.array(pd.read_csv(\"6_vecs_test.csv\"))\n",
    "pos_number = 899 # NOTE: the number of postive sample in test file\n",
    "X1 = data[0:pos_number, 1:]\n",
    "Y1 = data[0:pos_number, 0]\n",
    "X2 = data[pos_number:, 1:]\n",
    "Y2 = data[pos_number:, 0]\n",
    "X_test = np.concatenate([X1, X2], 0)\n",
    "Y_test = np.concatenate([Y1, Y2], 0)\n",
    "\n",
    "print(X1.shape, X2.shape)\n",
    "print(Y1.shape, Y2.shape)\n",
    "\n",
    "lr = 0.4\n",
    "# epoch = 3\n",
    "batch_size = 32\n",
    "data = np.array(pd.read_csv(\"6_vecs_train.csv\"))\n",
    "# pos_number = 3863\n",
    "# pos_number=2097\n",
    "pos_number=2994\n",
    "\n",
    "\n",
    "X1 = data[0:pos_number, 1:]\n",
    "Y1 = data[0:pos_number, 0]\n",
    "X2 = data[pos_number:, 1:]\n",
    "Y2 = data[pos_number:, 0]\n",
    "X = np.concatenate([X1, X2], 0)\n",
    "Y = np.concatenate([Y1, Y2], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4791, 200) (4791,) (1797, 200) (1198,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\n",
      "compile\n",
      "Epoch 1/15\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.1188 - tp: 4447.0000 - fp: 804.0000 - tn: 4575.0000 - fn: 954.0000 - accuracy: 0.8369 - precision: 0.8469 - recall: 0.8234 - auc: 0.9164 - val_loss: 0.1053 - val_tp: 824.0000 - val_fp: 176.0000 - val_tn: 722.0000 - val_fn: 75.0000 - val_accuracy: 0.8603 - val_precision: 0.8240 - val_recall: 0.9166 - val_auc: 0.9345\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1026 - tp: 2050.0000 - fp: 333.0000 - tn: 2051.0000 - fn: 357.0000 - accuracy: 0.8560 - precision: 0.8603 - recall: 0.8517 - auc: 0.9339 - val_loss: 0.0989 - val_tp: 714.0000 - val_fp: 81.0000 - val_tn: 817.0000 - val_fn: 185.0000 - val_accuracy: 0.8520 - val_precision: 0.8981 - val_recall: 0.7942 - val_auc: 0.9441\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0978 - tp: 2088.0000 - fp: 315.0000 - tn: 2069.0000 - fn: 319.0000 - accuracy: 0.8677 - precision: 0.8689 - recall: 0.8675 - auc: 0.9390 - val_loss: 0.0890 - val_tp: 814.0000 - val_fp: 127.0000 - val_tn: 771.0000 - val_fn: 85.0000 - val_accuracy: 0.8820 - val_precision: 0.8650 - val_recall: 0.9055 - val_auc: 0.9474\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0956 - tp: 2107.0000 - fp: 318.0000 - tn: 2066.0000 - fn: 300.0000 - accuracy: 0.8710 - precision: 0.8689 - recall: 0.8754 - auc: 0.9416 - val_loss: 0.0900 - val_tp: 797.0000 - val_fp: 119.0000 - val_tn: 779.0000 - val_fn: 102.0000 - val_accuracy: 0.8770 - val_precision: 0.8701 - val_recall: 0.8865 - val_auc: 0.9466\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0937 - tp: 2081.0000 - fp: 318.0000 - tn: 2066.0000 - fn: 326.0000 - accuracy: 0.8656 - precision: 0.8674 - recall: 0.8646 - auc: 0.9444 - val_loss: 0.0860 - val_tp: 815.0000 - val_fp: 126.0000 - val_tn: 772.0000 - val_fn: 84.0000 - val_accuracy: 0.8831 - val_precision: 0.8661 - val_recall: 0.9066 - val_auc: 0.9515\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0917 - tp: 2096.0000 - fp: 300.0000 - tn: 2084.0000 - fn: 311.0000 - accuracy: 0.8725 - precision: 0.8748 - recall: 0.8708 - auc: 0.9465 - val_loss: 0.0845 - val_tp: 812.0000 - val_fp: 124.0000 - val_tn: 774.0000 - val_fn: 87.0000 - val_accuracy: 0.8826 - val_precision: 0.8675 - val_recall: 0.9032 - val_auc: 0.9518\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0912 - tp: 2112.0000 - fp: 306.0000 - tn: 2078.0000 - fn: 295.0000 - accuracy: 0.8746 - precision: 0.8734 - recall: 0.8774 - auc: 0.9468 - val_loss: 0.0944 - val_tp: 866.0000 - val_fp: 203.0000 - val_tn: 695.0000 - val_fn: 33.0000 - val_accuracy: 0.8687 - val_precision: 0.8101 - val_recall: 0.9633 - val_auc: 0.9531\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0889 - tp: 2136.0000 - fp: 317.0000 - tn: 2067.0000 - fn: 271.0000 - accuracy: 0.8773 - precision: 0.8708 - recall: 0.8874 - auc: 0.9494 - val_loss: 0.1016 - val_tp: 680.0000 - val_fp: 51.0000 - val_tn: 847.0000 - val_fn: 219.0000 - val_accuracy: 0.8497 - val_precision: 0.9302 - val_recall: 0.7564 - val_auc: 0.9522\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0896 - tp: 2120.0000 - fp: 306.0000 - tn: 2078.0000 - fn: 287.0000 - accuracy: 0.8762 - precision: 0.8739 - recall: 0.8808 - auc: 0.9487 - val_loss: 0.0871 - val_tp: 849.0000 - val_fp: 160.0000 - val_tn: 738.0000 - val_fn: 50.0000 - val_accuracy: 0.8831 - val_precision: 0.8414 - val_recall: 0.9444 - val_auc: 0.9545\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0861 - tp: 2137.0000 - fp: 292.0000 - tn: 2092.0000 - fn: 270.0000 - accuracy: 0.8827 - precision: 0.8798 - recall: 0.8878 - auc: 0.9513 - val_loss: 0.0842 - val_tp: 774.0000 - val_fp: 82.0000 - val_tn: 816.0000 - val_fn: 125.0000 - val_accuracy: 0.8848 - val_precision: 0.9042 - val_recall: 0.8610 - val_auc: 0.9550\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0858 - tp: 2146.0000 - fp: 300.0000 - tn: 2084.0000 - fn: 261.0000 - accuracy: 0.8829 - precision: 0.8774 - recall: 0.8916 - auc: 0.9519 - val_loss: 0.0801 - val_tp: 823.0000 - val_fp: 109.0000 - val_tn: 789.0000 - val_fn: 76.0000 - val_accuracy: 0.8971 - val_precision: 0.8830 - val_recall: 0.9155 - val_auc: 0.9568\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0867 - tp: 2142.0000 - fp: 305.0000 - tn: 2079.0000 - fn: 265.0000 - accuracy: 0.8810 - precision: 0.8754 - recall: 0.8899 - auc: 0.9516 - val_loss: 0.0791 - val_tp: 834.0000 - val_fp: 116.0000 - val_tn: 782.0000 - val_fn: 65.0000 - val_accuracy: 0.8993 - val_precision: 0.8779 - val_recall: 0.9277 - val_auc: 0.9574\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0855 - tp: 2129.0000 - fp: 304.0000 - tn: 2080.0000 - fn: 278.0000 - accuracy: 0.8785 - precision: 0.8751 - recall: 0.8845 - auc: 0.9533 - val_loss: 0.0785 - val_tp: 828.0000 - val_fp: 115.0000 - val_tn: 783.0000 - val_fn: 71.0000 - val_accuracy: 0.8965 - val_precision: 0.8780 - val_recall: 0.9210 - val_auc: 0.9586\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0825 - tp: 2146.0000 - fp: 281.0000 - tn: 2103.0000 - fn: 261.0000 - accuracy: 0.8869 - precision: 0.8842 - recall: 0.8916 - auc: 0.9554 - val_loss: 0.0828 - val_tp: 785.0000 - val_fp: 93.0000 - val_tn: 805.0000 - val_fn: 114.0000 - val_accuracy: 0.8848 - val_precision: 0.8941 - val_recall: 0.8732 - val_auc: 0.9547\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0820 - tp: 2165.0000 - fp: 283.0000 - tn: 2101.0000 - fn: 242.0000 - accuracy: 0.8904 - precision: 0.8844 - recall: 0.8995 - auc: 0.9558 - val_loss: 0.0775 - val_tp: 795.0000 - val_fp: 88.0000 - val_tn: 810.0000 - val_fn: 104.0000 - val_accuracy: 0.8932 - val_precision: 0.9003 - val_recall: 0.8843 - val_auc: 0.9588\n",
      "train_auc:  0.9613534559436543\n",
      "test_auc:  0.9592822760255765\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "test_auc = dnn_model(X_train, y_train, X_test, Y_test, lr, 15, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
