{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "import warnings\n",
    "from sklearn import preprocessing\n",
    "import sklearn.preprocessing\n",
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to get w2vec model\n",
    "def getWord_model(word,num_features,min_count, model, Unfile):\n",
    "    word_model = \"\"\n",
    "    \n",
    "    # check if a model exists\n",
    "    if not os.path.isfile(model):\n",
    "        print(Unfile)\n",
    "        sentences = LineSentence(Unfile,max_sentence_length = 15000)\n",
    "\n",
    "        num_features = int(num_features)\n",
    "        min_word_count = int(min_count)\n",
    "        num_workers = 20\n",
    "        context = 20\n",
    "        downsampling = 1e-3\n",
    "        print (\"Training Word2Vec model...\")\n",
    "        word_model = Word2Vec(sentences, workers=num_workers,\\\n",
    "                        vector_size=num_features, min_count=min_word_count, \\\n",
    "                        window=context, sample=downsampling, seed=1,epochs = 50)\n",
    "        word_model.init_sims(replace=False)\n",
    "        word_model.save(model)\n",
    "    \n",
    "    # if w2vec model exists, load the model\n",
    "    else:\n",
    "        print (\"Loading Word2Vec model...\")\n",
    "        word_model = Word2Vec.load(model)\n",
    "\n",
    "    return word_model\n",
    "\n",
    "# Generate Kmers\n",
    "def DNAToWord(dna, K):\n",
    "\n",
    "    sentence = \"\"\n",
    "    length = len(dna)\n",
    "\n",
    "    for i in range(length - K + 1):\n",
    "        sentence += dna[i: i + K] + \" \"\n",
    "\n",
    "    sentence = sentence[0 : len(sentence) - 1]\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def getDNA_split(DNAdata,word):\n",
    "\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    for DNA in DNAdata[\"seq1\"]:\n",
    "        DNA = str(DNA).upper()\n",
    "        list1.append(DNAToWord(DNA,word).split(\" \"))\n",
    "\n",
    "    for DNA in DNAdata[\"seq2\"]:\n",
    "        DNA = str(DNA).upper()\n",
    "        list2.append(DNAToWord(DNA,word).split(\" \"))\n",
    "\n",
    "    return list1,list2\n",
    "\n",
    "def getAvgFeatureVecs(DNAdata1,DNAdata2,model,num_features):\n",
    "    counter = 0\n",
    "    DNAFeatureVecs = np.zeros((len(DNAdata1),2*num_features), dtype=\"float32\")\n",
    "\n",
    "    for DNA in DNAdata1:\n",
    "        print(DNA)\n",
    "        if counter % 1000 == 0:\n",
    "            print (\"DNA %d of %d\\r\" % (counter, len(DNAdata1)))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        DNAFeatureVecs[counter][0:num_features] = np.mean(model.wv[DNA],axis = 0)\n",
    "        counter += 1\n",
    "    print()\n",
    "\n",
    "    counter = 0\n",
    "    for DNA in DNAdata2:\n",
    "        if counter % 1000 == 0:\n",
    "            print (\"DNA %d of %d\\r\" % (counter, len(DNAdata2)))\n",
    "            sys.stdout.flush()\n",
    "        DNAFeatureVecs[counter][num_features:2*num_features] = np.mean(model[DNA],axis = 0)\n",
    "        counter += 1\n",
    "\n",
    "    return DNAFeatureVecs\n",
    "\n",
    "def npyTosvm(npyfile, svmfile, pos_num):\n",
    "    dataDataVecs = np.load(npyfile)\n",
    "    g = open(svmfile,'w')\n",
    "    print(len(dataDataVecs))\n",
    "    #print(dataDataVecs[0])\n",
    "    m = 0\n",
    "    for i in range(len(dataDataVecs)):\n",
    "        line = ''\n",
    "        for j in range(len(dataDataVecs[0])):\n",
    "            if j == len(dataDataVecs[0])-1:\n",
    "                line += str(j+1)+':'+str(dataDataVecs[i][j])+'\\n'\n",
    "            else:\n",
    "                line += str(j+1)+':'+str(dataDataVecs[i][j])+'\\t'\n",
    "        m += 1\n",
    "        if m < (pos_num+1):\n",
    "            g.write('1\\t'+line)\n",
    "        else:\n",
    "            g.write('0\\t'+line)\n",
    "\n",
    "def SVMtoCSV(svmfile, csvfile):\n",
    "    f = open(svmfile,'r')\n",
    "    g = open(csvfile,'w')\n",
    "    lines = f.readlines()\n",
    "    legth = len(lines[0].split(' '))-1\n",
    "    #print(legth)\n",
    "    classline = 'class'\n",
    "    for i in range(legth):\n",
    "        classline += ',%d'%(i+1)\n",
    "    g.write(classline+'\\n')\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip('\\n').split('\t')\n",
    "        g.write(line[0]+',')\n",
    "\n",
    "        legth2 = len(line[1:])\n",
    "        m = 0\n",
    "        for j in line[1:]:\n",
    "            if m == legth2-1:\n",
    "                j = j.split(':')[-1]\n",
    "                g.write(j)\n",
    "                m += 1\n",
    "            else:\n",
    "                j = j.split(':')[-1]\n",
    "                g.write(j+',')\n",
    "                m += 1\n",
    "        g.write('\\n')\n",
    "\n",
    "    f.close()\n",
    "    g.close()\n",
    "    word_model = \"\"\n",
    "    if not os.path.isfile(model):\n",
    "        sentence = LineSentence(Unfile,max_sentence_length = 15000)\n",
    "\n",
    "        num_features = int(num_features)\n",
    "        min_word_count = int(min_count)\n",
    "        num_workers = 20\n",
    "        context = 20\n",
    "        downsampling = 1e-3\n",
    "\n",
    "        print (\"Training Word2Vec model...\")\n",
    "        word_model = Word2Vec(sentence, workers=num_workers,\\\n",
    "                        vector_size=num_features, min_count=min_word_count, \\\n",
    "                        window=context, sample=downsampling, seed=1,epochs = 50)\n",
    "        word_model.init_sims(replace=False)\n",
    "        word_model.save(model)\n",
    "\n",
    "    else:\n",
    "        print (\"Loading Word2Vec model...\")\n",
    "        word_model = Word2Vec.load(model)\n",
    "\n",
    "    return word_model\n",
    "\n",
    "def DNAToWord(dna, K):\n",
    "\n",
    "    sentence = \"\"\n",
    "    length = len(dna)\n",
    "\n",
    "    for i in range(length - K + 1):\n",
    "        sentence += dna[i: i + K] + \" \"\n",
    "\n",
    "    sentence = sentence[0 : len(sentence) - 1]\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def getDNA_split(DNAdata,word):\n",
    "\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    for DNA in DNAdata[\"seq1\"]:\n",
    "        DNA = str(DNA).upper()\n",
    "        list1.append(DNAToWord(DNA,word).split(\" \"))\n",
    "\n",
    "    for DNA in DNAdata[\"seq2\"]:\n",
    "        DNA = str(DNA).upper()\n",
    "        list2.append(DNAToWord(DNA,word).split(\" \"))\n",
    "\n",
    "    return list1,list2\n",
    "\n",
    "def getAvgFeatureVecs(DNAdata1,DNAdata2,model,num_features):\n",
    "    counter = 0\n",
    "    DNAFeatureVecs = np.zeros((len(DNAdata1),2*num_features), dtype=\"float32\")\n",
    "\n",
    "    for DNA in DNAdata1:\n",
    "\n",
    "        if counter % 1000 == 0:\n",
    "            print (\"DNA %d of %d\\r\" % (counter, len(DNAdata1)))\n",
    "            sys.stdout.flush()\n",
    "        DNAFeatureVecs[counter][0:num_features] = np.mean(model.wv[DNA],axis = 0)\n",
    "        counter += 1\n",
    "\n",
    "    counter = 0\n",
    "    for DNA in DNAdata2:\n",
    "        if counter % 1000 == 0:\n",
    "            print (\"DNA %d of %d\\r\" % (counter, len(DNAdata2)))\n",
    "            sys.stdout.flush()\n",
    "        DNAFeatureVecs[counter][num_features:2*num_features] = np.mean(model.wv[DNA],axis = 0)\n",
    "        counter += 1\n",
    "\n",
    "    return DNAFeatureVecs\n",
    "\n",
    "def npyTosvm(npyfile, svmfile, pos_num):\n",
    "    dataDataVecs = np.load(npyfile)\n",
    "    g = open(svmfile,'w')\n",
    "    #print(dataDataVecs[0])\n",
    "    m = 0\n",
    "    for i in range(len(dataDataVecs)):\n",
    "        line = ''\n",
    "        for j in range(len(dataDataVecs[0])):\n",
    "            if j == len(dataDataVecs[0])-1:\n",
    "                line += str(j+1)+':'+str(dataDataVecs[i][j])+'\\n'\n",
    "            else:\n",
    "                line += str(j+1)+':'+str(dataDataVecs[i][j])+'\\t'\n",
    "        m += 1\n",
    "        if m < (pos_num+1):\n",
    "            g.write('1\\t'+line)\n",
    "        else:\n",
    "            g.write('0\\t'+line)\n",
    "\n",
    "def SVMtoCSV(svmfile, csvfile):\n",
    "    f = open(svmfile,'r')\n",
    "    g = open(csvfile,'w')\n",
    "    lines = f.readlines()\n",
    "    legth = len(lines[0].split('\t'))-1\n",
    "    #print(legth)\n",
    "    classline = 'class'\n",
    "    for i in range(legth):\n",
    "        classline += ',%d'%(i+1)\n",
    "    g.write(classline+'\\n')\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip('\\n').split('\t')\n",
    "        g.write(line[0]+',')\n",
    "\n",
    "        legth2 = len(line[1:])\n",
    "        m = 0\n",
    "        for j in line[1:]:\n",
    "            if m == legth2-1:\n",
    "                j = j.split(':')[-1]\n",
    "                g.write(j)\n",
    "                m += 1\n",
    "            else:\n",
    "                j = j.split(':')[-1]\n",
    "                g.write(j+',')\n",
    "                m += 1\n",
    "        g.write('\\n')\n",
    "\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abbasi/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7Un\n",
      "Training Word2Vec model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44915/4227819629.py:16: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  word_model.init_sims(replace=False)\n"
     ]
    }
   ],
   "source": [
    "kmer = 7\n",
    "seqfile = 'train_data.fa'\n",
    "# pos_number=899 # cross test\n",
    "pos_number = 3864 \n",
    "# pos_number = 1658\n",
    "# pos_number=2994\n",
    "# pos_number = 899\n",
    "# pos_number = 5522\n",
    "#### generate Unsupervised ##### \n",
    "Unfile = '%dUn'%(kmer)\n",
    "g = open(Unfile,'w')\n",
    "DNAseq = pd.read_csv(seqfile,sep = \"\\t\",error_bad_lines=False)\n",
    "words1,words2 = getDNA_split(DNAseq,kmer)\n",
    "\n",
    "for i in range(len(words1)):\n",
    "    line = ' '.join(words1[i])\n",
    "    g.write(line+'\\n')\n",
    "\n",
    "for i in range(len(words2)):\n",
    "    line = ' '.join(words2[i])\n",
    "    g.write(line+'\\n')\n",
    "g.close()\n",
    "\n",
    "#####get word2vec model#####\n",
    "model = 'model_%d'%(kmer)\n",
    "fea_num = 100\n",
    "min_fea = 10\n",
    "word_model = getWord_model(kmer,fea_num,min_fea,model,Unfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNA 0 of 7729\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Key 'TCGACGT' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_44915/1989889984.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mword_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdataDataVecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetAvgFeatureVecs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwords2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfea_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdataDataVecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfea_npy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%d_vecs.npy'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_44915/4227819629.py\u001b[0m in \u001b[0;36mgetAvgFeatureVecs\u001b[0;34m(DNAdata1, DNAdata2, model, num_features)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"DNA %d of %d\\r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDNAdata1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mDNAFeatureVecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDNA\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key_or_keys)\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \"\"\"\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'TCGACGT' not present\""
     ]
    }
   ],
   "source": [
    "\n",
    "####obtain word2vec feature set####\n",
    "\n",
    "word_model = Word2Vec.load(model)\n",
    "dataDataVecs = getAvgFeatureVecs(words1,words2,word_model,fea_num)\n",
    "print (dataDataVecs.shape)\n",
    "fea_npy = '%d_vecs.npy'%(kmer)\n",
    "np.save(fea_npy,dataDataVecs)\n",
    "\n",
    "\n",
    "#### npy To csv #####\n",
    "fea_svm = '%d_vecs.svm'%(kmer)\n",
    "fea_csv = '%d_train.csv'%(kmer)\n",
    "\n",
    "npyTosvm(fea_npy, fea_svm,pos_number)\n",
    "SVMtoCSV(fea_svm, fea_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 200)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDataVecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6_vecs.npy'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
