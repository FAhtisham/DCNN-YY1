{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 23:28:08.213216: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Dense, LSTM, Conv1D, Bidirectional, Flatten, Concatenate,concatenate,BatchNormalization,MaxPooling1D, Conv2D, MaxPooling2D, AveragePooling2D, Dropout, Reshape, normalization\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from sklearn import metrics\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def precision(y_true, y_pred):\n",
    "#     # Calculates the precision\n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#     predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "#     precision = true_positives / (predicted_positives + K.epsilon())\n",
    "#     return precision\n",
    "\n",
    "# def recall(y_true, y_pred):\n",
    "#     # Calculates the recall\n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#     possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "#     recall = true_positives / (possible_positives + K.epsilon())\n",
    "#     return recall\n",
    "\n",
    "# def f1(test_Y, pre_test_y):\n",
    "#     \"\"\"F1-score\"\"\"\n",
    "#     Precision = precision(test_Y, pre_test_y)\n",
    "#     Recall = recall(test_Y, pre_test_y)\n",
    "#     f1 = 2 * ((Precision * Recall) / (Precision + Recall + K.epsilon()))\n",
    "#     return f1 \n",
    "\n",
    "# def TP(test_Y,pre_test_y):\n",
    "#     TP = K.sum(K.round(K.clip(test_Y * pre_test_y, 0, 1)))#TP\n",
    "#     return TP\n",
    "\n",
    "# def FN(test_Y,pre_test_y):\n",
    "#     TP = K.sum(K.round(K.clip(test_Y * pre_test_y, 0, 1)))#TP\n",
    "#     P=K.sum(K.round(K.clip(test_Y, 0, 1)))\n",
    "#     FN = P-TP #FN=P-TP\n",
    "#     return FN\n",
    "\n",
    "# def TN(test_Y,pre_test_y):\n",
    "#     TN=K.sum(K.round(K.clip((test_Y-K.ones_like(test_Y))*(pre_test_y-K.ones_like(pre_test_y)), 0, 1)))#TN\n",
    "#     return TN\n",
    "\n",
    "# def FP(test_Y,pre_test_y):\n",
    "#     N = (-1)*K.sum(K.round(K.clip(test_Y-K.ones_like(test_Y), -1, 0)))#N\n",
    "#     TN=K.sum(K.round(K.clip((test_Y-K.ones_like(test_Y))*(pre_test_y-K.ones_like(pre_test_y)), 0, 1)))#TN\n",
    "#     FP=N-TN\n",
    "#     return FP\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc\n",
    "\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "\n",
    "def dnn_model(train_X, train_Y, test_X, test_Y, lr, epoch, batch_size):\n",
    "    train_X = np.expand_dims(train_X, 2)\n",
    "    test_X = np.expand_dims(test_X, 2)\n",
    "    inputs = Input(shape = (train_X.shape[1], train_X.shape[2]))\n",
    "    x = Conv1D(32, kernel_size = 5, strides = 1, padding = 'same', activation = 'relu')(inputs)\n",
    "    \n",
    "    x2 = Conv1D(32, kernel_size=10, strides = 1, padding = 'same', activation = 'relu')(x)\n",
    "    x = concatenate([inputs, x])\n",
    "    \n",
    "    x1 = Conv1D(32, kernel_size=8, strides = 1, padding = 'same', activation = 'relu')(x)\n",
    "    x1 = concatenate([inputs, x1])\n",
    "    # x = MaxPooling1D(pool_size = 2, strides = 2, padding = 'same')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x1= Flatten()(x1)\n",
    "    x1= Dropout(0.2)(x1)\n",
    "    x2 = Flatten()(x2)\n",
    "    \n",
    "    print(x.get_shape(), x2.get_shape(), x1.get_shape())\n",
    "    x = Dense(32, activation = 'relu')(x)\n",
    "    x1 = Dense(32)(x1)\n",
    "    x2=Dense(16)(x2)\n",
    "    x = concatenate([x, x1])\n",
    "    # x = Dense(16, activation = 'relu')(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "    x = concatenate([x, x2])\n",
    "    # x = Dense(8, activation = 'relu')(x)\n",
    "    predictions = Dense(1, activation = 'sigmoid')(x)\n",
    "    model = Model(inputs = inputs, outputs = predictions)\n",
    "    # print(model.summary())\n",
    "    model.compile(optimizer = 'Adam',\n",
    "                  loss = 'binary_crossentropy',\n",
    "                  metrics = METRICS)\n",
    "    print(\"compile\")\n",
    "    model.fit(train_X, train_Y, epochs = epoch, batch_size = batch_size, validation_data = (test_X, test_Y), shuffle = True)\n",
    "\n",
    "    pre_test_y = model.predict(test_X, batch_size = batch_size)\n",
    "    pre_train_y = model.predict(train_X, batch_size = batch_size)\n",
    "    test_auc = metrics.roc_auc_score(test_Y, pre_test_y)\n",
    "    train_auc = metrics.roc_auc_score(train_Y, pre_train_y)\n",
    "    print(\"train_auc: \", train_auc)\n",
    "    print(\"test_auc: \", test_auc) \n",
    "    return test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Independent Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data = np.array(pd.read_csv(\"6_test.csv\"))\n",
    "pos_number = 899\n",
    "X1 = data[0:pos_number, 1:]\n",
    "Y1 = data[0:pos_number, 0]\n",
    "X2 = data[pos_number:, 1:]\n",
    "Y2 = data[pos_number:, 0]\n",
    "X_test = np.concatenate([X1, X2], 0)\n",
    "Y_test = np.concatenate([Y1, Y2], 0)\n",
    "\n",
    "\n",
    "lr = 0.01\n",
    "batch_size = 32\n",
    "\n",
    "data = np.array(pd.read_csv(\"6_train.csv\"))\n",
    "pos_number = 3864 # NOTE: the number of postive sample in train file\n",
    "#CNN_model = 'CNN_model.h5'\n",
    "\n",
    "\n",
    "X1 = data[0:pos_number, 1:]\n",
    "Y1 = data[0:pos_number, 0]\n",
    "X2 = data[pos_number:, 1:]\n",
    "Y2 = data[pos_number:, 0]\n",
    "X = np.concatenate([X1, X2], 0)\n",
    "Y = np.concatenate([Y1, Y2], 0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 6600) (None, 6400) (None, 6600)\n",
      "compile\n",
      "Epoch 1/6\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3501 - tp: 3301.0000 - fp: 564.0000 - tn: 3301.0000 - fn: 563.0000 - accuracy: 0.8542 - precision: 0.8541 - recall: 0.8543 - auc: 0.9250 - val_loss: 0.3461 - val_tp: 787.0000 - val_fp: 158.0000 - val_tn: 740.0000 - val_fn: 112.0000 - val_accuracy: 0.8497 - val_precision: 0.8328 - val_recall: 0.8754 - val_auc: 0.9332\n",
      "Epoch 2/6\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3211 - tp: 3387.0000 - fp: 579.0000 - tn: 3286.0000 - fn: 477.0000 - accuracy: 0.8634 - precision: 0.8540 - recall: 0.8766 - auc: 0.9355 - val_loss: 0.3176 - val_tp: 783.0000 - val_fp: 129.0000 - val_tn: 769.0000 - val_fn: 116.0000 - val_accuracy: 0.8637 - val_precision: 0.8586 - val_recall: 0.8710 - val_auc: 0.9410\n",
      "Epoch 3/6\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3047 - tp: 3425.0000 - fp: 558.0000 - tn: 3307.0000 - fn: 439.0000 - accuracy: 0.8710 - precision: 0.8599 - recall: 0.8864 - auc: 0.9423 - val_loss: 0.3226 - val_tp: 828.0000 - val_fp: 180.0000 - val_tn: 718.0000 - val_fn: 71.0000 - val_accuracy: 0.8603 - val_precision: 0.8214 - val_recall: 0.9210 - val_auc: 0.9436\n",
      "Epoch 4/6\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2923 - tp: 3447.0000 - fp: 547.0000 - tn: 3318.0000 - fn: 417.0000 - accuracy: 0.8753 - precision: 0.8630 - recall: 0.8921 - auc: 0.9464 - val_loss: 0.3096 - val_tp: 823.0000 - val_fp: 163.0000 - val_tn: 735.0000 - val_fn: 76.0000 - val_accuracy: 0.8670 - val_precision: 0.8347 - val_recall: 0.9155 - val_auc: 0.9446\n",
      "Epoch 5/6\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2770 - tp: 3487.0000 - fp: 552.0000 - tn: 3313.0000 - fn: 377.0000 - accuracy: 0.8798 - precision: 0.8633 - recall: 0.9024 - auc: 0.9519 - val_loss: 0.2923 - val_tp: 793.0000 - val_fp: 125.0000 - val_tn: 773.0000 - val_fn: 106.0000 - val_accuracy: 0.8715 - val_precision: 0.8638 - val_recall: 0.8821 - val_auc: 0.9480\n",
      "Epoch 6/6\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.2688 - tp: 3487.0000 - fp: 506.0000 - tn: 3359.0000 - fn: 377.0000 - accuracy: 0.8858 - precision: 0.8733 - recall: 0.9024 - auc: 0.9549 - val_loss: 0.3081 - val_tp: 821.0000 - val_fp: 163.0000 - val_tn: 735.0000 - val_fn: 78.0000 - val_accuracy: 0.8659 - val_precision: 0.8343 - val_recall: 0.9132 - val_auc: 0.9450\n",
      "57/57 [==============================] - 0s 1ms/step\n",
      "242/242 [==============================] - 0s 1ms/step\n",
      "train_auc:  0.9655450250295292\n",
      "test_auc:  0.9451258636792677\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# test_auc = dnn_model(X_train, y_train, X_test, y_test, lr, 5, 32)\n",
    "\n",
    "\n",
    "test_auc = dnn_model(X, Y, X_test, Y_test, lr, 6, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
