{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "import warnings\n",
    "from sklearn import preprocessing\n",
    "import sklearn.preprocessing\n",
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to get w2vec model\n",
    "def getWord_model(word,num_features,min_count, model, Unfile):\n",
    "    word_model = \"\"\n",
    "    \n",
    "    # check if a model exists\n",
    "    if not os.path.isfile(model):\n",
    "        print(Unfile)\n",
    "        sentences = LineSentence(Unfile,max_sentence_length = 15000)\n",
    "\n",
    "        num_features = int(num_features)\n",
    "        min_word_count = int(min_count)\n",
    "        num_workers = 20\n",
    "        context = 20\n",
    "        downsampling = 1e-3\n",
    "        print (\"Training Word2Vec model...\")\n",
    "        word_model = Word2Vec(sentences, workers=num_workers,\\\n",
    "                        vector_size=num_features, min_count=min_word_count, \\\n",
    "                        window=context, sample=downsampling, seed=1,epochs = 50)\n",
    "        word_model.init_sims(replace=False)\n",
    "        word_model.save(model)\n",
    "    \n",
    "    # if w2vec model exists, load the model\n",
    "    else:\n",
    "        print (\"Loading Word2Vec model...\")\n",
    "        word_model = Word2Vec.load(model)\n",
    "\n",
    "    return word_model\n",
    "\n",
    "# # Function to Generate Kmers\n",
    "# def DNAToWord(dna, K):\n",
    "\n",
    "#     sentence = \"\"\n",
    "#     length = len(dna)\n",
    "\n",
    "#     for i in range(length - K + 1):\n",
    "#         sentence += dna[i: i + K] + \" \"\n",
    "\n",
    "#     sentence = sentence[0 : len(sentence) - 1]\n",
    "#     return sentence\n",
    "\n",
    "# # Get enhancer and promoter sequences separately\n",
    "# def getDNA_split(DNAdata,word):\n",
    "\n",
    "#     list1 = []\n",
    "#     list2 = []\n",
    "#     for DNA in DNAdata[\"seq1\"]:\n",
    "#         DNA = str(DNA).upper()\n",
    "#         list1.append(DNAToWord(DNA,word).split(\" \"))\n",
    "\n",
    "#     for DNA in DNAdata[\"seq2\"]:\n",
    "#         DNA = str(DNA).upper()\n",
    "#         list2.append(DNAToWord(DNA,word).split(\" \"))\n",
    "\n",
    "#     return list1,list2\n",
    "\n",
    "# # Average out the features individually for the separated sequences of promoters and enhancers\n",
    "# def getAvgFeatureVecs(DNAdata1,DNAdata2,model,num_features):\n",
    "#     counter = 0\n",
    "#     DNAFeatureVecs = np.zeros((len(DNAdata1),2*num_features), dtype=\"float32\")\n",
    "\n",
    "#     for DNA in DNAdata1:\n",
    "#         if counter % 1000 == 0:\n",
    "#             print (\"DNA %d of %d\\r\" % (counter, len(DNAdata1)))\n",
    "#             sys.stdout.flush()\n",
    "\n",
    "#         DNAFeatureVecs[counter][0:num_features] = np.mean(model.wv[DNA],axis = 0)\n",
    "#         counter += 1\n",
    "\n",
    "#     counter = 0\n",
    "#     for DNA in DNAdata2:\n",
    "#         if counter % 1000 == 0:\n",
    "#             print (\"DNA %d of %d\\r\" % (counter, len(DNAdata2)))\n",
    "#             sys.stdout.flush()\n",
    "#         DNAFeatureVecs[counter][num_features:2*num_features] = np.mean(model[DNA],axis = 0)\n",
    "#         counter += 1\n",
    "\n",
    "#     return DNAFeatureVecs\n",
    "\n",
    "# def npyTosvm(npyfile, svmfile, pos_num):\n",
    "#     dataDataVecs = np.load(npyfile)\n",
    "#     g = open(svmfile,'w')\n",
    "#     m = 0\n",
    "#     for i in range(len(dataDataVecs)):\n",
    "#         line = ''\n",
    "#         for j in range(len(dataDataVecs[0])):\n",
    "#             if j == len(dataDataVecs[0])-1:\n",
    "#                 line += str(j+1)+':'+str(dataDataVecs[i][j])+'\\n'\n",
    "#             else:\n",
    "#                 line += str(j+1)+':'+str(dataDataVecs[i][j])+'\\t'\n",
    "#         m += 1\n",
    "#         if m < (pos_num+1):\n",
    "#             g.write('1\\t'+line)\n",
    "#         else:\n",
    "#             g.write('0\\t'+line)\n",
    "            \n",
    "# # Function to write the vectors to csv file\n",
    "# def SVMtoCSV(svmfile, csvfile):\n",
    "#     f = open(svmfile,'r')\n",
    "#     g = open(csvfile,'w')\n",
    "#     lines = f.readlines()\n",
    "#     legth = len(lines[0].split(' '))-1\n",
    "#     classline = 'class'\n",
    "#     for i in range(legth):\n",
    "#         classline += ',%d'%(i+1)\n",
    "#     g.write(classline+'\\n')\n",
    "\n",
    "#     for line in lines:\n",
    "#         line = line.strip('\\n').split('\t')\n",
    "#         g.write(line[0]+',')\n",
    "\n",
    "#         legth2 = len(line[1:])\n",
    "#         m = 0\n",
    "#         for j in line[1:]:\n",
    "#             if m == legth2-1:\n",
    "#                 j = j.split(':')[-1]\n",
    "#                 g.write(j)\n",
    "#                 m += 1\n",
    "#             else:\n",
    "#                 j = j.split(':')[-1]\n",
    "#                 g.write(j+',')\n",
    "#                 m += 1\n",
    "#         g.write('\\n')\n",
    "\n",
    "#     f.close()\n",
    "#     g.close()\n",
    "#     word_model = \"\"\n",
    "#     if not os.path.isfile(model):\n",
    "#         sentence = LineSentence(Unfile,max_sentence_length = 15000)\n",
    "\n",
    "#         num_features = int(num_features)\n",
    "#         min_word_count = int(min_count)\n",
    "#         num_workers = 20\n",
    "#         context = 20\n",
    "#         downsampling = 1e-3\n",
    "\n",
    "#         print (\"Training Word2Vec model...\")\n",
    "#         word_model = Word2Vec(sentence, workers=num_workers,\\\n",
    "#                         vector_size=num_features, min_count=min_word_count, \\\n",
    "#                         window=context, sample=downsampling, seed=1,epochs = 50)\n",
    "#         word_model.init_sims(replace=False)\n",
    "#         word_model.save(model)\n",
    "\n",
    "#     else:\n",
    "#         print (\"Loading Word2Vec model...\")\n",
    "#         word_model = Word2Vec.load(model)\n",
    "\n",
    "#     return word_model\n",
    "\n",
    "def DNAToWord(dna, K):\n",
    "\n",
    "    sentence = \"\"\n",
    "    length = len(dna)\n",
    "\n",
    "    for i in range(length - K + 1):\n",
    "        sentence += dna[i: i + K] + \" \"\n",
    "\n",
    "    sentence = sentence[0 : len(sentence) - 1]\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def getDNA_split(DNAdata,word):\n",
    "\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    for DNA in DNAdata[\"seq1\"]:\n",
    "        DNA = str(DNA).upper()\n",
    "        list1.append(DNAToWord(DNA,word).split(\" \"))\n",
    "\n",
    "    for DNA in DNAdata[\"seq2\"]:\n",
    "        DNA = str(DNA).upper()\n",
    "        list2.append(DNAToWord(DNA,word).split(\" \"))\n",
    "\n",
    "    return list1,list2\n",
    "\n",
    "def getAvgFeatureVecs(DNAdata1,DNAdata2,model,num_features):\n",
    "    counter = 0\n",
    "    DNAFeatureVecs = np.zeros((len(DNAdata1),2*num_features), dtype=\"float32\")\n",
    "\n",
    "    for DNA in DNAdata1:\n",
    "\n",
    "        if counter % 1000 == 0:\n",
    "            print (\"DNA %d of %d\\r\" % (counter, len(DNAdata1)))\n",
    "            sys.stdout.flush()\n",
    "        DNAFeatureVecs[counter][0:num_features] = np.mean(model.wv[DNA],axis = 0)\n",
    "        counter += 1\n",
    "\n",
    "    counter = 0\n",
    "    for DNA in DNAdata2:\n",
    "        if counter % 1000 == 0:\n",
    "            print (\"DNA %d of %d\\r\" % (counter, len(DNAdata2)))\n",
    "            sys.stdout.flush()\n",
    "        DNAFeatureVecs[counter][num_features:2*num_features] = np.mean(model.wv[DNA],axis = 0)\n",
    "        counter += 1\n",
    "\n",
    "    return DNAFeatureVecs\n",
    "\n",
    "def npyTosvm(npyfile, svmfile, pos_num):\n",
    "    dataDataVecs = np.load(npyfile)\n",
    "    g = open(svmfile,'w')\n",
    "    #print(dataDataVecs[0])\n",
    "    m = 0\n",
    "    for i in range(len(dataDataVecs)):\n",
    "        line = ''\n",
    "        for j in range(len(dataDataVecs[0])):\n",
    "            if j == len(dataDataVecs[0])-1:\n",
    "                line += str(j+1)+':'+str(dataDataVecs[i][j])+'\\n'\n",
    "            else:\n",
    "                line += str(j+1)+':'+str(dataDataVecs[i][j])+'\\t'\n",
    "        m += 1\n",
    "        if m < (pos_num+1):\n",
    "            g.write('1\\t'+line)\n",
    "        else:\n",
    "            g.write('0\\t'+line)\n",
    "\n",
    "def SVMtoCSV(svmfile, csvfile):\n",
    "    f = open(svmfile,'r')\n",
    "    g = open(csvfile,'w')\n",
    "    lines = f.readlines()\n",
    "    legth = len(lines[0].split('\t'))-1\n",
    "    #print(legth)\n",
    "    classline = 'class'\n",
    "    for i in range(legth):\n",
    "        classline += ',%d'%(i+1)\n",
    "    g.write(classline+'\\n')\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip('\\n').split('\t')\n",
    "        g.write(line[0]+',')\n",
    "\n",
    "        legth2 = len(line[1:])\n",
    "        m = 0\n",
    "        for j in line[1:]:\n",
    "            if m == legth2-1:\n",
    "                j = j.split(':')[-1]\n",
    "                g.write(j)\n",
    "                m += 1\n",
    "            else:\n",
    "                j = j.split(':')[-1]\n",
    "                g.write(j+',')\n",
    "                m += 1\n",
    "        g.write('\\n')\n",
    "\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abbasi/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Word2Vec model...\n"
     ]
    }
   ],
   "source": [
    "kmer = 6\n",
    "seqfile = 'cross_test_data.fa'\n",
    "\n",
    "# define number of positive samples in train set\n",
    "pos_number=899 # cross test\n",
    "# pos_number = 3864 # train\n",
    "# pos_number = 1658 # test set\n",
    "\n",
    "#### generate Unsupervised ##### \n",
    "Unfile = '%dUn'%(kmer)\n",
    "g = open(Unfile,'w')\n",
    "DNAseq = pd.read_csv(seqfile,sep = \"\\t\",error_bad_lines=False)\n",
    "words1,words2 = getDNA_split(DNAseq,kmer)\n",
    "\n",
    "for i in range(len(words1)):\n",
    "    line = ' '.join(words1[i])\n",
    "    g.write(line+'\\n')\n",
    "\n",
    "for i in range(len(words2)):\n",
    "    line = ' '.join(words2[i])\n",
    "    g.write(line+'\\n')\n",
    "g.close()\n",
    "\n",
    "#####get word2vec model#####\n",
    "model = 'model_%d'%(kmer)\n",
    "fea_num = 100\n",
    "min_fea = 10\n",
    "word_model = getWord_model(kmer,fea_num,min_fea,model,Unfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNA 0 of 1797\n",
      "DNA 1000 of 1797\n",
      "DNA 0 of 1797\n",
      "DNA 1000 of 1797\n",
      "(1797, 200)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "####obtain word2vec feature set####\n",
    "word_model = Word2Vec.load(model)\n",
    "dataDataVecs = getAvgFeatureVecs(words1,words2,word_model,fea_num)\n",
    "print (dataDataVecs.shape)\n",
    "fea_npy = '%d_vecs.npy'%(kmer)\n",
    "np.save(fea_npy,dataDataVecs)\n",
    "\n",
    "\n",
    "#### npy To csv #####\n",
    "fea_svm = '%d_vecs.svm'%(kmer)\n",
    "fea_csv = '%cross_test.csv'%(kmer)\n",
    "\n",
    "npyTosvm(fea_npy, fea_svm,pos_number)\n",
    "SVMtoCSV(fea_svm, fea_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 200)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDataVecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6_vecs.npy'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
